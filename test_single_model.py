#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å–®æ¨¡å‹æ¸¬è©¦è…³æœ¬
æ¸¬è©¦å–®å€‹ OpenRouter å…è²»æ¨¡å‹ç”Ÿæˆ Zettelkasten å¡ç‰‡
"""

import shutil
import argparse
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

from src.generators.zettel_maker import ZettelMaker
from src.generators.slide_maker import SlideMaker


def extract_paper_content(md_path):
    """å¾ MD æ–‡ä»¶æå–è«–æ–‡å…§å®¹"""
    content = md_path.read_text(encoding='utf-8')

    import re
    title = "Unknown"
    authors = "Unknown"
    year = None

    title_match = re.search(r"title:\s*['\"]?(.+?)['\"]?\s*$", content, re.MULTILINE)
    if title_match:
        title = title_match.group(1)

    authors_match = re.search(r"authors:\s*(.+?)$", content, re.MULTILINE)
    if authors_match:
        authors = authors_match.group(1)

    year_match = re.search(r"year:\s*(\d{4})", content)
    if year_match:
        year = int(year_match.group(1))

    content_start = content.find('---', content.find('---') + 3) + 3
    full_content = content[content_start:].strip()

    return {
        'title': title,
        'authors': authors,
        'year': year,
        'content': full_content[:15000],
        'cite_key': md_path.stem
    }


def main():
    parser = argparse.ArgumentParser(description='å–®æ¨¡å‹æ¸¬è©¦')
    parser.add_argument('--cite-key', default='Jones-2024', help='è«–æ–‡ cite key')
    parser.add_argument('--model', default='google/gemini-2.0-flash-exp:free',
                       help='OpenRouter æ¨¡å‹ ID')
    parser.add_argument('--suffix', default='test', help='è¼¸å‡ºç›®éŒ„å¾Œç¶´')
    parser.add_argument('--max-tokens', type=int, default=4096,
                       help='æœ€å¤§ç”Ÿæˆ tokens æ•¸ï¼ˆé»˜èª 4096ï¼‰')
    args = parser.parse_args()

    print("\n" + "="*70)
    print("å–®æ¨¡å‹æ¸¬è©¦ - OpenRouter")
    print("="*70 + "\n")

    # 1. è®€å–è«–æ–‡
    md_path = Path(f"knowledge_base/papers/{args.cite_key}.md")
    if not md_path.exists():
        print(f"[ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {md_path}")
        return

    print(f"[INFO] è®€å–è«–æ–‡: {md_path}")
    paper_data = extract_paper_content(md_path)
    print(f"[OK] æ¨™é¡Œ: {paper_data['title'][:60]}...")
    print(f"[OK] ä½œè€…: {paper_data['authors']}")
    print(f"[OK] å¹´ä»½: {paper_data['year']}\n")

    # 2. åˆå§‹åŒ– SlideMaker
    print(f"[INFO] ä½¿ç”¨æ¨¡å‹: {args.model}")
    slide_maker = SlideMaker(llm_provider='openrouter')

    # 3. æº–å‚™ prompt
    from jinja2 import Template
    template_path = Path("templates/prompts/zettelkasten_template.jinja2")
    template = Template(template_path.read_text(encoding='utf-8'))

    prompt = template.render(
        topic=paper_data['title'],
        card_count=20,
        detail_level="comprehensive",
        paper_content=paper_data['content'],
        cite_key=paper_data['cite_key']
    )

    print(f"[INFO] Prompt é•·åº¦: {len(prompt)} å­—ç¬¦\n")

    # 4. èª¿ç”¨ LLM
    print(f"[INFO] æ­£åœ¨èª¿ç”¨ LLM...")
    print(f"[INFO] Max tokens: {args.max_tokens}")
    try:
        result = slide_maker.call_llm(
            prompt,
            provider='openrouter',
            model=args.model,
            timeout=600,
            max_tokens=args.max_tokens
        )

        if not result:
            print(f"[ERROR] LLM è¿”å›ç©ºéŸ¿æ‡‰")
            return

        response, provider = result
        print(f"[OK] LLM éŸ¿æ‡‰: {len(response)} å­—ç¬¦\n")

    except Exception as e:
        print(f"[ERROR] LLM èª¿ç”¨å¤±æ•—: {e}")
        return

    # 5. ç”Ÿæˆå¡ç‰‡æ–‡ä»¶
    output_dir = Path("output/zettelkasten_notes") / f"zettel_{paper_data['cite_key']}_{datetime.now().strftime('%Y%m%d')}_{args.suffix}"

    if output_dir.exists():
        shutil.rmtree(output_dir)

    print(f"[INFO] ç”Ÿæˆå¡ç‰‡åˆ°: {output_dir}")

    zettel_maker = ZettelMaker()
    result = zettel_maker.generate_zettelkasten(
        llm_output=response,
        output_dir=output_dir,
        paper_info={
            'cite_key': paper_data['cite_key'],
            'title': paper_data['title'],
            'authors': paper_data['authors'],
            'year': paper_data['year']
        }
    )

    print(f"\n[SUCCESS] ç”Ÿæˆ {result['card_count']} å¼µå¡ç‰‡")

    # 6. åˆ†æè¼¸å‡º
    print(f"\n" + "="*70)
    print("è¼¸å‡ºåˆ†æ")
    print("="*70)

    cards_dir = output_dir / "zettel_cards"
    if cards_dir.exists():
        card_files = list(cards_dir.glob("*.md"))
        print(f"å¡ç‰‡æ•¸é‡: {len(card_files)}")

        # åˆ†æ AI notes ä¸­çš„é€£çµ
        total_links = 0
        cards_with_links = 0

        for card_file in card_files:
            content = card_file.read_text(encoding='utf-8')

            if 'ğŸ¤– **AI**:' in content:
                ai_section = content.split('ğŸ¤– **AI**:')[1].split('âœï¸ **Human**:')[0]
                links = ai_section.count('[[')
                if links > 0:
                    cards_with_links += 1
                    total_links += links

        print(f"AI notes åŒ…å«é€£çµçš„å¡ç‰‡: {cards_with_links}/{len(card_files)} ({cards_with_links/len(card_files)*100:.1f}%)")
        print(f"AI notes ç¸½é€£çµæ•¸: {total_links}")
        print(f"å¹³å‡æ¯å¼µå¡ç‰‡é€£çµæ•¸: {total_links/len(card_files):.2f}")

        # é¡¯ç¤ºå‰ 3 å¼µå¡ç‰‡çš„ AI notesï¼ˆç¤ºä¾‹ï¼‰
        print(f"\nå‰ 3 å¼µå¡ç‰‡ AI notes ç¤ºä¾‹:")
        print("-" * 70)
        for i, card_file in enumerate(sorted(card_files)[:3], 1):
            content = card_file.read_text(encoding='utf-8')
            if 'ğŸ¤– **AI**:' in content:
                ai_section = content.split('ğŸ¤– **AI**:')[1].split('âœï¸ **Human**:')[0].strip()
                print(f"\nå¡ç‰‡ {i} ({card_file.name}):")
                print(f"  {ai_section[:150]}...")

    print(f"\n[SUCCESS] å®Œæˆï¼è¼¸å‡º: {output_dir}")


if __name__ == '__main__':
    main()
