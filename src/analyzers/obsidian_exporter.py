#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Obsidian Exporter - å°‡ Concept Mapper åˆ†æçµæœå°å‡ºç‚º Obsidian å‹å¥½æ ¼å¼

æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
- å»ºè­°é€£çµåˆ—è¡¨ (suggested_links.md)
- é—œéµæ¦‚å¿µåœ°åœ– MOC (key_concepts_moc.md)
- ç¤¾ç¾¤æ‘˜è¦ç­†è¨˜ (community_summaries/)
- è·¯å¾‘åˆ†æç­†è¨˜ (path_analysis.md)

ä½¿ç”¨ç¯„ä¾‹:
    from src.analyzers.obsidian_exporter import ObsidianExporter

    exporter = ObsidianExporter(vault_path="path/to/vault")
    exporter.export_all(
        analysis_results={...},
        output_dir="path/to/output"
    )
"""

import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import re

# å°å…¥æ¦‚å¿µæ˜ å°„å™¨çš„æ•¸æ“šé¡å‹
import sys
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.analyzers.concept_mapper import (
    Community,
    ConceptPath,
    CentralityScores
)


class ObsidianExporter:
    """Obsidian å°å‡ºå™¨

    å°‡ Concept Mapper çš„åˆ†æçµæœè½‰æ›ç‚º Obsidian å¯ç›´æ¥ä½¿ç”¨çš„æ ¼å¼
    """

    def __init__(self, kb_path: str = "knowledge_base"):
        """åˆå§‹åŒ–å°å‡ºå™¨

        åƒæ•¸:
            kb_path: çŸ¥è­˜åº«è·¯å¾‘ï¼ˆåŒ…å« Zettelkasten å¡ç‰‡ï¼‰
        """
        self.kb_path = Path(kb_path)
        self.zettel_dir = self.kb_path / "zettelkasten"

        # å»ºç«‹å¡ç‰‡ ID åˆ°æ¨™é¡Œçš„æ˜ å°„
        self.card_map = self._build_card_map()

    def _build_card_map(self) -> Dict[str, Dict[str, str]]:
        """å»ºç«‹å¡ç‰‡ ID åˆ°å…ƒæ•¸æ“šçš„æ˜ å°„ï¼ˆåŒ…å« zettel_index.md éŒ¨é»ä¿¡æ¯ï¼‰

        è¿”å›:
            Dict[card_id, {
                'title': str,
                'path': str,
                'core_concept': str,
                'zettel_folder': str,
                'index_entry': str,
                'index_number': str
            }]
        """
        card_map = {}

        # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨ output/zettelkasten_notes/ è·¯å¾‘
        possible_zettel_dirs = [
            self.zettel_dir,
            Path("output/zettelkasten_notes")
        ]

        zettel_dir = None
        for dir_path in possible_zettel_dirs:
            if dir_path.exists():
                zettel_dir = dir_path
                break

        if not zettel_dir:
            print(f"âš ï¸ Zettelkasten ç›®éŒ„ä¸å­˜åœ¨")
            print(f"   å˜—è©¦éçš„è·¯å¾‘: {', '.join(str(p) for p in possible_zettel_dirs)}")
            return card_map

        print(f"âœ… ä½¿ç”¨ Zettelkasten ç›®éŒ„: {zettel_dir}")

        # æƒææ‰€æœ‰ Zettelkasten è³‡æ–™å¤¾
        for zettel_folder in zettel_dir.iterdir():
            if not zettel_folder.is_dir():
                continue

            index_file = zettel_folder / "zettel_index.md"
            if not index_file.exists():
                continue

            # è®€å– index æ–‡ä»¶ï¼Œè§£ææ¢ç›®
            try:
                index_content = index_file.read_text(encoding='utf-8')
                # æå–æ¯å€‹å¡ç‰‡æ¢ç›®ï¼ˆæ ¼å¼: ### 1. [æ¨™é¡Œ](zettel_cards/ID.md)ï¼‰
                entry_pattern = r'###\s+(\d+)\.\s+\[([^\]]+)\]\(zettel_cards/([^)]+)\.md\)'
                entries = re.findall(entry_pattern, index_content)

                for entry_num, entry_title, card_id in entries:
                    # è®€å–å¡ç‰‡æ–‡ä»¶ç²å–å®Œæ•´å…ƒæ•¸æ“š
                    card_file = zettel_folder / "zettel_cards" / f"{card_id}.md"
                    if card_file.exists():
                        try:
                            card_content = card_file.read_text(encoding='utf-8')

                            # æå– YAML frontmatter ä¸­çš„æ¨™é¡Œ
                            title_match = re.search(r'^title:\s*"?([^"\n]+)"?', card_content, re.MULTILINE)
                            title = title_match.group(1).strip() if title_match else entry_title

                            # æå–æ ¸å¿ƒæ¦‚å¿µ
                            core_match = re.search(r'^core_concept:\s*"?([^"\n]+)"?', card_content, re.MULTILINE)
                            core_concept = core_match.group(1).strip() if core_match else ""

                            # æ§‹å»ºç›¸å°è·¯å¾‘ï¼ˆå¾ zettel è³‡æ–™å¤¾åç¨±é–‹å§‹ï¼Œä¸åŒ…å« output/zettelkasten_notes/ï¼‰
                            # ä¾‹å¦‚: zettel_Abbas-2022_20251104/zettel_index
                            zettel_folder_name = zettel_folder.name  # åªå–è³‡æ–™å¤¾åç¨±
                            index_path_rel = f"{zettel_folder_name}/zettel_index"
                            card_path_rel = f"{zettel_folder_name}/zettel_cards/{card_id}.md"

                            # æ§‹å»º index æ¢ç›®å­—ç¬¦ä¸²ï¼ˆç”¨æ–¼éŒ¨é»ï¼‰
                            index_entry = f"{entry_num}. [{entry_title}](zettel_cards/{card_id}.md)"

                            card_map[card_id] = {
                                'title': title,
                                'path': card_path_rel,
                                'core_concept': core_concept,
                                'zettel_folder': zettel_folder_name,
                                'index_path': index_path_rel,  # æ ¼å¼: zettel_xxx/zettel_index
                                'index_entry': index_entry,
                                'index_number': entry_num
                            }
                        except Exception as e:
                            print(f"âš ï¸ ç„¡æ³•è®€å–å¡ç‰‡ {card_file}: {e}")
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•è®€å–ç´¢å¼• {index_file}: {e}")

        print(f"âœ… å»ºç«‹å¡ç‰‡æ˜ å°„: {len(card_map)} å¼µå¡ç‰‡")
        return card_map

    def _get_note_title(self, card_id: str) -> str:
        """ç²å–å¡ç‰‡æ¨™é¡Œï¼ˆç”¨æ–¼ Wiki Linkï¼‰

        åƒæ•¸:
            card_id: å¡ç‰‡ ID

        è¿”å›:
            æ¨™é¡Œå­—ç¬¦ä¸²ï¼ˆå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› card_idï¼‰
        """
        if card_id in self.card_map:
            return self.card_map[card_id]['title']
        return card_id

    def _get_note_path(self, card_id: str) -> str:
        """ç²å–å¡ç‰‡ç›¸å°è·¯å¾‘

        åƒæ•¸:
            card_id: å¡ç‰‡ ID

        è¿”å›:
            ç›¸å°è·¯å¾‘ï¼ˆå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› card_idï¼‰
        """
        if card_id in self.card_map:
            return self.card_map[card_id]['path']
        return card_id

    def _format_wiki_link(self, card_id: str, use_alias: bool = True, use_index_anchor: bool = False) -> str:
        """æ ¼å¼åŒ– Wiki Linkï¼ˆä½¿ç”¨ç›´æ¥å¡ç‰‡è·¯å¾‘ï¼‰

        åƒæ•¸:
            card_id: å¡ç‰‡ ID
            use_alias: æ˜¯å¦ä½¿ç”¨åˆ¥åï¼ˆ|titleï¼‰ï¼Œåœ¨è¡¨æ ¼ä¸­æ‡‰è¨­ç‚º False é¿å…ç®¡é“ç¬¦è™Ÿå•é¡Œ
            use_index_anchor: å·²æ£„ç”¨ï¼Œä¿ç•™åƒæ•¸ä»¥å‘å¾Œç›¸å®¹

        è¿”å›:
            æ ¼å¼åŒ–çš„ Wiki Link å­—ç¬¦ä¸²

        ç¯„ä¾‹:
            å®Œæ•´æ ¼å¼ï¼ˆuse_alias=Trueï¼‰: [[zettel_Abbas-2022_20251104/zettel_cards/Abbas-2022-001|ç›®æ¨™è¨­å®šç†è«–]]
            ç°¡å–®æ ¼å¼ï¼ˆuse_alias=Falseï¼‰: [[zettel_Abbas-2022_20251104/zettel_cards/Abbas-2022-001]]
            æ‰¾ä¸åˆ°æ™‚: [[card_id]]
        """
        if card_id not in self.card_map:
            # æ‰¾ä¸åˆ°å¡ç‰‡ä¿¡æ¯ï¼Œä½¿ç”¨ç°¡å–®æ ¼å¼
            return f"[[{card_id}]]"

        card_info = self.card_map[card_id]
        title = card_info['title']
        card_path = card_info['path']

        # ç§»é™¤ .md å‰¯æª”åï¼ˆObsidian Wiki Link ä¸éœ€è¦å‰¯æª”åï¼‰
        if card_path.endswith('.md'):
            card_path = card_path[:-3]

        if use_alias:
            # å®Œæ•´æ ¼å¼ï¼šå¸¶åˆ¥åçš„é€£çµï¼ˆé©ç”¨æ–¼æ­£æ–‡ï¼‰
            return f"[[{card_path}|{title}]]"
        else:
            # ç°¡å–®æ ¼å¼ï¼šä¸å¸¶åˆ¥åï¼ˆé©ç”¨æ–¼è¡¨æ ¼ï¼Œé¿å…ç®¡é“ç¬¦è™Ÿè¡çªï¼‰
            return f"[[{card_path}]]"

    def _get_timestamp(self) -> str:
        """ç²å–ç•¶å‰æ™‚é–“æˆ³"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def export_suggested_links(
        self,
        relations: List[Dict],
        top_n: int = 50,
        min_confidence: float = 0.4
    ) -> str:
        """ç”Ÿæˆå»ºè­°é€£çµçš„ Markdown æ–‡ä»¶

        åƒæ•¸:
            relations: é—œä¿‚åˆ—è¡¨
            top_n: è¿”å› top-n å»ºè­°
            min_confidence: æœ€å°ä¿¡åº¦é–¾å€¼ï¼ˆé»˜èª 0.4ï¼Œæ¨è–¦ç¯„åœ 0.3-0.5ï¼‰

        è¿”å›:
            Markdown æ ¼å¼çš„å»ºè­°é€£çµæ–‡æª”
        """
        lines = ["# ğŸ”— å»ºè­°æ–°å¢çš„æ¦‚å¿µé€£çµ\n"]
        lines.append(f"**ç”Ÿæˆæ™‚é–“**: {self._get_timestamp()}\n")
        lines.append(f"**åˆ†æä¾†æº**: Concept Mapper (Phase 2.2)\n")
        lines.append(f"**ä¿¡åº¦é–¾å€¼**: {min_confidence}\n")
        lines.append("---\n")
        lines.append("åŸºæ–¼èªç¾©ç›¸ä¼¼åº¦åˆ†æï¼Œä»¥ä¸‹é€£çµå¯èƒ½æœ‰åŠ©æ–¼çŸ¥è­˜æ•´åˆã€‚\n")
        lines.append("**ä½¿ç”¨æ–¹æ³•**: è¤‡è£½ Wiki Link æ ¼å¼ `[[æ¦‚å¿µåç¨±]]` ä¸¦è²¼åˆ°ç›¸æ‡‰ç­†è¨˜ä¸­ã€‚\n")

        # éæ¿¾å’Œæ’åºé—œä¿‚
        filtered_relations = [
            rel for rel in relations
            if rel.get('confidence', 0) >= min_confidence  # ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„å­—æ®µå 'confidence'
        ]

        filtered_relations.sort(
            key=lambda r: r.get('confidence', 0),  # ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„å­—æ®µå 'confidence'
            reverse=True
        )

        # ä¿å­˜é«˜ä¿¡åº¦é—œä¿‚ç¸½æ•¸ï¼ˆåœ¨æˆªå–å‰ï¼‰
        high_confidence_count = len(filtered_relations)

        # åªå– top-n
        filtered_relations = filtered_relations[:top_n]

        lines.append(f"\n## ğŸ“Š çµ±è¨ˆ\n")
        lines.append(f"- ç¸½é—œä¿‚æ•¸: {len(relations)}")
        lines.append(f"- é«˜ä¿¡åº¦é—œä¿‚ (â‰¥ {min_confidence}): {high_confidence_count}")  # ä¿®å¾©ï¼šé¡¯ç¤ºçœŸå¯¦ç¸½æ•¸
        lines.append(f"- æœ¬æ–‡æª”é¡¯ç¤º: Top {min(top_n, len(filtered_relations))} å»ºè­°\n")

        # æŒ‰é—œä¿‚é¡å‹åˆ†çµ„
        relation_types = {}
        for rel in filtered_relations:
            rel_type = rel.get('relation_type', 'unknown')
            if rel_type not in relation_types:
                relation_types[rel_type] = []
            relation_types[rel_type].append(rel)

        # ç”Ÿæˆå»ºè­°
        for rel_type, rels in relation_types.items():
            # é—œä¿‚é¡å‹æ¨™é¡Œ
            type_name = {
                'leads_to': 'å°å‘é—œä¿‚ (Leads To)',
                'based_on': 'åŸºæ–¼é—œä¿‚ (Based On)',
                'related_to': 'ç›¸é—œé—œä¿‚ (Related To)',
                'contrasts_with': 'å°æ¯”é—œä¿‚ (Contrasts With)',
                'superclass_of': 'ä¸Šä½é—œä¿‚ (Superclass Of)',
                'subclass_of': 'ä¸‹ä½é—œä¿‚ (Subclass Of)'
            }.get(rel_type, rel_type)

            lines.append(f"\n## {type_name}\n")

            for i, rel in enumerate(rels[:20], 1):  # æ¯é¡æœ€å¤š 20 å€‹
                source_id = rel['source']
                target_id = rel['target']
                confidence = rel.get('confidence', 0)
                similarity = rel.get('similarity', 0)

                source_title = self._get_note_title(source_id)
                target_title = self._get_note_title(target_id)
                # ä»£ç¢¼å€å¡Šä¸­ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼ˆå¸¶åˆ¥åï¼‰
                source_link = self._format_wiki_link(source_id, use_alias=True)
                target_link = self._format_wiki_link(target_id, use_alias=True)

                lines.append(f"### {i}. {source_title} â†’ {target_title}\n")
                lines.append(f"- **ä¿¡åº¦**: {confidence:.2f} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                lines.append(f"- **é—œä¿‚é¡å‹**: `{rel_type}`")
                lines.append(f"- **å»ºè­°æ“ä½œ**:")
                lines.append(f"  ```markdown")
                lines.append(f"  åœ¨ {source_link} ä¸­æ–°å¢: {target_link}")
                lines.append(f"  ```")

                # å¦‚æœæœ‰æ ¸å¿ƒæ¦‚å¿µï¼Œé¡¯ç¤º
                if source_id in self.card_map and self.card_map[source_id]['core_concept']:
                    lines.append(f"- **ä¾†æºæ¦‚å¿µ**: {self.card_map[source_id]['core_concept'][:80]}")
                if target_id in self.card_map and self.card_map[target_id]['core_concept']:
                    lines.append(f"- **ç›®æ¨™æ¦‚å¿µ**: {self.card_map[target_id]['core_concept'][:80]}")

                lines.append("")

        lines.append("\n---\n")
        lines.append("**æç¤º**: é€™äº›å»ºè­°åŸºæ–¼ AI åˆ†æï¼Œè«‹æ ¹æ“šå¯¦éš›æƒ…æ³åˆ¤æ–·æ˜¯å¦æ¡ç´ã€‚\n")

        return "\n".join(lines)

    def export_key_concepts_moc(
        self,
        centralities: List[CentralityScores],
        top_n: int = 20
    ) -> str:
        """ç”Ÿæˆé—œéµæ¦‚å¿µ MOC (Map of Content)

        åƒæ•¸:
            centralities: ä¸­å¿ƒæ€§åˆ†æ•¸åˆ—è¡¨
            top_n: é¡¯ç¤º top-n æ¦‚å¿µ

        è¿”å›:
            Markdown æ ¼å¼çš„ MOC æ–‡æª”
        """
        lines = ["# ğŸ—ºï¸ é—œéµæ¦‚å¿µåœ°åœ– (MOC)\n"]
        lines.append(f"**ç”Ÿæˆæ™‚é–“**: {self._get_timestamp()}\n")
        lines.append(f"**åˆ†æä¾†æº**: Concept Mapper - PageRank åˆ†æ\n")
        lines.append("---\n")
        lines.append("æœ¬åœ°åœ–åˆ—å‡ºçŸ¥è­˜åº«ä¸­æœ€å…·å½±éŸ¿åŠ›çš„æ ¸å¿ƒæ¦‚å¿µï¼ŒåŸºæ–¼ PageRank ç®—æ³•è­˜åˆ¥ã€‚\n")

        # æ’åº
        sorted_centralities = sorted(
            centralities,
            key=lambda c: c.pagerank,
            reverse=True
        )[:top_n]

        lines.append(f"\n## ğŸ“Š Top {top_n} æ ¸å¿ƒæ¦‚å¿µ\n")
        lines.append("| æ’å | æ¦‚å¿µ | PageRank | åº¦ä¸­å¿ƒæ€§ | ä»‹æ•¸ä¸­å¿ƒæ€§ |")
        lines.append("|------|------|----------|----------|-----------|")

        for i, cent in enumerate(sorted_centralities, 1):
            card_id = cent.node_id
            # è¡¨æ ¼ä¸­ä½¿ç”¨ç°¡å–®æ ¼å¼ï¼ˆç„¡åˆ¥åï¼‰é¿å…ç®¡é“ç¬¦è™Ÿå•é¡Œ
            wiki_link = self._format_wiki_link(card_id, use_alias=False)

            lines.append(
                f"| {i} | {wiki_link} | {cent.pagerank:.4f} | "
                f"{cent.degree_centrality:.3f} | {cent.betweenness_centrality:.3f} |"
            )

        # æ·»åŠ èªªæ˜
        lines.append("\n## ğŸ“– æŒ‡æ¨™èªªæ˜\n")
        lines.append("- **PageRank**: æ¦‚å¿µçš„æ•´é«”å½±éŸ¿åŠ›ï¼ˆå€¼è¶Šé«˜è¶Šé‡è¦ï¼‰")
        lines.append("- **åº¦ä¸­å¿ƒæ€§**: èˆ‡å…¶ä»–æ¦‚å¿µçš„é€£æ¥æ•¸ï¼ˆå€¼è¶Šé«˜é€£æ¥è¶Šå¤šï¼‰")
        lines.append("- **ä»‹æ•¸ä¸­å¿ƒæ€§**: ä½œç‚ºæ©‹æ¥æ¦‚å¿µçš„é‡è¦æ€§ï¼ˆå€¼è¶Šé«˜è¶Šé—œéµï¼‰\n")

        # æŒ‰åº¦ä¸­å¿ƒæ€§åˆ†é¡
        lines.append("\n## ğŸŒŸ ä¸åŒé¡å‹çš„æ ¸å¿ƒæ¦‚å¿µ\n")

        # Hub ç¯€é»ï¼ˆé«˜åº¦ä¸­å¿ƒæ€§ï¼‰
        hubs = sorted(sorted_centralities, key=lambda c: c.degree_centrality, reverse=True)[:5]
        lines.append("### Hub ç¯€é»ï¼ˆé«˜åº¦é€£æ¥ï¼‰\n")
        lines.append("é€™äº›æ¦‚å¿µèˆ‡è¨±å¤šå…¶ä»–æ¦‚å¿µç›¸é€£ï¼Œæ˜¯çŸ¥è­˜ç¶²çµ¡çš„ä¸­å¿ƒã€‚\n")
        for hub in hubs:
            # åˆ—è¡¨é …ç›®ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼ˆå¸¶åˆ¥åï¼‰
            wiki_link = self._format_wiki_link(hub.node_id, use_alias=True)
            lines.append(f"- {wiki_link} (åº¦: {hub.degree_centrality:.3f})")

        # Bridge ç¯€é»ï¼ˆé«˜ä»‹æ•¸ä¸­å¿ƒæ€§ï¼‰
        bridges = sorted(sorted_centralities, key=lambda c: c.betweenness_centrality, reverse=True)[:5]
        lines.append("\n### Bridge ç¯€é»ï¼ˆæ©‹æ¥æ¦‚å¿µï¼‰\n")
        lines.append("é€™äº›æ¦‚å¿µé€£æ¥ä¸åŒçš„çŸ¥è­˜é ˜åŸŸï¼Œæ˜¯è·¨é ˜åŸŸæ•´åˆçš„é—œéµã€‚\n")
        for bridge in bridges:
            # åˆ—è¡¨é …ç›®ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼ˆå¸¶åˆ¥åï¼‰
            wiki_link = self._format_wiki_link(bridge.node_id, use_alias=True)
            lines.append(f"- {wiki_link} (ä»‹æ•¸: {bridge.betweenness_centrality:.3f})")

        lines.append("\n---\n")
        lines.append("**ä½¿ç”¨å»ºè­°**: å°‡é€™äº›æ ¸å¿ƒæ¦‚å¿µä½œç‚ºå­¸ç¿’å’Œæ•´ç†çš„èµ·é»ï¼Œå„ªå…ˆå®Œå–„å®ƒå€‘çš„å…§å®¹ã€‚\n")

        return "\n".join(lines)

    def export_community_notes(
        self,
        communities: List[Community],
        max_communities: int = 10
    ) -> Dict[str, str]:
        """ç‚ºæ¯å€‹ç¤¾ç¾¤ç”Ÿæˆæ‘˜è¦ç­†è¨˜

        åƒæ•¸:
            communities: ç¤¾ç¾¤åˆ—è¡¨
            max_communities: æœ€å¤šç”Ÿæˆå¤šå°‘å€‹ç¤¾ç¾¤ç­†è¨˜

        è¿”å›:
            Dict[filename, content]: æ–‡ä»¶ååˆ°å…§å®¹çš„æ˜ å°„
        """
        notes = {}

        # æŒ‰ç¤¾ç¾¤å¤§å°æ’åº
        sorted_communities = sorted(
            communities,
            key=lambda c: c.size,
            reverse=True
        )[:max_communities]

        for comm in sorted_communities:
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨ç¬¬ä¸€å€‹æ ¸å¿ƒæ¦‚å¿µï¼‰
            main_concept = comm.top_concepts[0] if comm.top_concepts else f"ç¤¾ç¾¤{comm.community_id}"
            # æ¸…ç†æ–‡ä»¶åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            safe_name = re.sub(r'[^\w\s-]', '', main_concept)
            safe_name = re.sub(r'[\s]+', '_', safe_name)
            filename = f"Community_{comm.community_id}_{safe_name}.md"

            # ç”Ÿæˆå…§å®¹
            lines = [f"# ğŸ“¦ ç¤¾ç¾¤ {comm.community_id}: {main_concept}\n"]
            lines.append(f"**ç”Ÿæˆæ™‚é–“**: {self._get_timestamp()}\n")
            lines.append(f"**åˆ†æä¾†æº**: Concept Mapper - ç¤¾ç¾¤æª¢æ¸¬ (Louvain ç®—æ³•)\n")
            lines.append("---\n")

            # ç¤¾ç¾¤çµ±è¨ˆ
            lines.append("## ğŸ“Š ç¤¾ç¾¤çµ±è¨ˆ\n")
            lines.append(f"- **ç¯€é»æ•¸**: {comm.size}")
            lines.append(f"- **å¯†åº¦**: {comm.density:.3f}")
            # åˆ—è¡¨é …ç›®ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼ˆå¸¶åˆ¥åï¼‰
            hub_link = self._format_wiki_link(comm.hub_node, use_alias=True)
            lines.append(f"- **ä¸­å¿ƒç¯€é»**: {hub_link}\n")

            # æ ¸å¿ƒæ¦‚å¿µ
            lines.append("## ğŸ”‘ æ ¸å¿ƒæ¦‚å¿µ\n")
            for concept in comm.top_concepts[:10]:
                lines.append(f"- {concept}")

            # æ‰€æœ‰ç¯€é»
            lines.append(f"\n## ğŸ“ æ‰€æœ‰æ¦‚å¿µ ({comm.size} å€‹)\n")

            # æŒ‰å­—æ¯é †åºæ’åˆ—
            sorted_nodes = sorted(comm.nodes, key=lambda nid: self._get_note_title(nid))

            for node_id in sorted_nodes:
                # åˆ—è¡¨é …ç›®ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼ˆå¸¶åˆ¥åï¼‰
                wiki_link = self._format_wiki_link(node_id, use_alias=True)
                lines.append(f"- {wiki_link}")

            lines.append("\n---\n")
            lines.append("**èªªæ˜**: é€™å€‹ç¤¾ç¾¤ä¸­çš„æ¦‚å¿µé€šå¸¸è¨è«–ç›¸åŒæˆ–ç›¸é—œçš„ä¸»é¡Œï¼Œå¯ä»¥ä¸€èµ·å­¸ç¿’å’Œæ•´ç†ã€‚\n")

            notes[filename] = "\n".join(lines)

        return notes

    def export_path_analysis(
        self,
        paths: List[ConceptPath],
        top_n: int = 10
    ) -> str:
        """ç”Ÿæˆè·¯å¾‘åˆ†ææ–‡æª”

        åƒæ•¸:
            paths: æ¦‚å¿µè·¯å¾‘åˆ—è¡¨
            top_n: é¡¯ç¤º top-n è·¯å¾‘

        è¿”å›:
            Markdown æ ¼å¼çš„è·¯å¾‘åˆ†ææ–‡æª”
        """
        lines = ["# ğŸ›¤ï¸ æ¦‚å¿µæ¨å°è·¯å¾‘åˆ†æ\n"]
        lines.append(f"**ç”Ÿæˆæ™‚é–“**: {self._get_timestamp()}\n")
        lines.append(f"**åˆ†æä¾†æº**: Concept Mapper - è·¯å¾‘åˆ†æ\n")
        lines.append("---\n")
        lines.append("ä»¥ä¸‹è·¯å¾‘å±•ç¤ºæ¦‚å¿µä¹‹é–“çš„æ¨å°å’Œæ¼”åŒ–é—œä¿‚ã€‚\n")

        if not paths:
            lines.append("\nâš ï¸ æœªæ‰¾åˆ°æœ‰å½±éŸ¿åŠ›çš„è·¯å¾‘ã€‚\n")
            lines.append("é€™å¯èƒ½æ˜¯å› ç‚ºï¼š\n")
            lines.append("- çŸ¥è­˜åº«æ˜¯ä¸€å€‹é«˜åº¦é€£æ¥çš„å–®ä¸€ç¤¾ç¾¤\n")
            lines.append("- Hub ç¯€é»ä¹‹é–“ç›´æ¥é€£æ¥ï¼Œç„¡éœ€ä¸­é–“è·¯å¾‘\n")
            return "\n".join(lines)

        # æ’åºè·¯å¾‘ï¼ˆæŒ‰ä¿¡åº¦ï¼‰
        sorted_paths = sorted(
            paths,
            key=lambda p: p.confidence,
            reverse=True
        )[:top_n]

        lines.append(f"\n## ğŸ“Š Top {len(sorted_paths)} æœ‰å½±éŸ¿åŠ›çš„è·¯å¾‘\n")

        for i, path in enumerate(sorted_paths, 1):
            start_title = self._get_note_title(path.start_node)
            end_title = self._get_note_title(path.end_node)

            lines.append(f"### {i}. {start_title} â” {end_title}\n")
            lines.append(f"- **è·¯å¾‘é•·åº¦**: {path.length}")
            lines.append(f"- **å¹³å‡ä¿¡åº¦**: {path.confidence:.2f}\n")
            lines.append("**æ¨å°è·¯å¾‘**:\n")
            lines.append("```")

            # ç”Ÿæˆè·¯å¾‘å¯è¦–åŒ–
            path_titles = [self._get_note_title(nid) for nid in path.path]
            lines.append(" â†’ ".join(path_titles))
            lines.append("```\n")

            # è©³ç´°ç¯€é»åˆ—è¡¨
            lines.append("**ç¯€é»è©³æƒ…**:\n")
            for j, node_id in enumerate(path.path, 1):
                # åˆ—è¡¨é …ç›®ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼ˆå¸¶åˆ¥åï¼‰
                wiki_link = self._format_wiki_link(node_id, use_alias=True)
                lines.append(f"{j}. {wiki_link}")

            lines.append("")

        lines.append("\n---\n")
        lines.append("**ä½¿ç”¨å»ºè­°**: é€™äº›è·¯å¾‘å¯ä»¥å¹«åŠ©ç†è§£æ¦‚å¿µä¹‹é–“çš„é‚è¼¯é€£æ¥å’Œæ¼”åŒ–é—œä¿‚ã€‚\n")

        return "\n".join(lines)

    def export_all(
        self,
        analysis_results: Dict,
        output_dir: str,
        options: Optional[Dict] = None
    ):
        """å°å‡ºæ‰€æœ‰ Obsidian å‹å¥½çš„åˆ†æçµæœ

        åƒæ•¸:
            analysis_results: åˆ†æçµæœå­—å…¸ï¼ŒåŒ…å«:
                - relations: List[Dict]
                - centralities: List[CentralityScores]
                - communities: List[Community]
                - paths: List[ConceptPath]
            output_dir: è¼¸å‡ºç›®éŒ„
            options: å¯é¸é…ç½®ï¼ŒåŒ…å«:
                - suggested_links_top_n: int (é»˜èª 50)
                - suggested_links_min_confidence: float (é»˜èª 0.4ï¼Œæ¨è–¦ 0.3-0.5)
                - moc_top_n: int (é»˜èª 20)
                - max_communities: int (é»˜èª 10)
                - path_top_n: int (é»˜èª 10)
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # é»˜èªé¸é …
        if options is None:
            options = {}

        print("\n" + "="*70)
        print("ğŸ“¤ å°å‡º Obsidian å‹å¥½æ ¼å¼")
        print("="*70)

        # 1. å»ºè­°é€£çµ
        print("\n[1] ç”Ÿæˆå»ºè­°é€£çµ...")
        suggested_links = self.export_suggested_links(
            relations=analysis_results.get('relations', []),
            top_n=options.get('suggested_links_top_n', 50),
            min_confidence=options.get('suggested_links_min_confidence', 0.4)
        )
        links_path = output_path / "suggested_links.md"
        links_path.write_text(suggested_links, encoding='utf-8')
        print(f"   âœ… {links_path}")

        # 2. é—œéµæ¦‚å¿µ MOC
        print("\n[2] ç”Ÿæˆé—œéµæ¦‚å¿µåœ°åœ–...")
        moc = self.export_key_concepts_moc(
            centralities=analysis_results.get('centralities', []),
            top_n=options.get('moc_top_n', 20)
        )
        moc_path = output_path / "key_concepts_moc.md"
        moc_path.write_text(moc, encoding='utf-8')
        print(f"   âœ… {moc_path}")

        # 3. ç¤¾ç¾¤æ‘˜è¦
        print("\n[3] ç”Ÿæˆç¤¾ç¾¤æ‘˜è¦ç­†è¨˜...")
        comm_dir = output_path / "community_summaries"
        comm_dir.mkdir(exist_ok=True)

        community_notes = self.export_community_notes(
            communities=analysis_results.get('communities', []),
            max_communities=options.get('max_communities', 10)
        )

        for filename, content in community_notes.items():
            note_path = comm_dir / filename
            note_path.write_text(content, encoding='utf-8')
            print(f"   âœ… {note_path}")

        # 4. è·¯å¾‘åˆ†æ
        print("\n[4] ç”Ÿæˆè·¯å¾‘åˆ†æ...")
        path_analysis = self.export_path_analysis(
            paths=analysis_results.get('paths', []),
            top_n=options.get('path_top_n', 10)
        )
        path_path = output_path / "path_analysis.md"
        path_path.write_text(path_analysis, encoding='utf-8')
        print(f"   âœ… {path_path}")

        # 5. ç”Ÿæˆç´¢å¼•æ–‡ä»¶
        print("\n[5] ç”Ÿæˆç´¢å¼•æ–‡ä»¶...")
        index_content = self._generate_index(output_path, analysis_results)
        index_path = output_path / "README.md"
        index_path.write_text(index_content, encoding='utf-8')
        print(f"   âœ… {index_path}")

        print("\n" + "="*70)
        print(f"âœ… Obsidian è¼¸å‡ºå®Œæˆï¼")
        print(f"   è¼¸å‡ºç›®éŒ„: {output_path}")
        print("="*70 + "\n")

    def _generate_index(self, output_path: Path, analysis_results: Dict) -> str:
        """ç”Ÿæˆç´¢å¼•æ–‡ä»¶

        åƒæ•¸:
            output_path: è¼¸å‡ºç›®éŒ„
            analysis_results: åˆ†æçµæœ

        è¿”å›:
            ç´¢å¼•æ–‡ä»¶çš„ Markdown å…§å®¹
        """
        lines = ["# ğŸ“Š Concept Mapper åˆ†æçµæœç´¢å¼•\n"]
        lines.append(f"**ç”Ÿæˆæ™‚é–“**: {self._get_timestamp()}\n")
        lines.append(f"**çŸ¥è­˜åº«**: {self.kb_path}\n")
        lines.append("---\n")

        lines.append("## ğŸ“ æ–‡ä»¶åˆ—è¡¨\n")
        lines.append("### æ ¸å¿ƒæ–‡ä»¶\n")
        lines.append("1. **[[suggested_links]]** - å»ºè­°æ–°å¢çš„æ¦‚å¿µé€£çµ")
        lines.append("   - åŸºæ–¼èªç¾©ç›¸ä¼¼åº¦çš„æ™ºèƒ½æ¨è–¦")
        lines.append("   - åŒ…å«é—œä¿‚é¡å‹å’Œä¿¡åº¦è©•åˆ†\n")

        lines.append("2. **[[key_concepts_moc]]** - é—œéµæ¦‚å¿µåœ°åœ–")
        lines.append("   - Top 20 æ ¸å¿ƒæ¦‚å¿µ (åŸºæ–¼ PageRank)")
        lines.append("   - Hub ç¯€é»å’Œ Bridge ç¯€é»åˆ†æ\n")

        lines.append("3. **[[path_analysis]]** - æ¦‚å¿µæ¨å°è·¯å¾‘")
        lines.append("   - æœ‰å½±éŸ¿åŠ›çš„æ¦‚å¿µæ¼”åŒ–è·¯å¾‘")
        lines.append("   - å¹«åŠ©ç†è§£æ¦‚å¿µé–“çš„é‚è¼¯é—œä¿‚\n")

        lines.append("### ç¤¾ç¾¤æ‘˜è¦\n")
        lines.append("- ğŸ“‚ [[community_summaries/]] - ç¤¾ç¾¤æª¢æ¸¬çµæœ")

        comm_count = len(analysis_results.get('communities', []))
        lines.append(f"  - æª¢æ¸¬åˆ° {comm_count} å€‹æ¦‚å¿µç¤¾ç¾¤")
        lines.append(f"  - æ¯å€‹ç¤¾ç¾¤å°æ‡‰ä¸€å€‹æ‘˜è¦ç­†è¨˜\n")

        # çµ±è¨ˆä¿¡æ¯
        lines.append("## ğŸ“Š çµ±è¨ˆæ‘˜è¦\n")

        network_stats = analysis_results.get('network_statistics', {})
        lines.append(f"- **ç¯€é»æ•¸**: {network_stats.get('node_count', 0)}")
        lines.append(f"- **é‚Šæ•¸**: {network_stats.get('edge_count', 0)}")
        lines.append(f"- **å¹³å‡åº¦**: {network_stats.get('avg_degree', 0):.2f}")
        lines.append(f"- **ç¶²çµ¡å¯†åº¦**: {network_stats.get('density', 0):.4f}")
        lines.append(f"- **ç¤¾ç¾¤æ•¸**: {comm_count}\n")

        # é—œä¿‚é¡å‹åˆ†å¸ƒ
        if 'relation_type_counts' in network_stats:
            lines.append("### é—œä¿‚é¡å‹åˆ†å¸ƒ\n")
            for rel_type, count in network_stats['relation_type_counts'].items():
                lines.append(f"- `{rel_type}`: {count}")

        lines.append("\n## ğŸš€ ä½¿ç”¨æŒ‡å—\n")
        lines.append("1. å¾ **key_concepts_moc** é–‹å§‹ï¼Œäº†è§£æ ¸å¿ƒæ¦‚å¿µ")
        lines.append("2. æŸ¥çœ‹ **suggested_links**ï¼Œè£œå……é€£çµåˆ°ä½ çš„ç­†è¨˜")
        lines.append("3. ç€è¦½ **community_summaries**ï¼Œç†è§£çŸ¥è­˜çµæ§‹")
        lines.append("4. æ¢ç´¢ **path_analysis**ï¼Œç™¼ç¾æ¦‚å¿µæ¼”åŒ–è·¯å¾‘\n")

        lines.append("---\n")
        lines.append("**å·¥å…·**: [Concept Mapper](https://github.com/your-repo) Phase 2.2\n")

        return "\n".join(lines)


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    # ç°¡å–®æ¸¬è©¦
    exporter = ObsidianExporter()
    print(f"âœ… ObsidianExporter åˆå§‹åŒ–å®Œæˆ")
    print(f"   å¡ç‰‡æ•¸: {len(exporter.card_map)}")
