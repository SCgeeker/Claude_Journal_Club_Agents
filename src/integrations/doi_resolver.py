#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DOI è§£æèˆ‡æŸ¥è©¢æ¨¡çµ„

åŠŸèƒ½ï¼š
- å¾ PDF æ–‡æœ¬/å…ƒæ•¸æ“šæå– DOI
- ä½¿ç”¨ CrossRef API æŸ¥è©¢å…ƒæ•¸æ“š
- ç”Ÿæˆ citekey å»ºè­°
"""

import re
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field

import requests


@dataclass
class DOIMetadata:
    """DOI å…ƒæ•¸æ“šçµæ§‹"""
    doi: str
    title: str
    authors: List[str] = field(default_factory=list)
    year: Optional[int] = None
    journal: Optional[str] = None
    publisher: Optional[str] = None
    volume: Optional[str] = None
    issue: Optional[str] = None
    pages: Optional[str] = None
    abstract: Optional[str] = None
    subject: List[str] = field(default_factory=list)  # å­¸ç§‘åˆ†é¡
    url: Optional[str] = None
    issn: Optional[str] = None
    isbn: Optional[str] = None
    type: Optional[str] = None  # journal-article, book, etc.

    # ç”Ÿæˆçš„ citekey
    suggested_citekey: Optional[str] = None

    def to_dict(self) -> Dict:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'doi': self.doi,
            'title': self.title,
            'authors': self.authors,
            'year': self.year,
            'journal': self.journal,
            'publisher': self.publisher,
            'volume': self.volume,
            'issue': self.issue,
            'pages': self.pages,
            'abstract': self.abstract,
            'subject': self.subject,
            'url': self.url,
            'type': self.type,
            'suggested_citekey': self.suggested_citekey,
        }


class DOIResolver:
    """
    DOI è§£æèˆ‡å…ƒæ•¸æ“šæŸ¥è©¢

    ä½¿ç”¨ CrossRef API (https://api.crossref.org)
    """

    # CrossRef API ç«¯é»
    CROSSREF_API = "https://api.crossref.org/works"

    # DOI æ­£å‰‡è¡¨é”å¼æ¨¡å¼
    DOI_PATTERNS = [
        # æ¨™æº– DOI æ ¼å¼
        r'(?:doi[:\s]*)?(?:https?://(?:dx\.)?doi\.org/)?'
        r'(10\.\d{4,}/[^\s\]\)>"\';,]+)',
        # DOI åœ¨æ‹¬è™Ÿæˆ–å¼•è™Ÿä¸­
        r'DOI[:\s]+(10\.\d{4,}/[^\s\]\)>"\';,]+)',
    ]

    def __init__(self, email: Optional[str] = None, timeout: int = 30):
        """
        åˆå§‹åŒ– DOI è§£æå™¨

        Args:
            email: è¯ç¹«éƒµç®±ï¼ˆCrossRef å»ºè­°æä¾›ï¼Œå¯ç²å¾—æ›´å¥½çš„æœå‹™ï¼‰
            timeout: è«‹æ±‚è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.email = email
        self.timeout = timeout
        self.session = requests.Session()

        # è¨­ç½® User-Agentï¼ˆCrossRef è¦æ±‚ï¼‰
        user_agent = "claude-lit-workflow/0.8.0"
        if email:
            user_agent += f" (mailto:{email})"
        self.session.headers.update({
            'User-Agent': user_agent
        })

        # é€Ÿç‡é™åˆ¶ï¼ˆCrossRef é™åˆ¶ï¼š50 req/secï¼‰
        self._last_request_time = 0
        self._min_interval = 0.1  # 100ms é–“éš”

    def extract_doi_from_text(self, text: str) -> List[str]:
        """
        å¾æ–‡æœ¬ä¸­æå– DOI

        Args:
            text: æ–‡æœ¬å…§å®¹ï¼ˆPDF æ–‡æœ¬ã€å…ƒæ•¸æ“šç­‰ï¼‰

        Returns:
            æ‰¾åˆ°çš„ DOI åˆ—è¡¨ï¼ˆå»é‡ï¼‰
        """
        dois = set()

        for pattern in self.DOI_PATTERNS:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                # æ¸…ç† DOI
                doi = self._clean_doi(match)
                if doi:
                    dois.add(doi)

        return list(dois)

    def extract_doi_from_pdf(self, pdf_path: Path) -> Optional[str]:
        """
        å¾ PDF æ–‡ä»¶æå– DOI

        å˜—è©¦é †åºï¼š
        1. PDF å…ƒæ•¸æ“š
        2. ç¬¬ä¸€é æ–‡æœ¬

        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾‘

        Returns:
            æ‰¾åˆ°çš„ DOIï¼Œæœªæ‰¾åˆ°è¿”å› None
        """
        try:
            import pdfplumber
        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£ pdfplumber: pip install pdfplumber")
            return None

        try:
            with pdfplumber.open(pdf_path) as pdf:
                # 1. æª¢æŸ¥ PDF å…ƒæ•¸æ“š
                metadata = pdf.metadata or {}
                for key in ['doi', 'DOI', 'Subject', 'Keywords']:
                    if key in metadata and metadata[key]:
                        dois = self.extract_doi_from_text(str(metadata[key]))
                        if dois:
                            return dois[0]

                # 2. æª¢æŸ¥ç¬¬ä¸€é æ–‡æœ¬
                if pdf.pages:
                    first_page = pdf.pages[0]
                    text = first_page.extract_text() or ""
                    # åªæª¢æŸ¥å‰ 2000 å­—å…ƒï¼ˆé€šå¸¸ DOI åœ¨é ­éƒ¨ï¼‰
                    dois = self.extract_doi_from_text(text[:2000])
                    if dois:
                        return dois[0]

        except Exception as e:
            print(f"âš ï¸  PDF DOI æå–å¤±æ•—: {e}")

        return None

    def resolve(self, doi: str) -> Optional[DOIMetadata]:
        """
        å¾ CrossRef æŸ¥è©¢ DOI å…ƒæ•¸æ“š

        Args:
            doi: DOI å­—ä¸²

        Returns:
            DOIMetadata å°è±¡ï¼ŒæŸ¥è©¢å¤±æ•—è¿”å› None
        """
        doi = self._clean_doi(doi)
        if not doi:
            return None

        # é€Ÿç‡é™åˆ¶
        self._rate_limit()

        try:
            url = f"{self.CROSSREF_API}/{doi}"
            response = self.session.get(url, timeout=self.timeout)

            if response.status_code == 404:
                print(f"âš ï¸  DOI æœªæ‰¾åˆ°: {doi}")
                return None

            response.raise_for_status()
            data = response.json()

            if data.get('status') != 'ok':
                return None

            return self._parse_crossref_response(data['message'])

        except requests.exceptions.Timeout:
            print(f"âš ï¸  CrossRef è«‹æ±‚è¶…æ™‚: {doi}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸  CrossRef è«‹æ±‚å¤±æ•—: {e}")
            return None
        except Exception as e:
            print(f"âš ï¸  DOI è§£æéŒ¯èª¤: {e}")
            return None

    def resolve_batch(
        self,
        dois: List[str],
        delay: float = 0.2
    ) -> Dict[str, Optional[DOIMetadata]]:
        """
        æ‰¹æ¬¡æŸ¥è©¢å¤šå€‹ DOI

        Args:
            dois: DOI åˆ—è¡¨
            delay: æ¯æ¬¡è«‹æ±‚é–“éš”ï¼ˆç§’ï¼‰

        Returns:
            DOI -> DOIMetadata å­—å…¸
        """
        results = {}

        for i, doi in enumerate(dois):
            print(f"  [{i+1}/{len(dois)}] æŸ¥è©¢ {doi}...", end=" ")
            result = self.resolve(doi)
            results[doi] = result

            if result:
                print(f"âœ“ {result.title[:40]}...")
            else:
                print("âœ—")

            if i < len(dois) - 1:
                time.sleep(delay)

        return results

    def _clean_doi(self, doi: str) -> Optional[str]:
        """
        æ¸…ç† DOI å­—ä¸²

        ç§»é™¤ URL å‰ç¶´ã€ç©ºç™½ã€å°¾éƒ¨æ¨™é»ç¬¦è™Ÿ
        """
        if not doi:
            return None

        # ç§»é™¤ URL å‰ç¶´
        doi = re.sub(r'^https?://(?:dx\.)?doi\.org/', '', doi)
        doi = re.sub(r'^doi[:\s]*', '', doi, flags=re.IGNORECASE)

        # ç§»é™¤ç©ºç™½
        doi = doi.strip()

        # ç§»é™¤å°¾éƒ¨æ¨™é»ç¬¦è™Ÿï¼ˆä½†ä¿ç•™ DOI ä¸­å¯èƒ½çš„æœ‰æ•ˆå­—å…ƒï¼‰
        doi = re.sub(r'[\s.,;:)\]>"\']+$', '', doi)

        # é©—è­‰ DOI æ ¼å¼
        if not re.match(r'^10\.\d{4,}/', doi):
            return None

        return doi

    def _parse_crossref_response(self, data: Dict) -> DOIMetadata:
        """
        è§£æ CrossRef API å›æ‡‰

        Args:
            data: CrossRef å›æ‡‰çš„ message éƒ¨åˆ†

        Returns:
            DOIMetadata å°è±¡
        """
        # DOI
        doi = data.get('DOI', '')

        # æ¨™é¡Œ
        title_list = data.get('title', [])
        title = title_list[0] if title_list else ''

        # ä½œè€…
        authors = []
        for author in data.get('author', []):
            if 'family' in author:
                name = author.get('family', '')
                if 'given' in author:
                    name = f"{author['given']} {name}"
                authors.append(name)

        # å¹´ä»½
        year = None
        date_parts = data.get('published-print', {}).get('date-parts', [[]])
        if not date_parts[0]:
            date_parts = data.get('published-online', {}).get('date-parts', [[]])
        if date_parts and date_parts[0]:
            year = date_parts[0][0]

        # æœŸåˆŠ
        container = data.get('container-title', [])
        journal = container[0] if container else None

        # å‡ºç‰ˆç¤¾
        publisher = data.get('publisher')

        # å·/æœŸ/é 
        volume = data.get('volume')
        issue = data.get('issue')
        pages = data.get('page')

        # æ‘˜è¦
        abstract = data.get('abstract', '')
        if abstract:
            # ç§»é™¤ jats æ¨™ç±¤
            abstract = re.sub(r'<[^>]+>', '', abstract)
            abstract = abstract.strip()

        # å­¸ç§‘
        subject = data.get('subject', [])

        # URL
        url = data.get('URL')

        # é¡å‹
        doc_type = data.get('type')

        # ç”Ÿæˆ citekey
        suggested_citekey = self._generate_citekey(authors, year)

        return DOIMetadata(
            doi=doi,
            title=title,
            authors=authors,
            year=year,
            journal=journal,
            publisher=publisher,
            volume=volume,
            issue=issue,
            pages=pages,
            abstract=abstract if len(abstract) > 10 else None,
            subject=subject,
            url=url,
            type=doc_type,
            suggested_citekey=suggested_citekey
        )

    def _generate_citekey(
        self,
        authors: List[str],
        year: Optional[int]
    ) -> Optional[str]:
        """
        å¾ä½œè€…å’Œå¹´ä»½ç”Ÿæˆ citekey

        æ ¼å¼: FirstAuthorLastName-Year
        """
        if not authors:
            return None

        # æå–ç¬¬ä¸€ä½œè€…å§“æ°
        first_author = authors[0]
        # è™•ç† "First Last" æ ¼å¼
        parts = first_author.split()
        last_name = parts[-1] if parts else first_author

        # ç§»é™¤ç‰¹æ®Šå­—å…ƒ
        last_name = re.sub(r'[^\w]', '', last_name)

        if year:
            return f"{last_name}-{year}"
        else:
            return last_name

    def _rate_limit(self):
        """é€Ÿç‡é™åˆ¶"""
        now = time.time()
        elapsed = now - self._last_request_time
        if elapsed < self._min_interval:
            time.sleep(self._min_interval - elapsed)
        self._last_request_time = time.time()


def main():
    """æ¸¬è©¦ DOI è§£æå™¨"""
    import sys
    import io

    # ä¿®å¾© Windows çµ‚ç«¯ UTF-8 ç·¨ç¢¼
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    resolver = DOIResolver()

    print("=" * 60)
    print("DOI Resolver æ¸¬è©¦")
    print("=" * 60)

    # æ¸¬è©¦ DOI
    test_dois = [
        "10.1017/S0140525X99002149",  # Barsalou 1999
        "10.1037/a0024587",           # å¿ƒç†å­¸è«–æ–‡
        "https://doi.org/10.1038/nature12373",  # Nature
    ]

    for doi in test_dois:
        print(f"\nğŸ” æŸ¥è©¢: {doi}")
        result = resolver.resolve(doi)

        if result:
            print(f"   âœ… æ¨™é¡Œ: {result.title[:60]}...")
            print(f"   ä½œè€…: {', '.join(result.authors[:3])}")
            print(f"   å¹´ä»½: {result.year}")
            print(f"   æœŸåˆŠ: {result.journal or 'N/A'}")
            print(f"   å»ºè­° citekey: {result.suggested_citekey}")
        else:
            print("   âŒ æœªæ‰¾åˆ°")

    # æ¸¬è©¦ DOI æå–
    print("\n" + "-" * 60)
    print("DOI æå–æ¸¬è©¦")
    print("-" * 60)

    test_texts = [
        "This paper (doi:10.1037/a0024587) discusses...",
        "Available at https://doi.org/10.1038/nature12373",
        "DOI: 10.1016/j.cognition.2020.104328",
    ]

    for text in test_texts:
        dois = resolver.extract_doi_from_text(text)
        print(f"\n   æ–‡æœ¬: {text[:50]}...")
        print(f"   æå–: {dois}")

    print("\n" + "=" * 60)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    main()
