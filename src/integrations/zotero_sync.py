#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZoteroSync - Zotero åˆ°çŸ¥è­˜åº«çš„åŒæ­¥æ¡†æ¶
æ•´åˆ BibTeX è§£æã€PDF åŒ¹é…ã€å»é‡å’Œæ‰¹é‡å°å…¥åŠŸèƒ½
"""

import sys
import io
import json
import sqlite3
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from difflib import SequenceMatcher
from datetime import datetime

# ä¿®å¾© Windows çµ‚ç«¯ UTF-8 ç·¨ç¢¼
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# æ¢ä»¶å¼å°å…¥
try:
    from .bibtex_parser import BibTeXParser, BibTeXEntry
    from .zotero_scanner import ZoteroScanner, PDFFile
except ImportError:
    from src.integrations.bibtex_parser import BibTeXParser, BibTeXEntry
    from src.integrations.zotero_scanner import ZoteroScanner, PDFFile


@dataclass
class SyncConflict:
    """åŒæ­¥è¡çªè¨˜éŒ„"""
    zotero_entry: BibTeXEntry
    kb_paper: Dict
    conflict_type: str  # 'duplicate', 'similar', 'metadata_mismatch'
    similarity_score: float
    resolution: str  # 'skip', 'replace', 'merge', 'manual_review'
    reason: str


@dataclass
class SyncResult:
    """åŒæ­¥çµæœçµ±è¨ˆ"""
    total_bibtex_entries: int
    successful_imports: int
    skipped_duplicates: int
    conflicts: List[SyncConflict]
    errors: List[Tuple[str, str]]  # (entry_key, error_message)
    import_list: List[Dict]  # å¯¦éš›å°å…¥çš„è«–æ–‡åˆ—è¡¨
    timestamp: str


class ZoteroSync:
    """
    Zotero åˆ°çŸ¥è­˜åº«çš„åŒæ­¥æ ¸å¿ƒé¡

    å·¥ä½œæµç¨‹ï¼š
    1. parse_bibtex() - è§£æ Zotero BibTeX å°å‡ºæª”æ¡ˆ
    2. match_with_kb() - èˆ‡ç¾æœ‰çŸ¥è­˜åº«é€²è¡ŒåŒ¹é…ï¼Œæª¢æ¸¬é‡è¤‡
    3. resolve_conflicts() - è™•ç†è¡çªå’Œå»é‡
    4. batch_import() - æ‰¹é‡å°å…¥åˆ°çŸ¥è­˜åº«
    """

    def __init__(self, kb_path: str = "knowledge_base"):
        """
        åˆå§‹åŒ– ZoteroSync

        Args:
            kb_path: çŸ¥è­˜åº«è·¯å¾‘ï¼ˆé è¨­: "knowledge_base"ï¼‰
        """
        self.kb_path = Path(kb_path)
        self.db_path = self.kb_path / "index.db"

        # é©—è­‰çŸ¥è­˜åº«
        if not self.kb_path.exists():
            raise FileNotFoundError(f"çŸ¥è­˜åº«è·¯å¾‘ä¸å­˜åœ¨: {kb_path}")
        if not self.db_path.exists():
            raise FileNotFoundError(f"çŸ¥è­˜åº«æ•¸æ“šåº«ä¸å­˜åœ¨: {self.db_path}")

        # åˆå§‹åŒ–
        self.parser = BibTeXParser()
        self.bibtex_entries: List[BibTeXEntry] = []
        self.kb_papers: List[Dict] = []
        self.conflicts: List[SyncConflict] = []
        self.errors: List[Tuple[str, str]] = []

    # ==================== ç¬¬1æ­¥: è§£æ BibTeX ====================

    def parse_bibtex(self, bib_file: str) -> List[BibTeXEntry]:
        """
        è§£æ Zotero å°å‡ºçš„ BibTeX æ–‡ä»¶

        Args:
            bib_file: .bib æ–‡ä»¶è·¯å¾‘

        Returns:
            BibTeXEntry å°è±¡åˆ—è¡¨

        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            ValueError: è§£æå¤±æ•—
        """
        bib_path = Path(bib_file)
        if not bib_path.exists():
            raise FileNotFoundError(f"BibTeX æ–‡ä»¶ä¸å­˜åœ¨: {bib_file}")

        print(f"ğŸ“š è§£æ BibTeX æ–‡ä»¶: {bib_file}")

        try:
            self.bibtex_entries = self.parser.parse_file(bib_file)
            print(f"âœ… æˆåŠŸè§£æ {len(self.bibtex_entries)} å€‹æ¢ç›®")
            return self.bibtex_entries
        except Exception as e:
            print(f"âŒ è§£æå¤±æ•—: {e}")
            raise

    # ==================== ç¬¬2æ­¥: å¾çŸ¥è­˜åº«è®€å–ç¾æœ‰è«–æ–‡ ====================

    def load_kb_papers(self) -> List[Dict]:
        """
        å¾çŸ¥è­˜åº«æ•¸æ“šåº«è®€å–ç¾æœ‰è«–æ–‡

        Returns:
            è«–æ–‡åˆ—è¡¨ï¼ˆåŒ…å« title, authors, year, keywords ç­‰ï¼‰
        """
        print(f"ğŸ“– å¾çŸ¥è­˜åº«è®€å–ç¾æœ‰è«–æ–‡...")

        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æŸ¥è©¢è«–æ–‡åŸºæœ¬ä¿¡æ¯
            cursor.execute("""
                SELECT id, title, authors, year, keywords, file_path
                FROM papers
                ORDER BY id DESC
            """)

            rows = cursor.fetchall()
            self.kb_papers = [dict(row) for row in rows]

            conn.close()

            print(f"âœ… è®€å– {len(self.kb_papers)} ç¯‡ç¾æœ‰è«–æ–‡")
            return self.kb_papers

        except Exception as e:
            print(f"âš ï¸  è®€å–çŸ¥è­˜åº«å¤±æ•—: {e}")
            self.kb_papers = []
            return []

    # ==================== ç¬¬3æ­¥: èˆ‡çŸ¥è­˜åº«åŒ¹é… ====================

    def match_with_kb(self, threshold: float = 0.8) -> Dict[str, Any]:
        """
        å°‡ BibTeX æ¢ç›®èˆ‡çŸ¥è­˜åº«é€²è¡ŒåŒ¹é…ï¼Œæª¢æ¸¬é‡è¤‡

        åŒ¹é…ç­–ç•¥ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰ï¼š
        1. ç²¾ç¢ºæ¨™é¡ŒåŒ¹é…
        2. ç›¸ä¼¼æ¨™é¡ŒåŒ¹é…ï¼ˆ>thresholdï¼‰
        3. ä½œè€…+å¹´ä»½çµ„åˆåŒ¹é…

        Args:
            threshold: æ¨™é¡Œç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­: 0.8ï¼‰

        Returns:
            åŒ¹é…çµæœçµ±è¨ˆå­—å…¸
        """
        print(f"ğŸ”— èˆ‡çŸ¥è­˜åº«é€²è¡ŒåŒ¹é… (ç›¸ä¼¼åº¦é–¾å€¼: {threshold})...")

        if not self.bibtex_entries:
            print("âŒ æœªè¼‰å…¥ BibTeX æ¢ç›®")
            return {'duplicates': [], 'new_entries': []}

        if not self.kb_papers:
            print("âš ï¸  çŸ¥è­˜åº«ç‚ºç©ºï¼Œå…¨éƒ¨ä½œç‚ºæ–°æ¢ç›®")
            return {
                'duplicates': [],
                'new_entries': [(i, e) for i, e in enumerate(self.bibtex_entries)]
            }

        duplicates = []
        new_entries = []

        # å»ºç«‹çŸ¥è­˜åº«æ¨™é¡Œç´¢å¼•ï¼ˆå¿«é€ŸæŸ¥æ‰¾ï¼‰
        kb_titles_lower = {
            p['title'].lower().strip(): p
            for p in self.kb_papers if p.get('title')
        }

        for i, bibtex_entry in enumerate(self.bibtex_entries):
            entry_title = bibtex_entry.title.lower().strip()

            # æ–¹æ³•1: ç²¾ç¢ºæ¨™é¡ŒåŒ¹é…
            if entry_title in kb_titles_lower:
                kb_paper = kb_titles_lower[entry_title]
                duplicates.append({
                    'index': i,
                    'bibtex_entry': bibtex_entry,
                    'kb_paper': kb_paper,
                    'match_type': 'exact_title',
                    'score': 1.0
                })
                continue

            # æ–¹æ³•2: ç›¸ä¼¼æ¨™é¡ŒåŒ¹é…
            best_match = self._find_best_title_match(
                entry_title,
                self.kb_papers,
                threshold
            )

            if best_match:
                kb_paper, score = best_match
                duplicates.append({
                    'index': i,
                    'bibtex_entry': bibtex_entry,
                    'kb_paper': kb_paper,
                    'match_type': 'similar_title',
                    'score': score
                })
                continue

            # æ–¹æ³•3: ä½œè€…+å¹´ä»½åŒ¹é…
            if bibtex_entry.authors and bibtex_entry.year:
                author_year_match = self._find_by_author_year(
                    bibtex_entry.authors,
                    bibtex_entry.year,
                    self.kb_papers
                )

                if author_year_match:
                    kb_paper, score = author_year_match
                    duplicates.append({
                        'index': i,
                        'bibtex_entry': bibtex_entry,
                        'kb_paper': kb_paper,
                        'match_type': 'author_year',
                        'score': score
                    })
                    continue

            # ç„¡åŒ¹é…ï¼Œä½œç‚ºæ–°æ¢ç›®
            new_entries.append((i, bibtex_entry))

        print(f"âœ… åŒ¹é…å®Œæˆ:")
        print(f"   - æª¢æ¸¬åˆ°é‡è¤‡: {len(duplicates)} ç¯‡")
        print(f"   - æ–°æ¢ç›®: {len(new_entries)} ç¯‡")

        return {
            'duplicates': duplicates,
            'new_entries': new_entries,
            'total_bibtex': len(self.bibtex_entries),
            'total_kb': len(self.kb_papers)
        }

    def _find_best_title_match(
        self,
        title: str,
        papers: List[Dict],
        threshold: float
    ) -> Optional[Tuple[Dict, float]]:
        """æŸ¥æ‰¾æœ€ä½³æ¨™é¡ŒåŒ¹é…"""
        best_match = None
        best_score = 0

        for paper in papers:
            paper_title = paper.get('title', '').lower().strip()
            if not paper_title:
                continue

            score = SequenceMatcher(None, title, paper_title).ratio()

            if score > best_score and score >= threshold:
                best_score = score
                best_match = paper

        if best_match:
            return (best_match, best_score)
        return None

    def _find_by_author_year(
        self,
        authors: List[str],
        year: int,
        papers: List[Dict]
    ) -> Optional[Tuple[Dict, float]]:
        """æ ¹æ“šä½œè€…å’Œå¹´ä»½æŸ¥æ‰¾åŒ¹é…"""
        candidates = []

        for paper in papers:
            # å¹´ä»½å¿…é ˆåŒ¹é…
            if paper.get('year') != year:
                continue

            # æª¢æŸ¥ä½œè€…
            paper_authors = paper.get('authors', [])
            if isinstance(paper_authors, str):
                paper_authors = [a.strip() for a in paper_authors.split(';')]

            if not paper_authors:
                continue

            # è¨ˆç®—ä½œè€…é‡ç–Šåº¦
            overlap = self._calculate_author_overlap(authors, paper_authors)

            if overlap > 0:
                candidates.append((paper, overlap))

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            return candidates[0]

        return None

    def _calculate_author_overlap(
        self,
        authors1: List[str],
        authors2: List[str]
    ) -> float:
        """è¨ˆç®—ä½œè€…åˆ—è¡¨çš„é‡ç–Šåº¦ï¼ˆJaccard ç›¸ä¼¼åº¦ï¼‰"""
        def extract_last_name(author: str) -> str:
            author = author.strip().lower()
            if ',' in author:
                return author.split(',')[0].strip()
            parts = author.split()
            return parts[-1].strip() if parts else author

        last_names1 = set(extract_last_name(a) for a in authors1)
        last_names2 = set(extract_last_name(a) for a in authors2)

        if not last_names1 or not last_names2:
            return 0.0

        intersection = len(last_names1 & last_names2)
        union = len(last_names1 | last_names2)

        return intersection / union if union > 0 else 0.0

    # ==================== ç¬¬4æ­¥: è§£æ±ºè¡çª ====================

    def resolve_conflicts(
        self,
        match_results: Dict,
        strategy: str = 'skip'
    ) -> List[BibTeXEntry]:
        """
        è§£æ±ºè¡çªå’Œå»é‡

        ç­–ç•¥ï¼š
        - 'skip': è·³éé‡è¤‡é …ï¼ˆä¿ç•™çŸ¥è­˜åº«ç‰ˆæœ¬ï¼‰
        - 'replace': ç”¨ BibTeX ç‰ˆæœ¬æ›¿æ›ï¼ˆä¿ç•™æ–°ç‰ˆæœ¬ï¼‰
        - 'merge': åˆä½µå…ƒæ•¸æ“šï¼ˆå„ªå…ˆå– BibTeX ç‰ˆæœ¬çš„æœ‰æ•ˆæ•¸æ“šï¼‰

        Args:
            match_results: match_with_kb() çš„çµæœ
            strategy: è¡çªè§£æ±ºç­–ç•¥

        Returns:
            å¾…å°å…¥çš„ BibTeXEntry åˆ—è¡¨
        """
        print(f"âš™ï¸  è§£æ±ºè¡çª (ç­–ç•¥: {strategy})...")

        duplicates = match_results['duplicates']
        new_entries = match_results['new_entries']

        # æ ¹æ“šç­–ç•¥è™•ç†é‡è¤‡
        entries_to_import = []

        if strategy == 'skip':
            # åªå°å…¥æ–°æ¢ç›®
            entries_to_import = [entry for _, entry in new_entries]

            if duplicates:
                print(f"â­ï¸  è·³é {len(duplicates)} ç¯‡é‡è¤‡è«–æ–‡ï¼ˆä¿ç•™çŸ¥è­˜åº«ç‰ˆæœ¬ï¼‰")

        elif strategy == 'replace':
            # å°å…¥æ–°æ¢ç›® + æ›¿æ›é‡è¤‡
            entries_to_import = [entry for _, entry in new_entries]
            entries_to_import.extend([d['bibtex_entry'] for d in duplicates])

            print(f"ğŸ”„ å°‡æ›¿æ› {len(duplicates)} ç¯‡é‡è¤‡è«–æ–‡ï¼ˆä½¿ç”¨æ–°ç‰ˆæœ¬ï¼‰")

        elif strategy == 'merge':
            # å°å…¥æ–°æ¢ç›® + åˆä½µé‡è¤‡
            entries_to_import = [entry for _, entry in new_entries]

            for dup in duplicates:
                merged = self._merge_entries(
                    dup['bibtex_entry'],
                    dup['kb_paper']
                )
                entries_to_import.append(merged)

            print(f"ğŸ”— åˆä½µ {len(duplicates)} ç¯‡é‡è¤‡è«–æ–‡ï¼ˆä¿ç•™å…©ç‰ˆæœ¬çš„æœ€ä½³æ•¸æ“šï¼‰")

        print(f"âœ… è¡çªè§£æ±ºå®Œæˆï¼šå¾…å°å…¥ {len(entries_to_import)} ç¯‡è«–æ–‡")

        return entries_to_import

    def _merge_entries(
        self,
        bibtex_entry: BibTeXEntry,
        kb_paper: Dict
    ) -> BibTeXEntry:
        """åˆä½µ BibTeX æ¢ç›®å’ŒçŸ¥è­˜åº«è«–æ–‡"""
        # å„ªå…ˆå– BibTeX ç‰ˆæœ¬çš„æ•¸æ“šï¼Œè£œå……çŸ¥è­˜åº«ç¼ºå¤±çš„éƒ¨åˆ†
        merged = BibTeXEntry(
            entry_type=bibtex_entry.entry_type,
            cite_key=bibtex_entry.cite_key,
            title=bibtex_entry.title,  # BibTeX ç‰ˆæœ¬
            authors=bibtex_entry.authors or kb_paper.get('authors', []),
            year=bibtex_entry.year or kb_paper.get('year'),
            abstract=bibtex_entry.abstract or kb_paper.get('abstract'),
            keywords=bibtex_entry.keywords or kb_paper.get('keywords', []),
            doi=bibtex_entry.doi,
            url=bibtex_entry.url,
            journal=bibtex_entry.journal,
            booktitle=bibtex_entry.booktitle,
            publisher=bibtex_entry.publisher,
            volume=bibtex_entry.volume,
            number=bibtex_entry.number,
            pages=bibtex_entry.pages,
            note=bibtex_entry.note,
            file=bibtex_entry.file,
            raw_entry=bibtex_entry.raw_entry
        )

        return merged

    # ==================== ç¬¬5æ­¥: æ‰¹é‡å°å…¥ ====================

    def batch_import(
        self,
        entries_to_import: List[BibTeXEntry],
        dry_run: bool = False
    ) -> SyncResult:
        """
        æ‰¹é‡å°å…¥è«–æ–‡åˆ°çŸ¥è­˜åº«

        Args:
            entries_to_import: å¾…å°å…¥çš„ BibTeXEntry åˆ—è¡¨
            dry_run: å¦‚æœ Trueï¼Œåªé©—è­‰ä¸å°å…¥

        Returns:
            SyncResult å°è±¡
        """
        print(f"\nğŸ“¤ æ‰¹é‡å°å…¥è«–æ–‡åˆ°çŸ¥è­˜åº« ({'æ¨¡æ“¬é‹è¡Œ' if dry_run else 'çœŸå¯¦å°å…¥'})...")

        successful_imports = []
        skipped = 0
        errors = []

        for i, entry in enumerate(entries_to_import, 1):
            try:
                # é©—è­‰å¿…è¦æ¬„ä½
                if not entry.title:
                    raise ValueError("ç¼ºå°‘æ¨™é¡Œ")

                # æº–å‚™å°å…¥è¨˜éŒ„
                import_record = {
                    'cite_key': entry.cite_key,
                    'entry_type': entry.entry_type,
                    'title': entry.title,
                    'authors': entry.authors,
                    'year': entry.year,
                    'abstract': entry.abstract,
                    'keywords': entry.keywords,
                    'doi': entry.doi,
                    'url': entry.url,
                    'journal': entry.journal,
                    'booktitle': entry.booktitle,
                    'publisher': entry.publisher,
                    'volume': entry.volume,
                    'number': entry.number,
                    'pages': entry.pages,
                    'note': entry.note,
                    'file': entry.file,
                    'source': 'zotero_sync',
                    'import_timestamp': datetime.now().isoformat()
                }

                if not dry_run:
                    # å¯¦éš›å°å…¥ï¼ˆæ­¤æ­¥é©Ÿç”±ä¸Šå±¤è™•ç†ï¼‰
                    pass

                successful_imports.append(import_record)

                if (i % 10) == 0:
                    print(f"   [{i}/{len(entries_to_import)}] âœ… {entry.cite_key}")

            except Exception as e:
                error_msg = f"å°å…¥å¤±æ•—: {str(e)}"
                errors.append((entry.cite_key, error_msg))
                print(f"   âŒ {entry.cite_key}: {error_msg}")

        # ç”Ÿæˆæœ€çµ‚çµæœ
        result = SyncResult(
            total_bibtex_entries=len(self.bibtex_entries),
            successful_imports=len(successful_imports),
            skipped_duplicates=len(self.bibtex_entries) - len(entries_to_import),
            conflicts=self.conflicts,
            errors=errors,
            import_list=successful_imports,
            timestamp=datetime.now().isoformat()
        )

        print(f"\nâœ… å°å…¥å®Œæˆ:")
        print(f"   - æˆåŠŸ: {result.successful_imports} ç¯‡")
        print(f"   - è·³é: {result.skipped_duplicates} ç¯‡")
        print(f"   - éŒ¯èª¤: {len(errors)} ç¯‡")

        return result

    # ==================== å·¥ä½œæµæ•´åˆ ====================

    def sync(
        self,
        bib_file: str,
        conflict_strategy: str = 'skip',
        dry_run: bool = False,
        output_file: Optional[str] = None
    ) -> SyncResult:
        """
        åŸ·è¡Œå®Œæ•´çš„ Zotero åŒæ­¥å·¥ä½œæµ

        å·¥ä½œæµæ­¥é©Ÿï¼š
        1. è§£æ BibTeX æ–‡ä»¶
        2. è®€å–çŸ¥è­˜åº«ç¾æœ‰è«–æ–‡
        3. èˆ‡çŸ¥è­˜åº«é€²è¡ŒåŒ¹é…
        4. è§£æ±ºè¡çªå’Œå»é‡
        5. æ‰¹é‡å°å…¥

        Args:
            bib_file: Zotero å°å‡ºçš„ .bib æ–‡ä»¶è·¯å¾‘
            conflict_strategy: è¡çªè§£æ±ºç­–ç•¥ ('skip', 'replace', 'merge')
            dry_run: æ¨¡æ“¬é‹è¡Œï¼ˆé©—è­‰ä½†ä¸å°å…¥ï¼‰
            output_file: å¯é¸ï¼Œå°‡çµæœè¼¸å‡ºåˆ° JSON æ–‡ä»¶

        Returns:
            SyncResult å°è±¡
        """
        print("=" * 60)
        print("ğŸ”„ ZoteroSync - Zotero åˆ°çŸ¥è­˜åº«åŒæ­¥")
        print("=" * 60)

        try:
            # ç¬¬1æ­¥ï¼šè§£æ BibTeX
            self.parse_bibtex(bib_file)

            # ç¬¬2æ­¥ï¼šè®€å–çŸ¥è­˜åº«
            self.load_kb_papers()

            # ç¬¬3æ­¥ï¼šåŒ¹é…
            match_results = self.match_with_kb()

            # ç¬¬4æ­¥ï¼šè§£æ±ºè¡çª
            entries_to_import = self.resolve_conflicts(
                match_results,
                strategy=conflict_strategy
            )

            # ç¬¬5æ­¥ï¼šæ‰¹é‡å°å…¥
            result = self.batch_import(entries_to_import, dry_run=dry_run)

            # è¼¸å‡ºçµæœ
            if output_file:
                self._save_result(result, output_file)

            return result

        except Exception as e:
            print(f"\nâŒ åŒæ­¥å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            raise

    def _save_result(self, result: SyncResult, output_file: str):
        """ä¿å­˜åŒæ­¥çµæœåˆ° JSON æ–‡ä»¶"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        result_dict = {
            'total_bibtex_entries': result.total_bibtex_entries,
            'successful_imports': result.successful_imports,
            'skipped_duplicates': result.skipped_duplicates,
            'errors': result.errors,
            'error_count': len(result.errors),
            'import_count': len(result.import_list),
            'conflict_count': len(result.conflicts),
            'timestamp': result.timestamp,
            'import_list': result.import_list
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result_dict, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ çµæœå·²ä¿å­˜: {output_file}")


def main():
    """æ¸¬è©¦ ZoteroSync"""
    import argparse

    parser = argparse.ArgumentParser(description='Zotero åˆ°çŸ¥è­˜åº«åŒæ­¥å·¥å…·')
    parser.add_argument('bib_file', help='Zotero å°å‡ºçš„ .bib æ–‡ä»¶')
    parser.add_argument(
        '--kb-path',
        default='knowledge_base',
        help='çŸ¥è­˜åº«è·¯å¾‘ (é è¨­: knowledge_base)'
    )
    parser.add_argument(
        '--strategy',
        choices=['skip', 'replace', 'merge'],
        default='skip',
        help='è¡çªè§£æ±ºç­–ç•¥ (é è¨­: skip)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='æ¨¡æ“¬é‹è¡Œï¼ˆé©—è­‰ä½†ä¸å°å…¥ï¼‰'
    )
    parser.add_argument(
        '--output',
        help='è¼¸å‡ºçµæœåˆ° JSON æ–‡ä»¶'
    )

    args = parser.parse_args()

    try:
        sync = ZoteroSync(kb_path=args.kb_path)
        result = sync.sync(
            bib_file=args.bib_file,
            conflict_strategy=args.strategy,
            dry_run=args.dry_run,
            output_file=args.output
        )

        return 0 if result.successful_imports > 0 else 1

    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        return 1


if __name__ == '__main__':
    sys.exit(main())
