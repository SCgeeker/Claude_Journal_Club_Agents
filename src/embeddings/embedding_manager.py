"""
EmbeddingManager - çµ±ä¸€çš„åµŒå…¥ç®¡ç†å™¨
æä¾›é«˜å±¤æ¬¡ API ç°¡åŒ–å‘é‡æœç´¢æ“ä½œ
"""

import numpy as np
from typing import Dict, List, Optional, Union
from pathlib import Path
import sys

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.embeddings.providers import GeminiEmbedder, OllamaEmbedder
from src.embeddings.vector_db import VectorDatabase
from src.knowledge_base.kb_manager import KnowledgeBaseManager
from src.knowledge_base.auto_link import auto_link_v2, auto_link_all_papers


class EmbeddingManager:
    """çµ±ä¸€çš„åµŒå…¥ç®¡ç†å™¨

    æä¾›ç°¡åŒ–çš„ API ç”¨æ–¼ï¼š
    - ç”ŸæˆåµŒå…¥
    - èªç¾©æœç´¢
    - ç›¸ä¼¼åº¦æŸ¥æ‰¾
    - è‡ªå‹•é€£çµ
    """

    def __init__(
        self,
        kb_root: str = "knowledge_base",
        provider: str = "gemini",
        chroma_db_path: str = "chroma_db"
    ):
        """
        åˆå§‹åŒ–åµŒå…¥ç®¡ç†å™¨

        Args:
            kb_root: çŸ¥è­˜åº«æ ¹ç›®éŒ„
            provider: åµŒå…¥æä¾›è€…ï¼ˆgemini æˆ– ollamaï¼‰
            chroma_db_path: ChromaDB æŒä¹…åŒ–ç›®éŒ„
        """
        self.kb_root = kb_root
        self.provider = provider
        self.chroma_db_path = chroma_db_path

        # åˆå§‹åŒ–çµ„ä»¶
        self.kb = KnowledgeBaseManager(kb_root=kb_root)
        self.embedder = self._init_embedder(provider)
        self.vector_db = VectorDatabase(persist_directory=chroma_db_path)

    def _init_embedder(self, provider: str):
        """åˆå§‹åŒ–åµŒå…¥æä¾›è€…"""
        if provider.lower() == "gemini":
            return GeminiEmbedder()
        elif provider.lower() == "ollama":
            return OllamaEmbedder()
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æä¾›è€…: {provider}ã€‚è«‹ä½¿ç”¨ 'gemini' æˆ– 'ollama'ã€‚")

    # ========== åµŒå…¥ç”Ÿæˆ ==========

    def generate_for_paper(
        self,
        paper_id: int,
        force_regenerate: bool = False
    ) -> Dict:
        """ç‚ºå–®ç¯‡è«–æ–‡ç”ŸæˆåµŒå…¥

        Args:
            paper_id: è«–æ–‡ ID
            force_regenerate: æ˜¯å¦å¼·åˆ¶é‡æ–°ç”Ÿæˆï¼ˆé»˜èªï¼šFalseï¼‰

        Returns:
            {
                'paper_id': int,
                'vector_id': str,
                'generated': bool,
                'message': str
            }
        """
        vector_id = f"paper_{paper_id}"

        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if not force_regenerate:
            existing = self.vector_db.get_paper_by_id(vector_id)
            if existing:
                return {
                    'paper_id': paper_id,
                    'vector_id': vector_id,
                    'generated': False,
                    'message': 'å‘é‡å·²å­˜åœ¨ï¼Œè·³éç”Ÿæˆ'
                }

        # å¾çŸ¥è­˜åº«ç²å–è«–æ–‡
        paper = self.kb.get_paper_by_id(paper_id)
        if not paper:
            raise ValueError(f"è«–æ–‡ ID {paper_id} ä¸å­˜åœ¨")

        # çµ„åˆæ–‡æœ¬
        text_parts = []
        if paper.get('title'):
            text_parts.append(f"æ¨™é¡Œ: {paper['title']}")
        if paper.get('authors'):
            authors_str = ', '.join(paper['authors']) if isinstance(paper['authors'], list) else paper['authors']
            text_parts.append(f"ä½œè€…: {authors_str}")
        if paper.get('abstract'):
            text_parts.append(f"æ‘˜è¦: {paper['abstract']}")
        if paper.get('keywords'):
            keywords_str = ', '.join(paper['keywords']) if isinstance(paper['keywords'], list) else paper['keywords']
            text_parts.append(f"é—œéµè©: {keywords_str}")

        combined_text = "\n".join(text_parts)

        # ç”ŸæˆåµŒå…¥
        embedding = self.embedder.embed(combined_text, task_type="retrieval_document")

        # æº–å‚™å…ƒæ•¸æ“š
        metadata = {
            'paper_id': paper_id,
            'title': paper.get('title', ''),
            'authors': ', '.join(paper['authors']) if isinstance(paper['authors'], list) else paper.get('authors', ''),
            'year': paper.get('year', 0) or 0,
            'type': 'paper'
        }

        # ä¿å­˜åˆ°å‘é‡æ•¸æ“šåº«
        self.vector_db.upsert_papers(
            embeddings=[embedding],
            documents=[combined_text],
            ids=[vector_id],
            metadatas=[metadata]
        )

        return {
            'paper_id': paper_id,
            'vector_id': vector_id,
            'generated': True,
            'message': 'æˆåŠŸç”Ÿæˆä¸¦ä¿å­˜å‘é‡'
        }

    def generate_for_zettel(
        self,
        card_id: int,
        force_regenerate: bool = False
    ) -> Dict:
        """ç‚ºå–®å¼µ Zettelkasten å¡ç‰‡ç”ŸæˆåµŒå…¥

        Args:
            card_id: å¡ç‰‡ ID
            force_regenerate: æ˜¯å¦å¼·åˆ¶é‡æ–°ç”Ÿæˆ

        Returns:
            ç”Ÿæˆçµæœå­—å…¸
        """
        # å¾çŸ¥è­˜åº«ç²å–å¡ç‰‡
        import sqlite3
        conn = sqlite3.connect(self.kb.db_path)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT zettel_id, title, content, core_concept, description, card_type, domain
            FROM zettel_cards
            WHERE card_id = ?
        """, (card_id,))
        result = cursor.fetchone()
        conn.close()

        if not result:
            raise ValueError(f"å¡ç‰‡ ID {card_id} ä¸å­˜åœ¨")

        zettel_id, title, content, core_concept, description, card_type, domain = result
        vector_id = f"zettel_{zettel_id}"

        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if not force_regenerate:
            existing = self.vector_db.get_zettel_by_id(vector_id)
            if existing:
                return {
                    'card_id': card_id,
                    'vector_id': vector_id,
                    'generated': False,
                    'message': 'å‘é‡å·²å­˜åœ¨ï¼Œè·³éç”Ÿæˆ'
                }

        # çµ„åˆæ–‡æœ¬
        text_parts = []
        if title:
            text_parts.append(f"æ¨™é¡Œ: {title}")
        if core_concept:
            text_parts.append(f"æ ¸å¿ƒæ¦‚å¿µ: {core_concept}")
        if description:
            text_parts.append(f"æè¿°: {description}")
        if content:
            text_parts.append(f"å…§å®¹: {content[:1500]}")  # é™åˆ¶é•·åº¦

        combined_text = "\n".join(text_parts)

        # ç”ŸæˆåµŒå…¥
        embedding = self.embedder.embed(combined_text, task_type="retrieval_document")

        # æº–å‚™å…ƒæ•¸æ“š
        metadata = {
            'card_id': card_id,
            'zettel_id': zettel_id,
            'title': title or '',
            'core_concept': core_concept or '',
            'card_type': card_type or 'concept',
            'domain': domain,
            'type': 'zettel'
        }

        # ä¿å­˜åˆ°å‘é‡æ•¸æ“šåº«
        self.vector_db.upsert_zettel(
            embeddings=[embedding],
            documents=[combined_text],
            ids=[vector_id],
            metadatas=[metadata]
        )

        return {
            'card_id': card_id,
            'vector_id': vector_id,
            'generated': True,
            'message': 'æˆåŠŸç”Ÿæˆä¸¦ä¿å­˜å‘é‡'
        }

    # ========== æœç´¢åŠŸèƒ½ ==========

    def search(
        self,
        query: str,
        type: str = "all",
        limit: int = 10,
        return_embeddings: bool = False
    ) -> Dict:
        """çµ±ä¸€çš„èªç¾©æœç´¢æ¥å£

        Args:
            query: æœç´¢æŸ¥è©¢
            type: æœç´¢é¡å‹ï¼ˆpapers / zettel / allï¼‰
            limit: è¿”å›æ•¸é‡
            return_embeddings: æ˜¯å¦è¿”å›å‘é‡ï¼ˆé»˜èªï¼šFalseï¼‰

        Returns:
            {
                'query': str,
                'type': str,
                'papers': List[Dict],
                'zettel': List[Dict]
            }
        """
        # ç”ŸæˆæŸ¥è©¢å‘é‡
        query_embedding = self.embedder.embed(query, task_type="retrieval_query")

        results = {
            'query': query,
            'type': type,
            'papers': [],
            'zettel': []
        }

        # æœç´¢è«–æ–‡
        if type in ['papers', 'all']:
            paper_results = self.vector_db.semantic_search_papers(
                query_embedding=query_embedding,
                n_results=limit
            )

            if paper_results and paper_results['ids'] and len(paper_results['ids'][0]) > 0:
                for i, (pid, distance, metadata) in enumerate(zip(
                    paper_results['ids'][0],
                    paper_results['distances'][0],
                    paper_results['metadatas'][0]
                )):
                    paper_id = int(pid.replace('paper_', ''))
                    similarity = 1.0 - distance

                    result_item = {
                        'rank': i + 1,
                        'paper_id': paper_id,
                        'similarity': similarity,
                        'title': metadata.get('title', ''),
                        'authors': metadata.get('authors', ''),
                        'year': metadata.get('year', 0)
                    }

                    if return_embeddings:
                        result_item['embedding'] = paper_results['embeddings'][0][i]

                    results['papers'].append(result_item)

        # æœç´¢ Zettelkasten
        if type in ['zettel', 'all']:
            zettel_results = self.vector_db.semantic_search_zettel(
                query_embedding=query_embedding,
                n_results=limit
            )

            if zettel_results and zettel_results['ids'] and len(zettel_results['ids'][0]) > 0:
                for i, (zid, distance, metadata) in enumerate(zip(
                    zettel_results['ids'][0],
                    zettel_results['distances'][0],
                    zettel_results['metadatas'][0]
                )):
                    similarity = 1.0 - distance

                    result_item = {
                        'rank': i + 1,
                        'zettel_id': zid,
                        'similarity': similarity,
                        'title': metadata.get('title', ''),
                        'core_concept': metadata.get('core_concept', ''),
                        'card_type': metadata.get('card_type', ''),
                        'domain': metadata.get('domain', '')
                    }

                    if return_embeddings:
                        result_item['embedding'] = zettel_results['embeddings'][0][i]

                    results['zettel'].append(result_item)

        return results

    def find_similar(
        self,
        id: Union[int, str],
        limit: int = 10,
        exclude_self: bool = True
    ) -> List[Dict]:
        """çµ±ä¸€çš„ç›¸ä¼¼åº¦æŸ¥æ‰¾æ¥å£

        Args:
            id: è«–æ–‡ IDï¼ˆæ•´æ•¸ï¼‰æˆ– Zettelkasten IDï¼ˆå­—ä¸²ï¼‰
            limit: è¿”å›æ•¸é‡
            exclude_self: æ˜¯å¦æ’é™¤è‡ªèº«

        Returns:
            ç›¸ä¼¼çµæœåˆ—è¡¨
        """
        # åˆ¤æ–·é¡å‹
        if isinstance(id, int):
            # è«–æ–‡ ID
            vector_id = f"paper_{id}"
            results = self.vector_db.find_similar_papers(
                paper_id=vector_id,
                n_results=limit,
                exclude_self=exclude_self
            )

            similar_items = []
            if results and results['ids'] and len(results['ids'][0]) > 0:
                for pid, distance, metadata in zip(
                    results['ids'][0],
                    results['distances'][0],
                    results['metadatas'][0]
                ):
                    paper_id = int(pid.replace('paper_', ''))
                    similarity = 1.0 - distance

                    similar_items.append({
                        'type': 'paper',
                        'paper_id': paper_id,
                        'similarity': similarity,
                        'title': metadata.get('title', ''),
                        'authors': metadata.get('authors', ''),
                        'year': metadata.get('year', 0)
                    })

            return similar_items

        else:
            # Zettelkasten ID
            if not id.startswith('zettel_'):
                vector_id = f"zettel_{id}"
            else:
                vector_id = id

            results = self.vector_db.find_similar_zettel(
                zettel_id=vector_id,
                n_results=limit,
                exclude_self=exclude_self
            )

            similar_items = []
            if results and results['ids'] and len(results['ids'][0]) > 0:
                for zid, distance, metadata in zip(
                    results['ids'][0],
                    results['distances'][0],
                    results['metadatas'][0]
                ):
                    similarity = 1.0 - distance

                    similar_items.append({
                        'type': 'zettel',
                        'zettel_id': zid,
                        'similarity': similarity,
                        'title': metadata.get('title', ''),
                        'core_concept': metadata.get('core_concept', ''),
                        'card_type': metadata.get('card_type', ''),
                        'domain': metadata.get('domain', '')
                    })

            return similar_items

    # ========== è‡ªå‹•é€£çµ ==========

    def auto_link_papers_to_zettel(
        self,
        paper_id: Optional[int] = None,
        threshold: float = 0.6,
        max_links: int = 5,
        batch_mode: bool = False,
        verbose: bool = False
    ) -> Dict:
        """è‡ªå‹•å»ºç«‹è«–æ–‡-Zettelkasten é€£çµï¼ˆåŸºæ–¼å‘é‡ç›¸ä¼¼åº¦ï¼‰

        Args:
            paper_id: è«–æ–‡ IDï¼ˆNone è¡¨ç¤ºè™•ç†æ‰€æœ‰è«–æ–‡ï¼‰
            threshold: ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆ0-1ï¼‰
            max_links: æ¯ç¯‡è«–æ–‡æœ€å¤šå»ºç«‹å¹¾å€‹é€£çµ
            batch_mode: æ˜¯å¦æ‰¹æ¬¡æ¨¡å¼ï¼ˆè™•ç†æ‰€æœ‰è«–æ–‡ï¼‰
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°é€²åº¦

        Returns:
            å–®ç¯‡æ¨¡å¼: auto_link_v2() çš„è¿”å›çµæœ
            æ‰¹æ¬¡æ¨¡å¼: auto_link_all_papers() çš„è¿”å›çµæœ
        """
        if batch_mode or paper_id is None:
            return auto_link_all_papers(
                threshold=threshold,
                max_links=max_links,
                kb_root=self.kb_root,
                chroma_db_path=self.chroma_db_path,
                verbose=verbose
            )
        else:
            return auto_link_v2(
                paper_id=paper_id,
                threshold=threshold,
                max_links=max_links,
                kb_root=self.kb_root,
                chroma_db_path=self.chroma_db_path
            )

    def get_paper_links(
        self,
        paper_id: int,
        min_similarity: float = 0.0
    ) -> List[Dict]:
        """ç²å–è«–æ–‡çš„ Zettelkasten é€£çµ

        Args:
            paper_id: è«–æ–‡ ID
            min_similarity: æœ€å°ç›¸ä¼¼åº¦éæ¿¾

        Returns:
            é€£çµåˆ—è¡¨
        """
        return self.kb.get_paper_zettel_links(paper_id, min_similarity)

    def get_zettel_links(
        self,
        card_id: int,
        min_similarity: float = 0.0
    ) -> List[Dict]:
        """ç²å– Zettelkasten å¡ç‰‡çš„è«–æ–‡é€£çµ

        Args:
            card_id: å¡ç‰‡ ID
            min_similarity: æœ€å°ç›¸ä¼¼åº¦éæ¿¾

        Returns:
            é€£çµåˆ—è¡¨
        """
        return self.kb.get_zettel_paper_links(card_id, min_similarity)

    # ========== çµ±è¨ˆèˆ‡ç®¡ç† ==========

    def get_stats(self) -> Dict:
        """ç²å–ç³»çµ±çµ±è¨ˆä¿¡æ¯

        Returns:
            {
                'kb_stats': Dict,
                'vector_stats': Dict
            }
        """
        return {
            'kb_stats': self.kb.get_stats(),
            'vector_stats': self.vector_db.get_stats()
        }

    def switch_provider(self, provider: str):
        """åˆ‡æ›åµŒå…¥æä¾›è€…

        Args:
            provider: æ–°çš„æä¾›è€…ï¼ˆgemini æˆ– ollamaï¼‰
        """
        self.provider = provider
        self.embedder = self._init_embedder(provider)


# ========== ä¾¿åˆ©å‡½æ•¸ ==========

def create_manager(
    provider: str = "gemini",
    kb_root: str = "knowledge_base",
    chroma_db_path: str = "chroma_db"
) -> EmbeddingManager:
    """å‰µå»º EmbeddingManager å¯¦ä¾‹çš„ä¾¿åˆ©å‡½æ•¸

    Args:
        provider: åµŒå…¥æä¾›è€…
        kb_root: çŸ¥è­˜åº«æ ¹ç›®éŒ„
        chroma_db_path: ChromaDB ç›®éŒ„

    Returns:
        EmbeddingManager å¯¦ä¾‹
    """
    return EmbeddingManager(
        kb_root=kb_root,
        provider=provider,
        chroma_db_path=chroma_db_path
    )


if __name__ == "__main__":
    """æ¸¬è©¦ EmbeddingManager"""
    import argparse
    import io

    # è¨­ç½® UTF-8 ç·¨ç¢¼ï¼ˆWindows ç›¸å®¹æ€§ï¼‰
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

    parser = argparse.ArgumentParser(description="EmbeddingManager æ¸¬è©¦å·¥å…·")
    parser.add_argument("--search", type=str, help="æ¸¬è©¦æœç´¢åŠŸèƒ½")
    parser.add_argument("--similar", type=str, help="æ¸¬è©¦ç›¸ä¼¼åº¦æŸ¥æ‰¾ï¼ˆè«–æ–‡IDæˆ–Zettel IDï¼‰")
    parser.add_argument("--stats", action="store_true", help="é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯")
    parser.add_argument("--provider", choices=['gemini', 'ollama'], default='gemini', help="æä¾›è€…")

    args = parser.parse_args()

    # å‰µå»ºç®¡ç†å™¨
    manager = create_manager(provider=args.provider)

    if args.stats:
        print("\n" + "=" * 60)
        print("ğŸ“Š ç³»çµ±çµ±è¨ˆ")
        print("=" * 60)
        stats = manager.get_stats()
        print(f"\nçŸ¥è­˜åº«çµ±è¨ˆ:")
        for key, value in stats['kb_stats'].items():
            print(f"  {key}: {value}")
        print(f"\nå‘é‡æ•¸æ“šåº«çµ±è¨ˆ:")
        for key, value in stats['vector_stats'].items():
            print(f"  {key}: {value}")
        print("\n" + "=" * 60)

    elif args.search:
        print("\n" + "=" * 60)
        print(f"ğŸ” æœç´¢: '{args.search}'")
        print("=" * 60)
        results = manager.search(args.search, type="all", limit=5)

        if results['papers']:
            print(f"\nğŸ“„ è«–æ–‡çµæœ ({len(results['papers'])}ç¯‡):")
            for item in results['papers']:
                print(f"  {item['rank']}. [{item['similarity']:.1%}] {item['title']}")

        if results['zettel']:
            print(f"\nğŸ—‚ï¸  Zettelkasten çµæœ ({len(results['zettel'])}å¼µ):")
            for item in results['zettel']:
                print(f"  {item['rank']}. [{item['similarity']:.1%}] {item['title']}")

        print("\n" + "=" * 60)

    elif args.similar:
        # åˆ¤æ–·æ˜¯è«–æ–‡ ID é‚„æ˜¯ Zettel ID
        try:
            id_val = int(args.similar)
            type_str = "è«–æ–‡"
        except:
            id_val = args.similar
            type_str = "Zettelkasten"

        print("\n" + "=" * 60)
        print(f"ğŸ” å°‹æ‰¾èˆ‡ {type_str} '{id_val}' ç›¸ä¼¼çš„å…§å®¹")
        print("=" * 60)

        similar = manager.find_similar(id_val, limit=5)

        for i, item in enumerate(similar, 1):
            if item['type'] == 'paper':
                print(f"{i}. [{item['similarity']:.1%}] {item['title']}")
                print(f"   é¡å‹: è«–æ–‡ | ID: {item['paper_id']}")
            else:
                print(f"{i}. [{item['similarity']:.1%}] {item['title']}")
                print(f"   é¡å‹: Zettelkasten | ID: {item['zettel_id']}")

        print("\n" + "=" * 60)

    else:
        parser.print_help()
