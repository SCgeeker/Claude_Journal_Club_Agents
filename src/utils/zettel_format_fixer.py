#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Zettelkasten æ ¼å¼ä¿®å¾©å·¥å…·

åŸºæ–¼ç”¨æˆ¶æ‰‹å‹•èª¿æ•´æ¨¡å¼ï¼Œè‡ªå‹•ä¿®å¾© LLM ç”Ÿæˆçš„ Zettelkasten å¡ç‰‡æ ¼å¼å•é¡Œã€‚

æ ¸å¿ƒä¿®å¾©è¦å‰‡ï¼ˆåŸºæ–¼ Barsalou-2009 å¡ç‰‡åˆ†æï¼‰ï¼š
1. fix_summary_field(): æ¸…ç† summaryï¼ˆ<100 å­—å…ƒï¼Œç§»é™¤ Markdownï¼‰
2. fix_link_format(): ä¿®å¾©é€£çµï¼ˆAuthorYearNumber â†’ Author-Year-Numberï¼‰
3. remove_redundant_sections(): ç§»é™¤å†—é¤˜ H1 å’Œã€Œæ ¸å¿ƒã€å€å¡Š
4. normalize_spacing(): æ¨™æº–åŒ–ç©ºè¡Œï¼ˆfrontmatter å¾Œ 1 è¡Œï¼Œå€æ®µé–“ 2 è¡Œï¼‰

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-11-05
ç‰ˆæœ¬: 1.0.0
"""

import re
import sys
import io
from pathlib import Path
from typing import List, Dict, Tuple
import argparse

# Windows ç·¨ç¢¼ä¿®å¾©
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


class ZettelFormatFixer:
    """Zettelkasten å¡ç‰‡æ ¼å¼ä¿®å¾©å™¨"""

    def __init__(self, dry_run: bool = False):
        """
        åˆå§‹åŒ–ä¿®å¾©å™¨

        Args:
            dry_run: æ˜¯å¦ç‚º dry-run æ¨¡å¼ï¼ˆåƒ…é è¦½è®Šæ›´ï¼Œä¸å¯¦éš›ä¿®æ”¹ï¼‰
        """
        self.dry_run = dry_run
        self.stats = {
            'total': 0,
            'fixed': 0,
            'skipped': 0,
            'errors': 0,
            'fixes': {
                'summary': 0,
                'links': 0,
                'redundant_h1': 0,
                'redundant_core': 0,
                'spacing': 0
            }
        }

    def fix_card(self, card_path: Path, index_data: Dict[str, str] = None) -> Tuple[bool, List[str]]:
        """
        ä¿®å¾©å–®å¼µå¡ç‰‡

        Args:
            card_path: å¡ç‰‡æ–‡ä»¶è·¯å¾‘
            index_data: zettel_index.md ä¸­çš„å¡ç‰‡æ ¸å¿ƒè³‡æ–™ï¼ˆé å…ˆè§£æä»¥æé«˜æ•ˆç‡ï¼‰

        Returns:
            (æ˜¯å¦æˆåŠŸ, ä¿®å¾©è®Šæ›´åˆ—è¡¨)
        """
        try:
            # è®€å–å¡ç‰‡å…§å®¹
            content = card_path.read_text(encoding='utf-8')
            original_content = content
            changes = []

            # åˆ†é›¢ frontmatter å’Œæ­£æ–‡
            frontmatter, body = self._split_frontmatter(content)
            if not frontmatter:
                return False, ["ç„¡æ³•è§£æ frontmatter"]

            # å¦‚æœæ²’æœ‰æä¾› index_dataï¼Œå¾ zettel_index.md è®€å–
            if index_data is None:
                index_data = self._parse_zettel_index(card_path)

            # è¦å‰‡ 1: ä¿®å¾© summaryï¼ˆå¾ zettel_index.md çš„ã€Œæ ¸å¿ƒã€æå–ï¼‰
            frontmatter_fixed, summary_changes = self.fix_summary_field(card_path, frontmatter, index_data)
            if summary_changes:
                changes.extend(summary_changes)
                frontmatter = frontmatter_fixed

            # è¦å‰‡ 2: ä¿®å¾©é€£çµæ ¼å¼
            body_fixed, link_changes = self.fix_link_format(body)
            if link_changes:
                changes.extend(link_changes)
                body = body_fixed

            # è¦å‰‡ 3: ç§»é™¤å†—é¤˜å€å¡Š
            body_fixed, redundant_changes = self.remove_redundant_sections(body)
            if redundant_changes:
                changes.extend(redundant_changes)
                body = body_fixed

            # è¦å‰‡ 4: æ¨™æº–åŒ–ç©ºè¡Œ
            content_fixed, spacing_changes = self.normalize_spacing(frontmatter, body)
            if spacing_changes:
                changes.extend(spacing_changes)

            # å¦‚æœæœ‰è®Šæ›´
            if changes:
                self.stats['fixed'] += 1

                # å¦‚æœä¸æ˜¯ dry-runï¼Œå¯«å…¥æ–‡ä»¶
                if not self.dry_run:
                    card_path.write_text(content_fixed, encoding='utf-8')

                return True, changes
            else:
                self.stats['skipped'] += 1
                return True, []

        except Exception as e:
            self.stats['errors'] += 1
            return False, [f"éŒ¯èª¤: {str(e)}"]

    def _parse_zettel_index(self, card_path: Path) -> Dict[str, str]:
        """
        è§£æ zettel_index.md ä»¥æå–æ‰€æœ‰å¡ç‰‡çš„ã€Œæ ¸å¿ƒã€å…§å®¹

        Args:
            card_path: å¡ç‰‡æ–‡ä»¶è·¯å¾‘ï¼ˆç”¨æ–¼æ‰¾åˆ°å°æ‡‰çš„ zettel_index.mdï¼‰

        Returns:
            {card_id: core_content} å­—å…¸
        """
        # æ‰¾åˆ°ä¸Šå±¤è³‡æ–™å¤¾çš„ zettel_index.md
        zettel_folder = card_path.parent.parent
        index_path = zettel_folder / "zettel_index.md"

        if not index_path.exists():
            return {}

        try:
            content = index_path.read_text(encoding='utf-8')
            index_data = {}

            # æ­£å‰‡è¡¨é”å¼ï¼šåŒ¹é…æ¯å¼µå¡ç‰‡çš„è³‡è¨Š
            # æ ¼å¼ï¼š### N. [æ¨™é¡Œ](zettel_cards/Card-ID.md)
            #       - **ID**: `Card-ID`
            #       - **æ ¸å¿ƒ**: [æ ¸å¿ƒå…§å®¹] æˆ– "æ ¸å¿ƒå…§å®¹" æˆ– æ ¸å¿ƒå…§å®¹
            # æ”¯æ´ä¸‰ç¨®æ ¼å¼ï¼šæ–¹æ‹¬è™Ÿ [...] | å¼•è™Ÿ "..." | ç„¡æ¨™è¨˜ï¼ˆåˆ°è¡Œå°¾ï¼‰
            # æ³¨æ„ï¼šç¬¬ä¸‰ç¨®æ ¼å¼ä½¿ç”¨ [^\n]+ é¿å…åœ¨ re.DOTALL æ¨¡å¼ä¸‹æ•ç²éå¤šå…§å®¹
            pattern = r'###\s+\d+\.\s+\[.*?\]\(zettel_cards/([\w-]+)\.md\)\n.*?\n.*?-\s+\*\*æ ¸å¿ƒ\*\*:\s+(?:\[(.*?)\]|"(.*?)"|([^\n]+))\n'

            matches = re.findall(pattern, content, re.DOTALL)

            for match in matches:
                card_id = match[0]
                # match[1] æ˜¯æ–¹æ‹¬è™Ÿå…§å®¹ï¼Œmatch[2] æ˜¯å¼•è™Ÿå…§å®¹ï¼Œmatch[3] æ˜¯ç´”æ–‡å­—
                core_content = match[1] if match[1] else (match[2] if match[2] else match[3])

                # æ¸…ç†æ ¸å¿ƒå…§å®¹ï¼ˆç§»é™¤å¤šé¤˜ç©ºç™½ï¼‰
                core_content = ' '.join(core_content.split())
                index_data[card_id] = core_content

            return index_data

        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: ç„¡æ³•è§£æ zettel_index.md: {e}")
            return {}

    def _split_frontmatter(self, content: str) -> Tuple[str, str]:
        """
        åˆ†é›¢ frontmatter å’Œæ­£æ–‡

        Returns:
            (frontmatter, body)
        """
        # åŒ¹é… YAML frontmatter
        pattern = r'^---\n(.*?)\n---\n(.*)$'
        match = re.match(pattern, content, re.DOTALL)

        if not match:
            return "", ""

        frontmatter = match.group(1)
        body = match.group(2)

        return frontmatter, body

    def fix_summary_field(self, card_path: Path, frontmatter: str, index_data: Dict[str, str]) -> Tuple[str, List[str]]:
        """
        è¦å‰‡ 1: ä¿®å¾© summary æ¬„ä½ï¼ˆå¾ zettel_index.md çš„ã€Œæ ¸å¿ƒã€æå–ï¼‰

        ç”¨æˆ¶åé¥‹ï¼šsummary å¿…é ˆèˆ‡ zettel_index.md ä¸­å°æ‡‰å¡ç‰‡çš„ã€Œæ ¸å¿ƒã€ä¸€è‡´
        é€™æ˜¯ Zettelkasten ç³»çµ±çš„è¨­è¨ˆï¼šindex æ˜¯å–®ä¸€çœŸç›¸ä¾†æº

        Args:
            card_path: å¡ç‰‡è·¯å¾‘ï¼ˆç”¨æ–¼æå– card_idï¼‰
            frontmatter: frontmatter å…§å®¹
            index_data: zettel_index.md ä¸­çš„ {card_id: core_content} å­—å…¸

        Returns:
            (ä¿®å¾©å¾Œçš„ frontmatter, è®Šæ›´åˆ—è¡¨)
        """
        changes = []

        # å¾æ–‡ä»¶åæå– card_idï¼ˆä¾‹å¦‚ "Barsalou-2009-005"ï¼‰
        card_id = card_path.stem

        # å¾ index_data ä¸­æŸ¥æ‰¾å°æ‡‰çš„æ ¸å¿ƒå…§å®¹
        if card_id not in index_data:
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›åŸå§‹ frontmatterï¼ˆå¯èƒ½æ˜¯ index_data è§£æå¤±æ•—ï¼‰
            return frontmatter, []

        correct_summary = index_data[card_id]

        # æå–ä¸¦æ›¿æ› summary è¡Œ
        summary_pattern = r'^(summary:\s*"?)(.+?)("?)$'
        lines = frontmatter.split('\n')

        for i, line in enumerate(lines):
            match = re.match(summary_pattern, line, re.MULTILINE)
            if match:
                prefix = match.group(1)
                current_summary = match.group(2)
                suffix = match.group(3)

                # æª¢æŸ¥æ˜¯å¦éœ€è¦ä¿®å¾©
                if current_summary != correct_summary:
                    # æ›¿æ›ç‚º zettel_index.md ä¸­çš„æ ¸å¿ƒå…§å®¹
                    lines[i] = f'{prefix}{correct_summary}{suffix}'
                    changes.append(f"ä¿®å¾© summary: åŒæ­¥ zettel_index.md æ ¸å¿ƒå…§å®¹")
                    changes.append(f"  åŸ: {current_summary[:50]}...")
                    changes.append(f"  æ–°: {correct_summary[:50]}...")
                    self.stats['fixes']['summary'] += 1

                break

        return '\n'.join(lines), changes

    def fix_link_format(self, body: str) -> Tuple[str, List[str]]:
        """
        è¦å‰‡ 2: ä¿®å¾©é€£çµæ ¼å¼

        ä¿®å¾©: [[AuthorYearNumber]] â†’ [[Author-Year-Number]]
        ä¾‹å¦‚: [[Barsalou2009002]] â†’ [[Barsalou-2009-002]]
              [[Wu202010]] â†’ [[Wu-2020-010]]

        Returns:
            (ä¿®å¾©å¾Œçš„æ­£æ–‡, è®Šæ›´åˆ—è¡¨)
        """
        changes = []

        # æ­£å‰‡è¡¨é”å¼: åŒ¹é… [[AuthorYearNumber]] æ ¼å¼
        # æ•ç²ç¾¤çµ„: 1=Author, 2=Year(4ä½), 3=Number(2-3ä½)
        pattern = r'\[\[([A-Za-z]+)(\d{4})(\d{2,3})\]\]'

        # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
        matches = list(re.finditer(pattern, body))

        if matches:
            # æ›¿æ›å‡½æ•¸ï¼šè‡ªå‹•è£œé›¶åˆ° 3 ä½æ•¸
            def fix_link(match):
                author = match.group(1)
                year = match.group(2)
                number = match.group(3).zfill(3)  # è£œé›¶åˆ° 3 ä½æ•¸
                return f"[[{author}-{year}-{number}]]"

            fixed_body = re.sub(pattern, fix_link, body)

            # è¨˜éŒ„è®Šæ›´
            unique_fixes = set()
            for match in matches:
                old_format = match.group(0)
                number_fixed = match.group(3).zfill(3)
                new_format = f"[[{match.group(1)}-{match.group(2)}-{number_fixed}]]"
                unique_fixes.add((old_format, new_format))

            for old, new in unique_fixes:
                changes.append(f"ä¿®å¾©é€£çµæ ¼å¼: {old} â†’ {new}")

            self.stats['fixes']['links'] += len(unique_fixes)

            return fixed_body, changes

        return body, changes

    def remove_redundant_sections(self, body: str) -> Tuple[str, List[str]]:
        """
        è¦å‰‡ 3: ç§»é™¤å†—é¤˜å€å¡Š

        - ç§»é™¤å†—é¤˜ H1 æ¨™é¡Œï¼ˆå¦‚ã€Œ# å¿ƒç†æ¨¡æ“¬...ã€ï¼‰
        - ç§»é™¤ã€Œ> **æ ¸å¿ƒ**: ...ã€å¼•ç”¨å€å¡Š

        Returns:
            (ä¿®å¾©å¾Œçš„æ­£æ–‡, è®Šæ›´åˆ—è¡¨)
        """
        changes = []
        original_body = body

        # ç§»é™¤ H1 æ¨™é¡Œï¼ˆåœ¨ç¬¬ä¸€å€‹ ## ä¹‹å‰ï¼‰
        h1_pattern = r'^#+\s+.+?\n'
        match = re.match(h1_pattern, body.lstrip(), re.MULTILINE)
        if match:
            h1_line = match.group(0).strip()
            body = re.sub(r'^#+\s+.+?\n+', '', body.lstrip(), count=1)
            changes.append(f"ç§»é™¤å†—é¤˜ H1: {h1_line[:50]}...")
            self.stats['fixes']['redundant_h1'] += 1

        # ç§»é™¤ã€Œæ ¸å¿ƒã€å¼•ç”¨å€å¡Š
        core_pattern = r'>\s*\*\*æ ¸å¿ƒ\*\*:\s*\[.+?\]\s*\n+'
        match = re.search(core_pattern, body)
        if match:
            core_text = match.group(0).strip()[:50]
            body = re.sub(core_pattern, '', body)
            changes.append(f"ç§»é™¤å†—é¤˜ã€Œæ ¸å¿ƒã€å€å¡Š: {core_text}...")
            self.stats['fixes']['redundant_core'] += 1

        return body, changes

    def normalize_spacing(self, frontmatter: str, body: str) -> Tuple[str, List[str]]:
        """
        è¦å‰‡ 4: æ¨™æº–åŒ–ç©ºè¡Œ

        - frontmatter å¾Œå›ºå®š 1 å€‹ç©ºè¡Œ
        - èªªæ˜æ®µè½å¾Œ: 1 å€‹ç©ºè¡Œ
        - ## é€£çµç¶²çµ¡å¾Œ: 2 å€‹ç©ºè¡Œ
        - é€£çµé …ä¹‹é–“: 2 å€‹ç©ºè¡Œ
        - æœ€å¾Œé€£çµé …å¾Œ: 3 å€‹ç©ºè¡Œï¼ˆåœ¨ ## ä¾†æºè„ˆçµ¡å‰ï¼‰
        - å…¶ä»–å€æ®µé–“: 2 å€‹ç©ºè¡Œ
        - æ–‡ä»¶çµå°¾ä¿ç•™ 1 å€‹ç©ºè¡Œ

        Returns:
            (ä¿®å¾©å¾Œçš„å®Œæ•´å…§å®¹, è®Šæ›´åˆ—è¡¨)
        """
        changes = []

        # é‡çµ„å…§å®¹
        content = f"---\n{frontmatter}\n---\n"

        # frontmatter å¾Œ 1 å€‹ç©ºè¡Œ
        content += "\n"

        # æ¸…ç†æ­£æ–‡å¤šé¤˜ç©ºè¡Œ
        body = body.strip()

        # æ¨™æº–åŒ–å€æ®µé–“ç©ºè¡Œ
        body_lines = body.split('\n')
        normalized_lines = []

        i = 0
        while i < len(body_lines):
            line = body_lines[i]

            # æª¢æŸ¥æ˜¯å¦ç‚ºå€æ®µæ¨™é¡Œ
            if line.startswith('## '):
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€å€‹å€æ®µï¼Œå‰é¢åŠ é©ç•¶ç©ºè¡Œ
                if normalized_lines:
                    # ç§»é™¤å‰é¢çš„æ‰€æœ‰ç©ºè¡Œ
                    while normalized_lines and normalized_lines[-1] == '':
                        normalized_lines.pop()

                    # æª¢æŸ¥å‰ä¸€å€‹å€æ®µæ˜¯å¦ç‚ºã€Œé€£çµç¶²çµ¡ã€
                    is_after_link_section = False
                    for prev_line in reversed(normalized_lines):
                        if prev_line.startswith('## '):
                            if 'é€£çµç¶²çµ¡' in prev_line:
                                is_after_link_section = True
                            break

                    # ã€Œ## ä¾†æºè„ˆçµ¡ã€åœ¨ã€Œé€£çµç¶²çµ¡ã€å¾Œéœ€è¦ 3 å€‹ç©ºè¡Œï¼Œå…¶ä»–æƒ…æ³ 2 å€‹
                    if is_after_link_section and 'ä¾†æº' in line:
                        normalized_lines.extend(['', '', ''])
                    else:
                        normalized_lines.extend(['', ''])

                normalized_lines.append(line)
            else:
                normalized_lines.append(line)

            i += 1

        body = '\n'.join(normalized_lines)

        # æ–‡ä»¶çµå°¾ä¿ç•™ 1 å€‹ç©ºè¡Œ
        content += body
        content = content.rstrip() + '\n'

        changes.append("æ¨™æº–åŒ–ç©ºè¡Œæ ¼å¼")
        self.stats['fixes']['spacing'] += 1

        return content, changes

    def process_batch(self, folder_path: Path, pattern: str = "*.md") -> Dict:
        """
        æ‰¹æ¬¡è™•ç†è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰å¡ç‰‡

        Args:
            folder_path: è³‡æ–™å¤¾è·¯å¾‘
            pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼

        Returns:
            è™•ç†çµ±è¨ˆä¿¡æ¯
        """
        # éè¿´æŸ¥æ‰¾æ‰€æœ‰å¡ç‰‡
        card_files = list(folder_path.rglob(pattern))

        # éæ¿¾æ‰ç´¢å¼•æ–‡ä»¶
        card_files = [f for f in card_files if 'zettel_index' not in f.name]

        self.stats['total'] = len(card_files)

        print(f"\nğŸ” æ‰¾åˆ° {len(card_files)} å¼µ Zettelkasten å¡ç‰‡")
        print(f"{'[DRY-RUN] ' if self.dry_run else ''}é–‹å§‹è™•ç†...\n")

        # æŒ‰è³‡æ–™å¤¾åˆ†çµ„å¡ç‰‡ï¼ˆæé«˜æ•ˆç‡ï¼šæ¯å€‹è³‡æ–™å¤¾åªè§£æä¸€æ¬¡ zettel_index.mdï¼‰
        cards_by_folder = {}
        for card_file in card_files:
            zettel_folder = card_file.parent.parent  # zettel_xxx_20251104
            if zettel_folder not in cards_by_folder:
                cards_by_folder[zettel_folder] = []
            cards_by_folder[zettel_folder].append(card_file)

        # ç‚ºæ¯å€‹è³‡æ–™å¤¾è™•ç†å¡ç‰‡
        processed = 0
        for zettel_folder, cards in cards_by_folder.items():
            # é å…ˆè§£æè©²è³‡æ–™å¤¾çš„ zettel_index.md
            sample_card = cards[0]
            index_data = self._parse_zettel_index(sample_card)

            if not index_data:
                print(f"âš ï¸ è­¦å‘Š: ç„¡æ³•è§£æ {zettel_folder.name}/zettel_index.mdï¼Œè·³é {len(cards)} å¼µå¡ç‰‡")
                self.stats['errors'] += len(cards)
                continue

            # è™•ç†è©²è³‡æ–™å¤¾çš„æ‰€æœ‰å¡ç‰‡
            for card_file in cards:
                processed += 1
                print(f"[{processed}/{len(card_files)}] è™•ç†: {card_file.name}", end=' ')

                success, changes = self.fix_card(card_file, index_data)

                if success:
                    if changes:
                        print("âœ… å·²ä¿®å¾©")
                        for change in changes:
                            print(f"    - {change}")
                    else:
                        print("â­ï¸  ç„¡éœ€ä¿®å¾©")
                else:
                    print("âŒ å¤±æ•—")
                    for error in changes:
                        print(f"    ! {error}")

        return self.get_stats()

    def get_stats(self) -> Dict:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        return self.stats

    def print_summary(self):
        """æ‰“å°è™•ç†æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š è™•ç†æ‘˜è¦")
        print("=" * 60)
        print(f"ç¸½å¡ç‰‡æ•¸: {self.stats['total']}")
        print(f"å·²ä¿®å¾©: {self.stats['fixed']} âœ…")
        print(f"ç„¡éœ€ä¿®å¾©: {self.stats['skipped']} â­ï¸")
        print(f"å¤±æ•—: {self.stats['errors']} âŒ")
        print(f"\nä¿®å¾©è©³æƒ…:")
        print(f"  - Summary æ¸…ç†: {self.stats['fixes']['summary']}")
        print(f"  - é€£çµæ ¼å¼ä¿®å¾©: {self.stats['fixes']['links']}")
        print(f"  - ç§»é™¤å†—é¤˜ H1: {self.stats['fixes']['redundant_h1']}")
        print(f"  - ç§»é™¤å†—é¤˜ã€Œæ ¸å¿ƒã€: {self.stats['fixes']['redundant_core']}")
        print(f"  - ç©ºè¡Œæ¨™æº–åŒ–: {self.stats['fixes']['spacing']}")

        if self.dry_run:
            print("\nâš ï¸  DRY-RUN æ¨¡å¼: æœªå¯¦éš›ä¿®æ”¹ä»»ä½•æ–‡ä»¶")
        else:
            print(f"\nâœ… å·²å¯«å…¥ {self.stats['fixed']} å¼µå¡ç‰‡çš„ä¿®å¾©")

    def fix_index_mermaid(self, index_path: Path) -> Tuple[bool, List[str]]:
        """
        ä¿®å¾© zettel_index.md ä¸­ mermaid åœ–è¡¨çš„é€£çµæ ¼å¼éŒ¯èª¤

        å•é¡Œç¯„ä¾‹ï¼ˆWu-2020ï¼‰:
        - Wu-2020-001 --> Wu2020002  # âŒ ç›®æ¨™ç¯€é»ç¼ºå°‘é€£å­—è™Ÿ
        - Wu2020001 --> Wu-2020-002  # âŒ ä¾†æºç¯€é»ç¼ºå°‘é€£å­—è™Ÿ
        - Wu-2020-009 --> Wu202010   # âŒ æ‹¼å¯«éŒ¯èª¤

        ä¿®å¾©:
        - çµ±ä¸€ç‚º Author-Year-Number æ ¼å¼
        - ç§»é™¤éå¤šç©ºè¡Œï¼ˆ3+ å€‹ â†’ 1-2 å€‹ï¼‰
        - ç§»é™¤é‡è¤‡é€£çµ

        Returns:
            (æ˜¯å¦æˆåŠŸ, è®Šæ›´åˆ—è¡¨)
        """
        changes = []

        try:
            # è®€å– zettel_index.md
            content = index_path.read_text(encoding='utf-8')
            original_content = content

            # æ‰¾åˆ° mermaid åœ–è¡¨å€åŸŸ
            mermaid_pattern = r'```mermaid\n(.*?)\n```'
            mermaid_match = re.search(mermaid_pattern, content, re.DOTALL)

            if not mermaid_match:
                return False, ["â­ï¸ ç„¡ mermaid åœ–è¡¨"]

            mermaid_content = mermaid_match.group(1)
            original_mermaid = mermaid_content

            # ä¿®å¾© 1a: ä¿®å¾©ç¯€é» ID æ ¼å¼ï¼ˆAuthorYearNumber â†’ Author-Year-Numberï¼‰
            # åŒ¹é…æ¨¡å¼: Wu2020002 æˆ– Wu202010 (ç¼ºå°‘é€£å­—è™Ÿ)
            pattern1 = r'\b([A-Za-z]+)(\d{4})(\d{2,3})\b'

            def fix_node_id(match):
                author = match.group(1)
                year = match.group(2)
                number = match.group(3)

                # è£œé½Šç‚ºä¸‰ä½æ•¸ï¼ˆWu202010 â†’ Wu-2020-010, Wu20209 â†’ Wu-2020-009ï¼‰
                number = number.zfill(3)

                return f"{author}-{year}-{number}"

            fixed_mermaid = re.sub(pattern1, fix_node_id, mermaid_content)

            # ä¿®å¾© 1b: ä¿®æ­£å·²æœ‰é€£å­—è™Ÿä½†æ•¸å­—éŒ¯èª¤çš„ç¯€é» ID
            # ä¾‹å¦‚: Wu-2020-100 â†’ Wu-2020-010 (ä¹‹å‰éŒ¯èª¤ä¿®å¾©çš„çµæœ)
            pattern2 = r'\b([A-Za-z]+-\d{4}-)(1\d{2})\b'  # åŒ¹é… 100-199

            def fix_wrong_number(match):
                prefix = match.group(1)  # "Wu-2020-"
                wrong_number = match.group(2)  # "100"

                # ä¿®å¾©é‚è¼¯ï¼šä¹‹å‰éŒ¯èª¤åœ°åœ¨å³å´è£œé›¶ï¼Œç¾åœ¨æ”¹ç‚ºå·¦å´è£œé›¶
                # "10" + "0" = "100" (éŒ¯èª¤) â†’ "0" + "10" = "010" (æ­£ç¢º)
                # æ–¹æ³•ï¼šç§»é™¤æœ€å¾Œçš„ '0'ï¼ŒåŠ åˆ°å‰é¢
                if wrong_number[0] == '1' and wrong_number[2] == '0':
                    correct_number = '0' + wrong_number[:-1]  # "100" â†’ "010"
                    return f"{prefix}{correct_number}"
                return match.group(0)  # ä¿æŒä¸è®Š

            fixed_mermaid = re.sub(pattern2, fix_wrong_number, fixed_mermaid)

            # ä¿®å¾© 1c: ç§»é™¤æŒ‡å‘ "000" çš„éŒ¯èª¤é€£çµï¼ˆå› ç‚ºæ²’æœ‰ 000 å¡ç‰‡ï¼‰
            # é€™é€šå¸¸æ˜¯æ•¸æ“šéŒ¯èª¤ç”¢ç”Ÿçš„å¹»å½±é€£çµ
            pattern3 = r'^\s*.+ --> .+-000\s*$'
            lines_before_000_removal = fixed_mermaid.split('\n')
            lines_after_000_removal = [
                line for line in lines_before_000_removal
                if not re.match(pattern3, line)
            ]

            if len(lines_after_000_removal) < len(lines_before_000_removal):
                removed_000_count = len(lines_before_000_removal) - len(lines_after_000_removal)
                changes.append(f"ç§»é™¤ {removed_000_count} å€‹æŒ‡å‘ '000' çš„éŒ¯èª¤é€£çµ")
                fixed_mermaid = '\n'.join(lines_after_000_removal)

            if fixed_mermaid != mermaid_content:
                changes.append("ä¿®å¾© mermaid ç¯€é» ID æ ¼å¼")

            # ä¿®å¾© 2: ç§»é™¤éå¤šç©ºè¡Œï¼ˆ3+ å€‹ç©ºè¡Œ â†’ 2 å€‹ç©ºè¡Œï¼‰
            fixed_mermaid = re.sub(r'\n{4,}', '\n\n', fixed_mermaid)

            if fixed_mermaid != mermaid_content and "ä¿®å¾© mermaid ç¯€é» ID æ ¼å¼" in changes:
                changes.append("æ¨™æº–åŒ– mermaid åœ–è¡¨ç©ºè¡Œ")
            elif fixed_mermaid != mermaid_content:
                changes.append("æ¨™æº–åŒ– mermaid åœ–è¡¨ç©ºè¡Œ")

            # ä¿®å¾© 3: ç§»é™¤é‡è¤‡é€£çµ
            lines = fixed_mermaid.split('\n')
            seen_links = set()
            deduplicated_lines = []

            for line in lines:
                stripped = line.strip()
                # æª¢æŸ¥æ˜¯å¦ç‚ºé€£çµè¡Œï¼ˆmermaid çš„ --> æˆ– -.-> é€£çµï¼‰
                is_link_line = ' --> ' in line or ' -.-> ' in line

                if is_link_line:
                    if stripped not in seen_links:
                        seen_links.add(stripped)
                        deduplicated_lines.append(line)
                    # å¦‚æœé‡è¤‡ï¼Œè·³éæ­¤è¡Œ
                else:
                    # éé€£çµè¡Œï¼Œç›´æ¥ä¿ç•™
                    deduplicated_lines.append(line)

            if len(deduplicated_lines) < len(lines):
                removed_count = len(lines) - len(deduplicated_lines)
                changes.append(f"ç§»é™¤ {removed_count} å€‹é‡è¤‡é€£çµ")

            fixed_mermaid = '\n'.join(deduplicated_lines)

            # æ›¿æ›åŸå§‹å…§å®¹ä¸­çš„ mermaid å€åŸŸ
            if fixed_mermaid != original_mermaid:
                content = content.replace(
                    f"```mermaid\n{original_mermaid}\n```",
                    f"```mermaid\n{fixed_mermaid}\n```"
                )

            # å¯«å…¥ä¿®å¾©çµæœ
            if content != original_content:
                if not self.dry_run:
                    index_path.write_text(content, encoding='utf-8')
                return True, changes
            else:
                return False, ["â­ï¸ ç„¡éœ€ä¿®å¾©"]

        except Exception as e:
            return False, [f"âŒ éŒ¯èª¤: {str(e)}"]

    def batch_fix_indices(self, root_folder: Path) -> Dict:
        """
        æ‰¹æ¬¡ä¿®å¾©æ‰€æœ‰ zettel_index.md æ–‡ä»¶

        Args:
            root_folder: Zettelkasten æ ¹ç›®éŒ„

        Returns:
            çµ±è¨ˆä¿¡æ¯å­—å…¸
        """
        stats = {
            'total': 0,
            'fixed': 0,
            'skipped': 0,
            'errors': 0
        }

        # æŸ¥æ‰¾æ‰€æœ‰ zettel_index.md æ–‡ä»¶
        index_files = list(root_folder.glob("*/zettel_index.md"))
        stats['total'] = len(index_files)

        print(f"ğŸ” æ‰¾åˆ° {stats['total']} å€‹ zettel_index.md æ–‡ä»¶")
        print("é–‹å§‹ä¿®å¾© mermaid åœ–è¡¨...\n")

        for i, index_file in enumerate(index_files, 1):
            folder_name = index_file.parent.name
            print(f"[{i}/{stats['total']}] è™•ç†: {folder_name}", end=' ')

            success, changes = self.fix_index_mermaid(index_file)

            if success:
                stats['fixed'] += 1
                print("âœ… å·²ä¿®å¾©")
                for change in changes:
                    print(f"    - {change}")
            elif changes and changes[0].startswith("â­ï¸"):
                stats['skipped'] += 1
                print(changes[0])
            else:
                stats['errors'] += 1
                print("âŒ å¤±æ•—")
                for error in changes:
                    print(f"    ! {error}")

        # æ‰“å°æ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š Mermaid åœ–è¡¨ä¿®å¾©æ‘˜è¦")
        print("=" * 60)
        print(f"ç¸½ index æ–‡ä»¶æ•¸: {stats['total']}")
        print(f"å·²ä¿®å¾©: {stats['fixed']} âœ…")
        print(f"ç„¡éœ€ä¿®å¾©: {stats['skipped']} â­ï¸")
        print(f"å¤±æ•—: {stats['errors']} âŒ")

        if self.dry_run:
            print("\nâš ï¸  DRY-RUN æ¨¡å¼: æœªå¯¦éš›ä¿®æ”¹ä»»ä½•æ–‡ä»¶")
        else:
            print(f"\nâœ… å·²ä¿®å¾© {stats['fixed']} å€‹ zettel_index.md æ–‡ä»¶")

        return stats


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description='Zettelkasten æ ¼å¼ä¿®å¾©å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # Dry-run æ¨¡å¼é è¦½è®Šæ›´
  python zettel_format_fixer.py --file card.md --dry-run

  # ä¿®å¾©å–®å¼µå¡ç‰‡
  python zettel_format_fixer.py --file output/zettel_Barsalou-2009_20251104/zettel_cards/Barsalou-2009-005.md

  # æ‰¹æ¬¡ä¿®å¾©è³‡æ–™å¤¾
  python zettel_format_fixer.py --batch output/zettelkasten_notes/

  # æ‰¹æ¬¡ä¿®å¾©å¡ç‰‡ä¸¦ä¿®å¾© mermaid åœ–è¡¨
  python zettel_format_fixer.py --batch output/zettelkasten_notes/ --fix-index

  # æ‰¹æ¬¡ä¿®å¾©ä¸¦ç”Ÿæˆå ±å‘Š
  python zettel_format_fixer.py --batch output/zettelkasten_notes/ --fix-index --report fix_report.md
        """
    )

    parser.add_argument('--file', type=str, help='å–®å¼µå¡ç‰‡æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--batch', type=str, help='æ‰¹æ¬¡è™•ç†è³‡æ–™å¤¾è·¯å¾‘')
    parser.add_argument('--fix-index', action='store_true', help='ä¿®å¾© zettel_index.md ä¸­çš„ mermaid åœ–è¡¨')
    parser.add_argument('--dry-run', action='store_true', help='Dry-run æ¨¡å¼ï¼ˆåƒ…é è¦½ï¼Œä¸ä¿®æ”¹ï¼‰')
    parser.add_argument('--report', type=str, help='ç”Ÿæˆä¿®å¾©å ±å‘Šæ–‡ä»¶è·¯å¾‘')

    args = parser.parse_args()

    # æª¢æŸ¥åƒæ•¸
    if not args.file and not args.batch:
        parser.print_help()
        sys.exit(1)

    # å‰µå»ºä¿®å¾©å™¨
    fixer = ZettelFormatFixer(dry_run=args.dry_run)

    # å–®æ–‡ä»¶æ¨¡å¼
    if args.file:
        card_path = Path(args.file)
        if not card_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {card_path}")
            sys.exit(1)

        print(f"\nğŸ”§ ä¿®å¾©å¡ç‰‡: {card_path.name}\n")
        success, changes = fixer.fix_card(card_path)

        if success:
            if changes:
                print("âœ… ä¿®å¾©æˆåŠŸ")
                for change in changes:
                    print(f"  - {change}")
            else:
                print("â­ï¸  ç„¡éœ€ä¿®å¾©")
        else:
            print("âŒ ä¿®å¾©å¤±æ•—")
            for error in changes:
                print(f"  ! {error}")

    # æ‰¹æ¬¡æ¨¡å¼
    elif args.batch:
        batch_path = Path(args.batch)
        if not batch_path.exists():
            print(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {batch_path}")
            sys.exit(1)

        stats = fixer.process_batch(batch_path)
        fixer.print_summary()

        # å¦‚æœæŒ‡å®š --fix-indexï¼Œä¿®å¾© zettel_index.md çš„ mermaid åœ–è¡¨
        if args.fix_index:
            print("\n" + "=" * 60)
            print("ğŸ”§ é–‹å§‹ä¿®å¾© zettel_index.md çš„ mermaid åœ–è¡¨")
            print("=" * 60 + "\n")
            index_stats = fixer.batch_fix_indices(batch_path)

        # ç”Ÿæˆå ±å‘Š
        if args.report:
            report_path = Path(args.report)
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(f"# Zettelkasten æ ¼å¼ä¿®å¾©å ±å‘Š\n\n")
                f.write(f"**ç”Ÿæˆæ™‚é–“**: {Path().resolve()}\n")
                f.write(f"**æ¨¡å¼**: {'DRY-RUN' if args.dry_run else 'LIVE'}\n\n")
                f.write(f"## çµ±è¨ˆæ‘˜è¦\n\n")
                f.write(f"- ç¸½å¡ç‰‡æ•¸: {stats['total']}\n")
                f.write(f"- å·²ä¿®å¾©: {stats['fixed']}\n")
                f.write(f"- ç„¡éœ€ä¿®å¾©: {stats['skipped']}\n")
                f.write(f"- å¤±æ•—: {stats['errors']}\n\n")
                f.write(f"## ä¿®å¾©è©³æƒ…\n\n")
                f.write(f"- Summary æ¸…ç†: {stats['fixes']['summary']}\n")
                f.write(f"- é€£çµæ ¼å¼ä¿®å¾©: {stats['fixes']['links']}\n")
                f.write(f"- ç§»é™¤å†—é¤˜ H1: {stats['fixes']['redundant_h1']}\n")
                f.write(f"- ç§»é™¤å†—é¤˜ã€Œæ ¸å¿ƒã€: {stats['fixes']['redundant_core']}\n")
                f.write(f"- ç©ºè¡Œæ¨™æº–åŒ–: {stats['fixes']['spacing']}\n")

            print(f"\nğŸ“ å ±å‘Šå·²ç”Ÿæˆ: {report_path}")


if __name__ == '__main__':
    main()
