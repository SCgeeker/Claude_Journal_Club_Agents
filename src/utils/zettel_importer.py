#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Zettel å¡ç‰‡åŒ¯å…¥æ¨¡çµ„

ç”¨æ–¼å°‡ç¾æœ‰çš„ Zettelkasten å¡ç‰‡åŒ¯å…¥çŸ¥è­˜åº«ã€‚
æ”¯æ´å–®ä¸€è³‡æ–™å¤¾æˆ–æ‰¹æ¬¡åŒ¯å…¥ã€‚
"""

import re
import yaml
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass


@dataclass
class ImportResult:
    """åŒ¯å…¥çµæœ"""
    folder: str
    total_cards: int
    imported: int
    skipped: int
    errors: int
    paper_id: Optional[int] = None
    cite_key: Optional[str] = None


def parse_zettel_index(index_path: Path) -> Optional[Dict]:
    """
    è§£æ zettel_index.md æª”æ¡ˆ

    Args:
        index_path: ç´¢å¼•æª”æ¡ˆè·¯å¾‘

    Returns:
        è§£æçµæœå­—å…¸ï¼ŒåŒ…å« cite_keyã€paper_titleã€authorsã€yearã€card_count
    """
    try:
        content = index_path.read_text(encoding='utf-8')

        # æå– YAML front matter
        yaml_match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
        if not yaml_match:
            return None

        metadata = yaml.safe_load(yaml_match.group(1))

        return {
            'cite_key': metadata.get('title', ''),  # title æ¬„ä½å­˜çš„æ˜¯ cite_key
            'paper_title': metadata.get('paper_title', ''),
            'authors': metadata.get('authors', ''),
            'year': metadata.get('year'),
            'card_count': metadata.get('card_count', 0),
            'generated_date': metadata.get('generated_date', '')
        }

    except Exception as e:
        print(f"  [ERROR] è§£æç´¢å¼•æª”æ¡ˆå¤±æ•—ï¼š{e}")
        return None


def find_paper_by_citekey(kb, cite_key: str) -> Optional[int]:
    """
    åœ¨çŸ¥è­˜åº«ä¸­æŸ¥æ‰¾å°æ‡‰çš„è«–æ–‡

    Args:
        kb: KnowledgeBaseManager å¯¦ä¾‹
        cite_key: è«–æ–‡ cite_key

    Returns:
        paper_id æˆ– None
    """
    try:
        paper = kb.get_paper_by_citekey(cite_key)
        if paper:
            return paper['id']

        # å˜—è©¦æ¨¡ç³ŠåŒ¹é…ï¼ˆç§»é™¤å¹´ä»½å¾Œç¶´ï¼‰
        base_key = re.sub(r'-\d{4}[a-z]?$', '', cite_key)
        papers = kb.search_papers(base_key, limit=5)
        for p in papers:
            if p.get('cite_key') and base_key.lower() in p['cite_key'].lower():
                return p['id']

        return None

    except Exception:
        return None


def _find_bib_entry(cite_key: str, bib_entries: Dict):
    """
    åœ¨ bib_entries ä¸­æŸ¥æ‰¾å°æ‡‰çš„æ¢ç›®ï¼ˆæ”¯æ´ Unicode æ­£è¦åŒ–æ¯”å°ï¼‰

    Args:
        cite_key: è¦æŸ¥æ‰¾çš„ cite_key
        bib_entries: BibTeX æ¢ç›®å­—å…¸ {cite_key: BibTeXEntry}

    Returns:
        åŒ¹é…çš„ BibTeXEntry æˆ– None
    """
    from src.utils.citekey_resolver import normalize_citekey

    # 1. ç²¾ç¢ºåŒ¹é…
    if cite_key in bib_entries:
        return bib_entries[cite_key]

    # 2. å¿½ç•¥å¤§å°å¯«åŒ¹é…
    cite_key_lower = cite_key.lower()
    for key, entry in bib_entries.items():
        if key.lower() == cite_key_lower:
            return entry

    # 3. Unicode æ­£è¦åŒ–åŒ¹é…ï¼ˆè™•ç† Ã©â†’e, Ã¼â†’ue ç­‰ï¼‰
    cite_key_normalized = normalize_citekey(cite_key).lower()
    for key, entry in bib_entries.items():
        if normalize_citekey(key).lower() == cite_key_normalized:
            return entry

    return None


def add_paper_from_bib(kb, cite_key: str, bib_entries: Dict) -> Optional[int]:
    """
    å¾ BibTeX è³‡æ–™æ–°å¢è«–æ–‡åˆ°çŸ¥è­˜åº«

    Args:
        kb: KnowledgeBaseManager å¯¦ä¾‹
        cite_key: è«–æ–‡ cite_key
        bib_entries: BibTeX æ¢ç›®å­—å…¸ {cite_key: BibTeXEntry}

    Returns:
        æ–°å¢çš„ paper_id æˆ– None
    """
    entry = _find_bib_entry(cite_key, bib_entries)
    if entry is None:
        return None

    try:
        # å»ºç«‹è«–æ–‡ Markdown æª”æ¡ˆè·¯å¾‘
        from pathlib import Path
        papers_dir = Path("knowledge_base/papers")
        papers_dir.mkdir(parents=True, exist_ok=True)

        # å»ºç«‹æª”æ¡ˆåç¨±
        safe_key = re.sub(r'[^\w\-]', '_', cite_key)
        file_path = papers_dir / f"{safe_key}.md"

        # å»ºç«‹åŸºæœ¬ Markdown å…§å®¹
        authors_str = ', '.join(entry.authors) if entry.authors else ''
        keywords_str = ', '.join(entry.keywords) if entry.keywords else ''

        content = f"""---
title: "{entry.title}"
authors: "{authors_str}"
year: {entry.year or ''}
keywords: [{keywords_str}]
doi: "{entry.doi or ''}"
cite_key: "{entry.cite_key}"
---

# {entry.title}

## æ‘˜è¦

{entry.abstract or 'ï¼ˆç„¡æ‘˜è¦ï¼‰'}

## ä¾†æº

- DOI: {entry.doi or 'N/A'}
- æœŸåˆŠ: {entry.journal or entry.booktitle or 'N/A'}
"""

        # å¯«å…¥æª”æ¡ˆ
        file_path.write_text(content, encoding='utf-8')

        # æ–°å¢åˆ°çŸ¥è­˜åº«
        paper_id = kb.add_paper(
            file_path=str(file_path),
            title=entry.title,
            authors=entry.authors,
            year=entry.year,
            keywords=entry.keywords,
            doi=entry.doi,
            cite_key=entry.cite_key,
            abstract=entry.abstract,
            source='bib_import'
        )

        return paper_id

    except Exception as e:
        print(f"  [ERROR] å¾ bib æ–°å¢è«–æ–‡å¤±æ•—: {e}")
        return None


def import_zettel_folder(
    folder_path: Path,
    kb,
    embed: bool = False,
    dry_run: bool = False,
    bib_entries: Dict = None
) -> ImportResult:
    """
    åŒ¯å…¥å–®ä¸€ Zettelkasten è³‡æ–™å¤¾

    Args:
        folder_path: Zettel è³‡æ–™å¤¾è·¯å¾‘
        kb: KnowledgeBaseManager å¯¦ä¾‹
        embed: æ˜¯å¦ç”Ÿæˆå‘é‡åµŒå…¥
        dry_run: é è¦½æ¨¡å¼ï¼ˆä¸å¯¦éš›å¯«å…¥ï¼‰
        bib_entries: BibTeX æ¢ç›®å­—å…¸ï¼ˆç”¨æ–¼è‡ªå‹•æ–°å¢ç¼ºå¤±è«–æ–‡ï¼‰

    Returns:
        ImportResult
    """
    folder_name = folder_path.name
    result = ImportResult(
        folder=folder_name,
        total_cards=0,
        imported=0,
        skipped=0,
        errors=0
    )

    # 1. è§£æç´¢å¼•æª”æ¡ˆ
    index_path = folder_path / 'zettel_index.md'
    if not index_path.exists():
        print(f"  âš ï¸  æ‰¾ä¸åˆ°ç´¢å¼•æª”æ¡ˆï¼š{index_path}")
        result.errors = 1
        return result

    index_data = parse_zettel_index(index_path)
    if not index_data:
        result.errors = 1
        return result

    result.cite_key = index_data['cite_key']

    # 2. æŸ¥æ‰¾å°æ‡‰è«–æ–‡
    paper_id = find_paper_by_citekey(kb, index_data['cite_key'])

    # 2.1 å¦‚æœæ‰¾ä¸åˆ°ä¸”æœ‰ bib_entriesï¼Œå˜—è©¦å¾ bib æ–°å¢
    if not paper_id and bib_entries and not dry_run:
        paper_id = add_paper_from_bib(kb, index_data['cite_key'], bib_entries)
        if paper_id:
            print(f"  ğŸ“¥ å¾ bib æ–°å¢è«–æ–‡ ID: {paper_id}")

    result.paper_id = paper_id

    if paper_id:
        print(f"  ğŸ“„ é—œè¯è«–æ–‡ ID: {paper_id}")
    elif bib_entries and _find_bib_entry(index_data['cite_key'], bib_entries):
        print(f"  ğŸ“‹ [DRY RUN] å°‡å¾ bib æ–°å¢è«–æ–‡ï¼ˆcite_key: {index_data['cite_key']}ï¼‰")
    else:
        print(f"  âš ï¸  æœªæ‰¾åˆ°å°æ‡‰è«–æ–‡ï¼ˆcite_key: {index_data['cite_key']}ï¼‰")

    # 3. æƒæå¡ç‰‡è³‡æ–™å¤¾
    cards_folder = folder_path / 'zettel_cards'
    if not cards_folder.exists():
        print(f"  âš ï¸  æ‰¾ä¸åˆ°å¡ç‰‡è³‡æ–™å¤¾ï¼š{cards_folder}")
        result.errors = 1
        return result

    card_files = list(cards_folder.glob('*.md'))
    result.total_cards = len(card_files)

    if dry_run:
        print(f"  [DRY RUN] å°‡åŒ¯å…¥ {result.total_cards} å¼µå¡ç‰‡")
        return result

    # 4. åŒ¯å…¥å¡ç‰‡
    for card_file in card_files:
        card_data = kb.parse_zettel_card(str(card_file))
        if not card_data:
            result.errors += 1
            continue

        add_result = kb.add_zettel_card(card_data)

        if add_result['status'] == 'inserted':
            result.imported += 1
        elif add_result['status'] == 'duplicate':
            result.skipped += 1
        else:
            result.errors += 1
            continue

        # å»ºç«‹è«–æ–‡-å¡ç‰‡é—œè¯ï¼ˆç„¡è«–æ˜¯æ–°å¢æˆ–é‡è¤‡éƒ½å˜—è©¦å»ºç«‹ï¼‰
        if paper_id and add_result['card_id'] > 0:
            kb.link_paper_to_zettel(paper_id, add_result['card_id'], 1.0)

    # 5. å‘é‡åµŒå…¥ï¼ˆå¯é¸ï¼‰
    if embed and result.imported > 0:
        try:
            from integrations.vector_db import VectorDatabase
            from integrations.embedder import get_embedder

            vector_db = VectorDatabase()
            embedder = get_embedder(provider='google')

            for card_file in card_files:
                card_data = kb.parse_zettel_card(str(card_file))
                if card_data and card_data.get('content'):
                    embedding = embedder.embed(
                        card_data['content'][:2000],
                        task_type="retrieval_document"
                    )
                    vector_db.upsert_zettel(
                        embeddings=[embedding],
                        documents=[card_data['content'][:2000]],
                        ids=[card_data['zettel_id']],
                        metadatas=[{
                            'title': card_data.get('title', ''),
                            'core_concept': card_data.get('core_concept', ''),
                            'card_type': card_data.get('card_type', 'concept'),
                            'cite_key': result.cite_key
                        }]
                    )

        except Exception as e:
            print(f"  âš ï¸  å‘é‡åµŒå…¥å¤±æ•—ï¼š{e}")

    return result


def import_all_zettel_folders(
    base_path: Path,
    kb,
    embed: bool = False,
    dry_run: bool = False,
    bib_entries: Dict = None
) -> List[ImportResult]:
    """
    æ‰¹æ¬¡åŒ¯å…¥æ‰€æœ‰ Zettelkasten è³‡æ–™å¤¾

    Args:
        base_path: åŸºç¤è·¯å¾‘ï¼ˆé€šå¸¸æ˜¯ output/zettelkasten_notes/ï¼‰
        kb: KnowledgeBaseManager å¯¦ä¾‹
        embed: æ˜¯å¦ç”Ÿæˆå‘é‡åµŒå…¥
        dry_run: é è¦½æ¨¡å¼
        bib_entries: BibTeX æ¢ç›®å­—å…¸ï¼ˆç”¨æ–¼è‡ªå‹•æ–°å¢ç¼ºå¤±è«–æ–‡ï¼‰

    Returns:
        æ‰€æœ‰åŒ¯å…¥çµæœåˆ—è¡¨
    """
    results = []

    # æƒææ‰€æœ‰ zettel_ é–‹é ­çš„è³‡æ–™å¤¾
    zettel_folders = sorted(base_path.glob('zettel_*'))

    print(f"\næ‰¾åˆ° {len(zettel_folders)} å€‹ Zettel è³‡æ–™å¤¾")

    if bib_entries:
        print(f"ğŸ“š å·²è¼‰å…¥ {len(bib_entries)} ç­† BibTeX æ¢ç›®")

    for folder in zettel_folders:
        if not folder.is_dir():
            continue

        print(f"\nğŸ“ è™•ç†ï¼š{folder.name}")
        result = import_zettel_folder(folder, kb, embed=embed, dry_run=dry_run, bib_entries=bib_entries)
        results.append(result)

        # é¡¯ç¤ºçµæœ
        if not dry_run:
            print(f"   âœ… åŒ¯å…¥ {result.imported} / {result.total_cards} å¼µ")
            if result.skipped > 0:
                print(f"   â­ï¸  è·³é {result.skipped} å¼µé‡è¤‡")
            if result.errors > 0:
                print(f"   âŒ éŒ¯èª¤ {result.errors} å¼µ")

    return results


def summarize_import_results(results: List[ImportResult]) -> Dict:
    """
    çµ±è¨ˆåŒ¯å…¥çµæœ

    Args:
        results: åŒ¯å…¥çµæœåˆ—è¡¨

    Returns:
        çµ±è¨ˆæ‘˜è¦
    """
    total_folders = len(results)
    total_cards = sum(r.total_cards for r in results)
    total_imported = sum(r.imported for r in results)
    total_skipped = sum(r.skipped for r in results)
    total_errors = sum(r.errors for r in results)
    linked_papers = sum(1 for r in results if r.paper_id)

    return {
        'folders': total_folders,
        'total_cards': total_cards,
        'imported': total_imported,
        'skipped': total_skipped,
        'errors': total_errors,
        'linked_papers': linked_papers
    }
