#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen3-Embedding å¯¦éš›è«–æ–‡æ¸¬è©¦
ä½¿ç”¨ Guest-2025b.pdf é€²è¡Œå®Œæ•´æµç¨‹æ¸¬è©¦
"""

import sys
import io
import subprocess
import time
import requests
import numpy as np
from pathlib import Path

# è¨­ç½® UTF-8 ç·¨ç¢¼
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')


class Qwen3Embeddings:
    """Qwen3-Embedding-4B å°è£"""

    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model = "qwen3-embedding:4b"

    def embed(self, text: str) -> np.ndarray:
        """åµŒå…¥å–®å€‹æ–‡æœ¬"""
        response = requests.post(
            f"{self.base_url}/api/embeddings",
            json={"model": self.model, "prompt": text},
            timeout=60
        )
        response.raise_for_status()
        return np.array(response.json()['embedding'], dtype=np.float32)

    def check_available(self) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        try:
            # æ¸¬è©¦åµŒå…¥ç°¡å–®æ–‡æœ¬
            self.embed("test")
            return True
        except Exception as e:
            print(f"âŒ Qwen3-Embedding ä¸å¯ç”¨: {e}")
            return False


def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦"""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def main():
    print("=" * 70)
    print("Qwen3-Embedding å¯¦éš›è«–æ–‡æ¸¬è©¦")
    print("æ¸¬è©¦è«–æ–‡: Guest-2025b.pdf")
    print("=" * 70)

    # æª¢æŸ¥ PDF æ–‡ä»¶
    pdf_path = Path(r"D:\core\research\Program_verse\+\pdf\Guest-2025b.pdf")
    if not pdf_path.exists():
        print(f"âŒ éŒ¯èª¤: PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        return

    print(f"\nâœ… PDF æ–‡ä»¶å­˜åœ¨: {pdf_path.name} ({pdf_path.stat().st_size / 1024 / 1024:.1f} MB)")

    # åˆå§‹åŒ– embedder
    print("\nğŸ“ æ­¥é©Ÿ 1: åˆå§‹åŒ– Qwen3-Embedding")
    print("-" * 70)
    embedder = Qwen3Embeddings()

    print("æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§...")
    if not embedder.check_available():
        print("è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œä¸”å·²å®‰è£ qwen3-embedding:4b")
        print("åŸ·è¡Œ: ollama pull qwen3-embedding:4b")
        return

    print("âœ… Qwen3-Embedding-4B å¯ç”¨")

    # åˆ†æè«–æ–‡ä¸¦åŠ å…¥çŸ¥è­˜åº«
    print("\nğŸ“š æ­¥é©Ÿ 2: åˆ†æè«–æ–‡ä¸¦åŠ å…¥çŸ¥è­˜åº«")
    print("-" * 70)
    print("åŸ·è¡Œ: analyze_paper.py --pdf Guest-2025b.pdf --add-to-kb")

    cmd = [
        "python", "analyze_paper.py",
        "--pdf", str(pdf_path),
        "--add-to-kb",
        "--domain", "CogSci"
    ]

    print(f"å‘½ä»¤: {' '.join(cmd)}\n")

    start_time = time.time()
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=300
        )

        if result.returncode != 0:
            print("âŒ åˆ†æå¤±æ•—:")
            print(result.stderr)
            return

        print("âœ… è«–æ–‡åˆ†æå®Œæˆ")
        # å¾è¼¸å‡ºä¸­æå– paper_id
        for line in result.stdout.split('\n'):
            if 'paper_id' in line.lower() or 'id:' in line:
                print(f"   {line.strip()}")

    except subprocess.TimeoutExpired:
        print("âŒ åˆ†æè¶…æ™‚ï¼ˆ>5åˆ†é˜ï¼‰")
        return
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        return

    elapsed = time.time() - start_time
    print(f"   è€—æ™‚: {elapsed:.1f} ç§’")

    # å¾çŸ¥è­˜åº«ç²å–è«–æ–‡è³‡è¨Š
    print("\nğŸ“– æ­¥é©Ÿ 3: å¾çŸ¥è­˜åº«è®€å–è«–æ–‡è³‡è¨Š")
    print("-" * 70)

    from src.knowledge_base.kb_manager import KnowledgeBaseManager

    kb = KnowledgeBaseManager()
    papers = kb.list_papers()

    # æŸ¥æ‰¾å‰›åŠ å…¥çš„è«–æ–‡ï¼ˆæœ€æ–°çš„ï¼‰
    if not papers:
        print("âŒ çŸ¥è­˜åº«ç‚ºç©º")
        return

    # æŒ‰ ID æ’åºï¼Œå–æœ€å¾Œä¸€å€‹ï¼ˆæœ€æ–°ï¼‰
    papers_sorted = sorted(papers, key=lambda x: x['id'], reverse=True)
    paper = papers_sorted[0]

    print(f"âœ… æ‰¾åˆ°è«–æ–‡:")
    print(f"   ID: {paper['id']}")
    print(f"   æ¨™é¡Œ: {paper['title']}")
    print(f"   ä½œè€…: {paper['authors']}")
    print(f"   å¹´ä»½: {paper.get('year', 'N/A')}")
    print(f"   é—œéµè©: {paper.get('keywords', [])}")

    # è®€å–è«–æ–‡ Markdown å…§å®¹
    paper_md_path = Path(paper['file_path'])
    if not paper_md_path.exists():
        print(f"âŒ Markdown æ–‡ä»¶ä¸å­˜åœ¨: {paper_md_path}")
        return

    with open(paper_md_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # æå–æ‘˜è¦ï¼ˆå‰ 500 å­—å…ƒï¼‰
    abstract = content[:500] if len(content) > 500 else content
    print(f"\næ‘˜è¦é è¦½ (å‰ 500 å­—å…ƒ):")
    print(f"{abstract}...")

    # ç”Ÿæˆè«–æ–‡åµŒå…¥
    print("\nğŸ”¢ æ­¥é©Ÿ 4: ç”Ÿæˆè«–æ–‡å‘é‡åµŒå…¥")
    print("-" * 70)

    # çµ„åˆæ–‡æœ¬ï¼šæ¨™é¡Œ + æ‘˜è¦ + é—œéµè©
    text_to_embed = f"{paper['title']}. "
    if paper.get('keywords'):
        text_to_embed += f"Keywords: {', '.join(paper['keywords'])}. "
    text_to_embed += abstract

    print(f"æ–‡æœ¬é•·åº¦: {len(text_to_embed)} å­—å…ƒ")
    print("ç”ŸæˆåµŒå…¥ä¸­...")

    start_time = time.time()
    embedding = embedder.embed(text_to_embed)
    elapsed = time.time() - start_time

    print(f"âœ… åµŒå…¥ç”Ÿæˆå®Œæˆ")
    print(f"   ç¶­åº¦: {len(embedding)}")
    print(f"   è€—æ™‚: {elapsed:.2f} ç§’")
    print(f"   ç¯„åœ: [{embedding.min():.4f}, {embedding.max():.4f}]")
    print(f"   L2ç¯„æ•¸: {np.linalg.norm(embedding):.4f}")

    # æ¸¬è©¦èªç¾©æœç´¢
    print("\nğŸ” æ­¥é©Ÿ 5: æ¸¬è©¦èªç¾©æœç´¢")
    print("-" * 70)

    # ç”Ÿæˆä¸€äº›æŸ¥è©¢
    queries = [
        "èªçŸ¥ç§‘å­¸ç ”ç©¶æ–¹æ³•",
        "å¿ƒæ™ºæ¨¡æ“¬èˆ‡é æ¸¬",
        "æ·±åº¦å­¸ç¿’èˆ‡ç¥ç¶“ç¶²çµ¡",
        "çŸ¥è­˜è¡¨ç¤ºèˆ‡æ¨ç†",
    ]

    print(f"æ¸¬è©¦ {len(queries)} å€‹æŸ¥è©¢...")
    query_embeddings = []

    for i, query in enumerate(queries, 1):
        print(f"  [{i}/{len(queries)}] åµŒå…¥æŸ¥è©¢: {query}")
        q_emb = embedder.embed(query)
        query_embeddings.append(q_emb)

    # è¨ˆç®—ç›¸ä¼¼åº¦
    print("\nç›¸ä¼¼åº¦çµæœ:")
    similarities = []
    for i, (query, q_emb) in enumerate(zip(queries, query_embeddings)):
        sim = cosine_similarity(embedding, q_emb)
        similarities.append((query, sim))

        # åˆ¤æ–·ç›¸é—œæ€§
        if sim > 0.7:
            relevance = "é«˜åº¦ç›¸é—œ âœ…"
        elif sim > 0.5:
            relevance = "ä¸­åº¦ç›¸é—œ âš ï¸"
        else:
            relevance = "ä½åº¦ç›¸é—œ âŒ"

        print(f"{i+1}. [{sim:.4f}] {relevance}")
        print(f"   æŸ¥è©¢: {query}")

    # ä¿å­˜åµŒå…¥ï¼ˆç¤ºç¯„ï¼‰
    print("\nğŸ’¾ æ­¥é©Ÿ 6: ä¿å­˜å‘é‡åµŒå…¥ï¼ˆæ¨¡æ“¬ï¼‰")
    print("-" * 70)

    # å¯¦éš›å°ˆæ¡ˆä¸­æœƒä½¿ç”¨ ChromaDB æˆ– SQLite
    output_dir = Path("output/embeddings")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜ç‚º numpy æ ¼å¼
    embedding_file = output_dir / f"paper_{paper['id']}_qwen3.npy"
    np.save(embedding_file, embedding)

    print(f"âœ… åµŒå…¥å·²ä¿å­˜åˆ°: {embedding_file}")
    print(f"   æ–‡ä»¶å¤§å°: {embedding_file.stat().st_size / 1024:.1f} KB")

    # ç¸½çµ
    print("\n" + "=" * 70)
    print("âœ… æ¸¬è©¦å®Œæˆï¼")
    print("=" * 70)

    print(f"\næ¸¬è©¦ç¸½çµ:")
    print(f"  ğŸ“„ è«–æ–‡: {paper['title']}")
    print(f"  ğŸ“Š Paper ID: {paper['id']}")
    print(f"  ğŸ”¢ åµŒå…¥ç¶­åº¦: {len(embedding)}")
    print(f"  ğŸ’¾ åµŒå…¥æ–‡ä»¶: {embedding_file}")
    print(f"\n  ğŸ“ˆ æœ€ç›¸é—œæŸ¥è©¢:")
    # æ’åºä¸¦é¡¯ç¤º Top 2
    similarities.sort(key=lambda x: x[1], reverse=True)
    for i, (query, sim) in enumerate(similarities[:2], 1):
        print(f"     {i}. {query} (ç›¸ä¼¼åº¦: {sim:.4f})")

    print(f"\nä¸‹ä¸€æ­¥å»ºè­°:")
    print(f"  1. ä½¿ç”¨ ChromaDB æ•´åˆå‘é‡å­˜å„²")
    print(f"  2. ç‚ºå…¶é¤˜ {len(papers)-1} ç¯‡è«–æ–‡ç”ŸæˆåµŒå…¥")
    print(f"  3. å¯¦ä½œèªç¾©æœç´¢åŠŸèƒ½")
    print(f"  4. æ¸¬è©¦ Hybrid Searchï¼ˆFTS5 + Vectorï¼‰")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
