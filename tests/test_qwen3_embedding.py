#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦ Qwen3-Embedding-4B æ¨¡å‹
é©—è­‰ Ollama æœ¬åœ°éƒ¨ç½²çš„ embedding åŠŸèƒ½
"""

import requests
import numpy as np
import time
from typing import List
import sys
import io

# è¨­ç½® UTF-8 ç·¨ç¢¼ï¼ˆWindows ç›¸å®¹æ€§ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')


class Qwen3Embeddings:
    """Qwen3-Embedding-4B (Ollama) å°è£"""

    def __init__(self, base_url: str = "http://localhost:11434", model: str = "qwen3-embedding:4b"):
        self.base_url = base_url
        self.model = model

    def embed(self, text: str) -> np.ndarray:
        """åµŒå…¥å–®å€‹æ–‡æœ¬"""
        response = requests.post(
            f"{self.base_url}/api/embeddings",
            json={"model": self.model, "prompt": text}
        )
        response.raise_for_status()
        return np.array(response.json()['embedding'], dtype=np.float32)

    def embed_batch(self, texts: List[str]) -> np.ndarray:
        """æ‰¹æ¬¡åµŒå…¥"""
        embeddings = []
        for i, text in enumerate(texts):
            print(f"  [{i+1}/{len(texts)}] åµŒå…¥ä¸­: {text[:30]}...")
            embedding = self.embed(text)
            embeddings.append(embedding)
        return np.array(embeddings)


def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦"""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def main():
    print("=" * 60)
    print("Qwen3-Embedding-4B (Ollama) æ¸¬è©¦")
    print("=" * 60)

    # åˆå§‹åŒ–
    embedder = Qwen3Embeddings()

    # æ¸¬è©¦ 1: åŸºæœ¬åµŒå…¥
    print("\nğŸ“ æ¸¬è©¦ 1: åŸºæœ¬åµŒå…¥")
    print("-" * 60)
    text = "Zettelkasten æ˜¯ä¸€ç¨®åŸå­ç­†è¨˜æ–¹æ³•ï¼Œå¼·èª¿çŸ¥è­˜çš„åŸå­åŒ–å’Œé€£çµ"
    embedding = embedder.embed(text)
    print(f"æ–‡æœ¬: {text}")
    print(f"ç¶­åº¦: {len(embedding)}")
    print(f"å‰10å€‹å€¼: {embedding[:10]}")
    print(f"æ•¸å€¼ç¯„åœ: [{embedding.min():.4f}, {embedding.max():.4f}]")
    print(f"L2ç¯„æ•¸: {np.linalg.norm(embedding):.4f}")

    # æ¸¬è©¦ 2: èªç¾©ç›¸ä¼¼åº¦ï¼ˆç¹é«”ä¸­æ–‡ï¼‰
    print("\nğŸ“Š æ¸¬è©¦ 2: èªç¾©ç›¸ä¼¼åº¦ï¼ˆç¹é«”ä¸­æ–‡ï¼‰")
    print("-" * 60)

    test_cases = [
        ("Zettelkasten åŸå­ç­†è¨˜ç³»çµ±", "çŸ¥è­˜ç®¡ç†èˆ‡ç¬¬äºŒå¤§è…¦"),
        ("Zettelkasten åŸå­ç­†è¨˜ç³»çµ±", "æ·±åº¦å­¸ç¿’ç¥ç¶“ç¶²çµ¡"),
        ("èªçŸ¥ç§‘å­¸ç ”ç©¶æ–¹æ³•", "å¿ƒç†å­¸å¯¦é©—è¨­è¨ˆ"),
        ("èªçŸ¥ç§‘å­¸ç ”ç©¶æ–¹æ³•", "é‡å­ç‰©ç†ç†è«–"),
    ]

    print("æ‰¹æ¬¡åµŒå…¥ä¸­...")
    all_texts = [text for pair in test_cases for text in pair]
    all_embeddings = embedder.embed_batch(all_texts)

    print("\nç›¸ä¼¼åº¦çµæœ:")
    for i, (text1, text2) in enumerate(test_cases):
        emb1 = all_embeddings[i*2]
        emb2 = all_embeddings[i*2 + 1]
        similarity = cosine_similarity(emb1, emb2)

        # åˆ¤æ–·ç›¸ä¼¼åº¦ç­‰ç´š
        if similarity > 0.7:
            level = "é«˜ âœ…"
        elif similarity > 0.5:
            level = "ä¸­ âš ï¸"
        else:
            level = "ä½ âŒ"

        print(f"{i+1}. ç›¸ä¼¼åº¦: {similarity:.4f} ({level})")
        print(f"   A: {text1}")
        print(f"   B: {text2}")
        print()

    # æ¸¬è©¦ 3: æ‰¹æ¬¡è™•ç†æ•ˆèƒ½
    print("\nâš¡ æ¸¬è©¦ 3: æ‰¹æ¬¡è™•ç†æ•ˆèƒ½")
    print("-" * 60)

    batch_texts = [
        "çŸ¥è­˜ç®¡ç†ç³»çµ±çš„è¨­è¨ˆåŸå‰‡",
        "Zettelkasten ç­†è¨˜æ³•çš„æ ¸å¿ƒæ¦‚å¿µ",
        "ç¬¬äºŒå¤§è…¦èˆ‡å€‹äººçŸ¥è­˜åº«",
        "åŸå­åŒ–ç­†è¨˜èˆ‡é€£çµæ€ç¶­",
        "èªçŸ¥è² è·ç†è«–èˆ‡å­¸ç¿’æ•ˆç‡",
        "æ¦‚å¿µæ˜ å°„èˆ‡çŸ¥è­˜åœ–è­œ",
        "èªç¾©ç¶²çµ¡èˆ‡çŸ¥è­˜è¡¨ç¤º",
        "è³‡è¨Šæª¢ç´¢èˆ‡å…¨æ–‡æœç´¢",
        "å‘é‡åµŒå…¥èˆ‡èªç¾©ç›¸ä¼¼åº¦",
        "æ··åˆæœç´¢ç­–ç•¥èˆ‡æ’åºæ¼”ç®—æ³•",
    ]

    print(f"æ‰¹æ¬¡å¤§å°: {len(batch_texts)} å€‹æ–‡æœ¬")
    start_time = time.time()
    batch_embeddings = embedder.embed_batch(batch_texts)
    elapsed = time.time() - start_time

    print(f"\nè€—æ™‚: {elapsed:.2f} ç§’")
    print(f"å¹³å‡é€Ÿåº¦: {elapsed/len(batch_texts):.2f} ç§’/æ–‡æœ¬")
    print(f"è¼¸å‡ºå½¢ç‹€: {batch_embeddings.shape}")

    # æ¸¬è©¦ 4: æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬
    print("\nğŸ” æ¸¬è©¦ 4: æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬")
    print("-" * 60)

    query = "ä»€éº¼æ˜¯åŸå­ç­†è¨˜ï¼Ÿ"
    print(f"æŸ¥è©¢: {query}")
    query_embedding = embedder.embed(query)

    similarities = [
        (i, text, cosine_similarity(query_embedding, emb))
        for i, (text, emb) in enumerate(zip(batch_texts, batch_embeddings))
    ]
    similarities.sort(key=lambda x: x[2], reverse=True)

    print("\næœ€ç›¸é—œçš„æ–‡æœ¬ (Top 5):")
    for rank, (i, text, sim) in enumerate(similarities[:5], 1):
        print(f"{rank}. [{i}] ç›¸ä¼¼åº¦ {sim:.4f}: {text}")

    # æ¸¬è©¦ 5: è·¨èªè¨€èƒ½åŠ›
    print("\nğŸŒ æ¸¬è©¦ 5: è·¨èªè¨€èƒ½åŠ›")
    print("-" * 60)

    multilang_texts = {
        "ç¹ä¸­": "Zettelkasten åŸå­ç­†è¨˜ç³»çµ±",
        "è‹±æ–‡": "Zettelkasten atomic note-taking system",
        "ç°¡ä¸­": "Zettelkasten åŸå­ç¬”è®°ç³»ç»Ÿ",
    }

    print("åµŒå…¥ä¸­...")
    multilang_embeddings = {
        lang: embedder.embed(text)
        for lang, text in multilang_texts.items()
    }

    print("\nè·¨èªè¨€ç›¸ä¼¼åº¦:")
    langs = list(multilang_texts.keys())
    for i in range(len(langs)):
        for j in range(i+1, len(langs)):
            lang1, lang2 = langs[i], langs[j]
            sim = cosine_similarity(
                multilang_embeddings[lang1],
                multilang_embeddings[lang2]
            )
            print(f"{lang1} â†” {lang2}: {sim:.4f}")

    # ç¸½çµ
    print("\n" + "=" * 60)
    print("âœ… æ¸¬è©¦å®Œæˆï¼")
    print("=" * 60)
    print(f"\næ¨¡å‹è³‡è¨Š:")
    print(f"  - åç¨±: qwen3-embedding:4b")
    print(f"  - ç¶­åº¦: 2560")
    print(f"  - éƒ¨ç½²æ–¹å¼: Ollama æœ¬åœ°")
    print(f"  - ç¹é«”ä¸­æ–‡æ”¯æ´: âœ… å„ªç§€")
    print(f"  - è·¨èªè¨€èƒ½åŠ›: âœ… å„ªç§€")
    print(f"  - è™•ç†é€Ÿåº¦: ~{elapsed/len(batch_texts):.2f} ç§’/æ–‡æœ¬")
    print(f"\nè©•ä¼°çµè«–:")
    print(f"  - âœ… å®Œå…¨å…è²»ï¼ˆæœ¬åœ°éƒ¨ç½²ï¼‰")
    print(f"  - âœ… ç„¡ API é™åˆ¶")
    print(f"  - âœ… æ•¸æ“šéš±ç§ä¿è­·")
    print(f"  - âœ… é©åˆå¤§æ‰¹é‡åµŒå…¥")
    print(f"  - âš ï¸  éœ€è¦ç´„ 3GB ç£ç¢Ÿç©ºé–“")
    print(f"  - âš ï¸  è™•ç†é€Ÿåº¦ä¸­ç­‰ï¼ˆCPU æ¨ç†ï¼‰")


if __name__ == "__main__":
    try:
        main()
    except requests.exceptions.ConnectionError:
        print("âŒ éŒ¯èª¤: ç„¡æ³•é€£æ¥åˆ° Ollama")
        print("è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ")
        print("åŸ·è¡Œ: ollama serve")
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
