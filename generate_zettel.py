#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Zettelkasten å¡ç‰‡ç”Ÿæˆå‘½ä»¤è¡Œå·¥å…·

å¾è«–æ–‡ç”ŸæˆåŸå­åŒ–çŸ¥è­˜å¡ç‰‡ï¼Œæ”¯æ´ï¼š
- è‡ªå‹•å…¥åº«ï¼ˆçŸ¥è­˜åº«æ•´åˆï¼‰
- è·¨è«–æ–‡é€£çµ
- è‡ªè¨‚éœ€æ±‚æª”æ¡ˆ
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime

# æ·»åŠ  src åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from generators import SlideMaker
from generators.zettel_maker import ZettelMaker
from extractors import PDFExtractor
from knowledge_base import KnowledgeBaseManager
from jinja2 import Template


# å¯ç”¨çš„è©³ç´°ç¨‹åº¦ï¼ˆ5 ç¨®ï¼‰
AVAILABLE_DETAILS = {
    'minimal': 'æ¥µç°¡ - 5 å¼µå¡ç‰‡',
    'brief': 'ç°¡è¦ - 8 å¼µå¡ç‰‡',
    'standard': 'æ¨™æº– - 12 å¼µå¡ç‰‡ï¼ˆé è¨­ï¼‰',
    'detailed': 'è©³ç´° - 20 å¼µå¡ç‰‡',
    'comprehensive': 'å®Œæ•´ - 30+ å¼µå¡ç‰‡'
}

# å¯ç”¨çš„èªè¨€ï¼ˆ3 ç¨®ï¼‰
AVAILABLE_LANGUAGES = {
    'chinese': 'ç¹é«”ä¸­æ–‡',
    'english': 'English',
    'bilingual': 'ä¸­è‹±é›™èª'
}


def _query_related_cards(paper_content: str, cite_key: str, limit: int = 10) -> list:
    """
    æŸ¥è©¢çŸ¥è­˜åº«ä¸­èˆ‡ç•¶å‰è«–æ–‡ç›¸é—œçš„å¡ç‰‡ï¼ˆç”¨æ–¼è·¨è«–æ–‡é€£çµï¼‰

    Args:
        paper_content: è«–æ–‡å…§å®¹ï¼ˆç”¨æ–¼èªç¾©æœç´¢ï¼‰
        cite_key: ç•¶å‰è«–æ–‡ cite_keyï¼ˆç”¨æ–¼æ’é™¤åŒä¸€è«–æ–‡çš„å¡ç‰‡ï¼‰
        limit: è¿”å›æ•¸é‡ä¸Šé™

    Returns:
        ç›¸é—œå¡ç‰‡åˆ—è¡¨
    """
    try:
        from integrations.vector_db import VectorDatabase
        from integrations.embedder import get_embedder

        vector_db = VectorDatabase()

        # æå–è«–æ–‡æ‘˜è¦ï¼ˆå‰ 1000 å­—ï¼‰ç”¨æ–¼æŸ¥è©¢
        query_text = paper_content[:1000] if paper_content else ""

        if not query_text:
            return []

        # ç”ŸæˆæŸ¥è©¢åµŒå…¥
        embedder = get_embedder(provider='google')
        query_embedding = embedder.embed(query_text, task_type="retrieval_query")

        # å‘é‡æœç´¢ç›¸ä¼¼å¡ç‰‡
        results = vector_db.semantic_search_zettel(
            query_embedding=query_embedding,
            n_results=limit * 2
        )

        if not results or not results.get('ids') or not results['ids'][0]:
            return []

        # éæ¿¾ä¸¦æ§‹å»ºçµæœ
        related_cards = []
        for i, zettel_id in enumerate(results['ids'][0]):
            # æ’é™¤åŒä¸€ cite_key çš„å¡ç‰‡
            if not zettel_id.startswith(cite_key):
                metadata = results['metadatas'][0][i] if results.get('metadatas') else {}
                card = {
                    'zettel_id': zettel_id,
                    'title': metadata.get('title', 'Unknown'),
                    'core_concept': metadata.get('core_concept', ''),
                    'card_type': metadata.get('card_type', 'concept'),
                    'source_paper': zettel_id.split('-')[0] if '-' in zettel_id else 'Unknown'
                }
                related_cards.append(card)
                if len(related_cards) >= limit:
                    break

        return related_cards

    except Exception as e:
        print(f"  [WARN] ç„¡æ³•æŸ¥è©¢ç›¸é—œå¡ç‰‡: {e}")
        return []


def _get_cite_key_or_fallback(paper_data: dict) -> str:
    """
    ç²å–è«–æ–‡çš„ cite_keyï¼ˆåš´æ ¼æ¨¡å¼ï¼‰

    Args:
        paper_data: è«–æ–‡è³‡æ–™å­—å…¸

    Returns:
        cite_key å­—ä¸²

    Raises:
        ValueError: å¦‚æœç¼ºå°‘ cite_key
    """
    if paper_data.get('cite_key') and paper_data['cite_key'].strip():
        return paper_data['cite_key'].strip()

    paper_id = paper_data.get('id', 'æœªçŸ¥')
    raise ValueError(
        f"\nè«–æ–‡ ID {paper_id} ç¼ºå°‘ cite_keyã€‚\n"
        f"è«‹åŸ·è¡Œä»¥ä¸‹å‘½ä»¤ä¿®æ­£ï¼š\n"
        f"  1. uv run kb check-cite-keys\n"
        f"  2. uv run kb update-from-bib 'My Library.bib'\n"
    )


def load_custom_requirements(custom_file: str = None, default_file: str = None) -> str | None:
    """
    è¼‰å…¥è‡ªè¨‚éœ€æ±‚

    å„ªå…ˆé †åºï¼š
    1. custom_fileï¼ˆæ˜ç¢ºæŒ‡å®šçš„æª”æ¡ˆï¼‰
    2. default_fileï¼ˆé è¨­æª”æ¡ˆï¼Œè‹¥å­˜åœ¨ï¼‰

    Args:
        custom_file: ä½¿ç”¨è€…æŒ‡å®šçš„æª”æ¡ˆè·¯å¾‘
        default_file: é è¨­æª”æ¡ˆè·¯å¾‘

    Returns:
        è‡ªè¨‚éœ€æ±‚å…§å®¹ï¼Œæˆ– None
    """
    # 1. ä½¿ç”¨è€…æŒ‡å®šçš„æª”æ¡ˆ
    if custom_file:
        path = Path(custom_file)
        if path.exists():
            print(f"ğŸ“‹ è¼‰å…¥è‡ªè¨‚éœ€æ±‚ï¼š{path}")
            return path.read_text(encoding='utf-8')
        else:
            print(f"âš ï¸  è­¦å‘Šï¼šæ‰¾ä¸åˆ°è‡ªè¨‚éœ€æ±‚æª”æ¡ˆ {path}")
            return None

    # 2. é è¨­æª”æ¡ˆ
    if default_file:
        path = Path(default_file)
        if path.exists():
            print(f"ğŸ“‹ è¼‰å…¥é è¨­éœ€æ±‚ï¼š{path}")
            return path.read_text(encoding='utf-8')

    return None


def main():
    parser = argparse.ArgumentParser(
        description='Zettelkasten å¡ç‰‡ç”Ÿæˆå·¥å…· - å¾è«–æ–‡ç”ŸæˆåŸå­åŒ–çŸ¥è­˜å¡ç‰‡',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨æ–¹å¼ï¼š
  # ç­‰æ•ˆæŒ‡ä»¤æ ¼å¼
  uv run zettel [é¸é …]
  python generate_zettel.py [é¸é …]

ç¯„ä¾‹ç”¨æ³•ï¼š
  # å¾ PDF ç”Ÿæˆå¡ç‰‡ï¼ˆè‡ªå‹•å…¥åº«ï¼‰
  uv run zettel --pdf paper.pdf

  # å¾çŸ¥è­˜åº«è«–æ–‡ç”Ÿæˆå¡ç‰‡
  uv run zettel --from-kb 1

  # æŒ‡å®šè©³ç´°ç¨‹åº¦
  uv run zettel --pdf paper.pdf --detail comprehensive

  # ä½¿ç”¨è‡ªè¨‚éœ€æ±‚æª”æ¡ˆ
  uv run zettel --pdf paper.pdf --custom-file my_style.md

  # è·³éé è¨­éœ€æ±‚
  uv run zettel --pdf paper.pdf --no-custom

  # ä¸å…¥åº«ï¼ˆåƒ…ç”Ÿæˆæª”æ¡ˆï¼‰
  uv run zettel --pdf paper.pdf --no-add-to-kb

  # å•Ÿç”¨è·¨è«–æ–‡é€£çµ
  uv run zettel --pdf paper.pdf --cross-link
        """
    )

    # å…§å®¹ä¾†æºï¼ˆäº’æ–¥ï¼‰
    source_group = parser.add_mutually_exclusive_group(required=True)
    source_group.add_argument('--pdf', type=str, help='PDF æª”æ¡ˆè·¯å¾‘')
    source_group.add_argument('--from-kb', type=int, metavar='PAPER_ID',
                              help='å¾çŸ¥è­˜åº«ä¸­çš„è«–æ–‡ ID ç”Ÿæˆ')

    # ç”Ÿæˆåƒæ•¸
    parser.add_argument('--detail', type=str, default='standard',
                        choices=AVAILABLE_DETAILS.keys(),
                        help='è©³ç´°ç¨‹åº¦ï¼ˆé è¨­ï¼šstandardï¼‰')
    parser.add_argument('--language', type=str, default='chinese',
                        choices=AVAILABLE_LANGUAGES.keys(),
                        help='èªè¨€æ¨¡å¼ï¼ˆé è¨­ï¼šchineseï¼‰')
    parser.add_argument('--domain', type=str, default='Research',
                        help='é ˜åŸŸä»£ç¢¼ï¼ˆå¦‚ NeuroPsyã€AIï¼Œé è¨­ï¼šResearchï¼‰')

    # è‡ªè¨‚éœ€æ±‚
    parser.add_argument('--custom-file', type=str,
                        help='è‡ªè¨‚éœ€æ±‚æª”æ¡ˆè·¯å¾‘ï¼ˆ.txt æˆ– .mdï¼‰')
    parser.add_argument('--no-custom', action='store_true',
                        help='å¿½ç•¥é è¨­è‡ªè¨‚éœ€æ±‚æª”æ¡ˆ')

    # çŸ¥è­˜åº«æ•´åˆ
    parser.add_argument('--no-add-to-kb', action='store_true',
                        help='ä¸å°‡å¡ç‰‡åŠ å…¥çŸ¥è­˜åº«ï¼ˆåƒ…ç”Ÿæˆæª”æ¡ˆï¼‰')
    parser.add_argument('--cross-link', action='store_true',
                        help='å•Ÿç”¨è·¨è«–æ–‡é€£çµï¼ˆæŸ¥è©¢çŸ¥è­˜åº«ç›¸é—œæ¦‚å¿µï¼‰')

    # å‘é‡åµŒå…¥
    parser.add_argument('--no-embed', action='store_true',
                        help='è·³éå‘é‡åµŒå…¥ï¼ˆç¨å¾Œç”¨ uv run embeddings è£œä¸Šï¼‰')

    # LLM åƒæ•¸
    parser.add_argument('--model', type=str, default=None,
                        help='LLM æ¨¡å‹åç¨±ï¼ˆé è¨­ï¼šè‡ªå‹•é¸æ“‡ï¼‰')
    parser.add_argument('--llm-provider', type=str, default='auto',
                        choices=['auto', 'ollama', 'google', 'openai', 'anthropic'],
                        help='LLM æä¾›è€…ï¼ˆé è¨­ï¼šautoï¼‰')
    parser.add_argument('--selection-strategy', type=str, default='balanced',
                        choices=['balanced', 'quality_first', 'cost_first', 'speed_first'],
                        help='æ¨¡å‹é¸æ“‡ç­–ç•¥ï¼ˆé è¨­ï¼šbalancedï¼‰')

    # è¼¸å‡º
    parser.add_argument('--output', type=str, help='è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼‰')

    # é™¤éŒ¯
    parser.add_argument('--list-options', action='store_true',
                        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨é¸é …')

    args = parser.parse_args()

    # åˆ—å‡ºé¸é …
    if args.list_options:
        print("\nğŸ“Š å¯ç”¨çš„è©³ç´°ç¨‹åº¦ï¼š")
        for key, desc in AVAILABLE_DETAILS.items():
            print(f"   â€¢ {key:15s} - {desc}")
        print("\nğŸŒ å¯ç”¨çš„èªè¨€æ¨¡å¼ï¼š")
        for key, desc in AVAILABLE_LANGUAGES.items():
            print(f"   â€¢ {key:15s} - {desc}")
        print()
        return 0

    print("=" * 70)
    print("ğŸ—‚ï¸  Zettelkasten å¡ç‰‡ç”Ÿæˆå·¥å…·")
    print("=" * 70)

    # è¼‰å…¥è‡ªè¨‚éœ€æ±‚
    custom_requirements = None
    if not args.no_custom:
        custom_requirements = load_custom_requirements(
            custom_file=args.custom_file,
            default_file='config/custom_zettel.md'
        )

    print(f"\nè©³ç´°ç¨‹åº¦ï¼š{args.detail} - {AVAILABLE_DETAILS[args.detail]}")
    print(f"èªè¨€ï¼š{args.language} - {AVAILABLE_LANGUAGES[args.language]}")
    print(f"é ˜åŸŸï¼š{args.domain}")
    print(f"LLM æä¾›è€…ï¼š{args.llm_provider}")
    print(f"å…¥åº«ï¼š{'å¦' if args.no_add_to_kb else 'æ˜¯'}")
    print(f"è·¨è«–æ–‡é€£çµï¼š{'æ˜¯' if args.cross_link else 'å¦'}")
    if custom_requirements:
        print(f"è‡ªè¨‚éœ€æ±‚ï¼šå·²è¼‰å…¥ï¼ˆ{len(custom_requirements)} å­—å…ƒï¼‰")

    print("\n" + "=" * 70)

    try:
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        maker = SlideMaker(
            llm_provider=args.llm_provider,
            selection_strategy=args.selection_strategy
        )
        zettel_maker = ZettelMaker()

        # æº–å‚™å…§å®¹
        pdf_content = None
        paper_data = None
        effective_topic = None

        # å¾çŸ¥è­˜åº«è®€å–
        if args.from_kb:
            print(f"\nğŸ“š å¾çŸ¥è­˜åº«è®€å–è«–æ–‡ ID {args.from_kb}...")
            kb = KnowledgeBaseManager()
            paper = kb.get_paper_by_id(args.from_kb)

            if not paper:
                print(f"\nâŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è«–æ–‡ ID {args.from_kb}")
                print("ğŸ’¡ æç¤ºï¼šä½¿ç”¨ 'uv run kb list' æŸ¥çœ‹æ‰€æœ‰è«–æ–‡")
                return 1

            paper_data = paper
            effective_topic = paper['title']

            # è®€å– Markdown ç­†è¨˜
            md_path = Path(paper['file_path'])
            if md_path.exists():
                pdf_content = md_path.read_text(encoding='utf-8')
                print(f"âœ… æˆåŠŸè®€å–è«–æ–‡ï¼š{effective_topic}")
                print(f"   ä½œè€…ï¼š{', '.join(paper['authors']) if paper['authors'] else 'æœªçŸ¥'}")
                print(f"   å¹´ä»½ï¼š{paper['year'] or 'æœªçŸ¥'}")
            else:
                print(f"âš ï¸  è­¦å‘Šï¼šæ‰¾ä¸åˆ° Markdown ç­†è¨˜ï¼Œä½¿ç”¨è³‡æ–™åº«å…§å®¹")
                authors_str = ', '.join(paper['authors']) if paper['authors'] else 'æœªçŸ¥'
                abstract = paper['abstract'] or 'ç„¡æ‘˜è¦'
                pdf_content = f"# {paper['title']}\n\nä½œè€…ï¼š{authors_str}\nå¹´ä»½ï¼š{paper['year'] or 'æœªçŸ¥'}\n\n## æ‘˜è¦\n{abstract}"

        # å¾ PDF è®€å–
        elif args.pdf:
            pdf_path = Path(args.pdf)
            if not pdf_path.exists():
                print(f"\nâŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° PDF æª”æ¡ˆï¼š{args.pdf}")
                return 1

            print(f"\nğŸ“„ æ­£åœ¨æå– PDF å…§å®¹ï¼š{pdf_path.name}...")
            extractor = PDFExtractor(max_chars=40000)
            pdf_result = extractor.extract(str(pdf_path))
            pdf_content = pdf_result['full_text']
            effective_topic = pdf_result.get('title') or pdf_path.stem

            if pdf_result['truncated']:
                print(f"âš ï¸  è­¦å‘Šï¼šPDF å…§å®¹å·²æˆªæ–·ï¼ˆ{pdf_result['char_count']} â†’ 40000 å­—å…ƒï¼‰")
            else:
                print(f"âœ… æˆåŠŸæå– {pdf_result['char_count']} å­—å…ƒ")

        # ç²å– cite_key
        if args.from_kb and paper_data:
            cite_key = _get_cite_key_or_fallback(paper_data)
        else:
            cite_key = Path(args.pdf).stem

        # è¼‰å…¥ Zettelkasten prompt æ¨¡æ¿
        zettel_template_path = Path(__file__).parent / "templates" / "prompts" / "zettelkasten_template.jinja2"
        with open(zettel_template_path, 'r', encoding='utf-8') as f:
            zettel_template = Template(f.read())

        # æ±ºå®šå¡ç‰‡æ•¸é‡
        style_config = zettel_maker.styles_config['styles']['zettelkasten']
        card_count = style_config['default_card_count'].get(args.detail, 12)

        # æŸ¥è©¢ç›¸é—œå¡ç‰‡ï¼ˆè·¨è«–æ–‡é€£çµï¼‰
        related_cards = []
        if args.cross_link:
            print("\nğŸ” æŸ¥è©¢çŸ¥è­˜åº«ç›¸é—œæ¦‚å¿µ...")
            related_cards = _query_related_cards(
                paper_content=pdf_content,
                cite_key=cite_key,
                limit=10
            )
            if related_cards:
                print(f"  æ‰¾åˆ° {len(related_cards)} å€‹ç›¸é—œæ¦‚å¿µï¼ˆå°‡ç”¨æ–¼å»ºç«‹è·¨è«–æ–‡é€£çµï¼‰")
            else:
                print("  æœªæ‰¾åˆ°ç›¸é—œæ¦‚å¿µï¼ˆå°‡åªå»ºç«‹è«–æ–‡å…§é€£çµï¼‰")

        # ç”Ÿæˆ prompt
        date_str = datetime.now().strftime("%Y%m%d")
        zettel_prompt = zettel_template.render(
            topic=effective_topic,
            pdf_content=pdf_content,
            card_count=card_count,
            domain=args.domain,
            date=date_str,
            cite_key=cite_key,
            language=args.language,
            existing_related_cards=related_cards,
            custom_requirements=custom_requirements  # æ–°å¢ï¼šè‡ªè¨‚éœ€æ±‚
        )

        # èª¿ç”¨ LLM
        print(f"\nğŸ¤– æ­£åœ¨ç”Ÿæˆ {card_count} å¼µåŸå­ç­†è¨˜å¡ç‰‡...")
        llm_output, used_provider = maker.call_llm(zettel_prompt, model=args.model)
        print(f"âœ… ä½¿ç”¨ {used_provider} ç”Ÿæˆå®Œæˆ")

        # æ±ºå®šè¼¸å‡ºç›®éŒ„
        if args.output:
            output_dir = Path(args.output)
        elif args.from_kb and paper_data:
            output_dir = Path(f"output/zettelkasten_notes/zettel_{cite_key}_{date_str}")
        else:
            pdf_stem = Path(args.pdf).stem
            output_dir = Path(f"output/zettelkasten_notes/zettel_{pdf_stem}_{date_str}")

        # æº–å‚™è«–æ–‡è³‡è¨Š
        if paper_data:
            paper_info = {
                'title': paper_data['title'],
                'authors': ', '.join(paper_data.get('authors', [])),
                'year': paper_data.get('year', datetime.now().year),
                'paper_id': args.from_kb if args.from_kb else '',
                'cite_key': paper_data.get('cite_key', ''),
                'citation': paper_data['title']
            }
        else:
            paper_info = {
                'title': effective_topic,
                'authors': '',
                'year': datetime.now().year,
                'paper_id': '',
                'cite_key': cite_key,
                'citation': effective_topic
            }

        # ç”Ÿæˆå¡ç‰‡
        result = zettel_maker.generate_zettelkasten(
            llm_output=llm_output,
            output_dir=output_dir,
            paper_info=paper_info
        )

        # é¡¯ç¤ºçµæœ
        print("\n" + "=" * 70)
        print("âœ… Zettelkasten åŸå­ç­†è¨˜ç”Ÿæˆå®Œæˆï¼")
        print("=" * 70)
        print(f"\nğŸ“ è¼¸å‡ºç›®éŒ„ï¼š{result['output_dir']}")
        print(f"ğŸ“„ ç´¢å¼•æ–‡ä»¶ï¼š{result['index_file']}")
        print(f"ğŸ—‚ï¸  å¡ç‰‡æ•¸é‡ï¼š{result['card_count']}")
        print(f"ğŸ“ è©³ç´°ç¨‹åº¦ï¼š{args.detail}")
        print(f"ğŸŒ èªè¨€æ¨¡å¼ï¼š{args.language}")
        print(f"ğŸ¤– ä½¿ç”¨ LLMï¼š{used_provider}")

        print("\nğŸ“š ç”Ÿæˆçš„å¡ç‰‡æ–‡ä»¶ï¼š")
        for i, card_file in enumerate(result['card_files'][:5], 1):
            print(f"   {i}. {Path(card_file).name}")
        if len(result['card_files']) > 5:
            print(f"   ... ä»¥åŠå…¶ä»– {len(result['card_files']) - 5} å¼µå¡ç‰‡")

        # å…¥åº«åŠŸèƒ½
        if not args.no_add_to_kb:
            print("\nğŸ“¥ æ­£åœ¨å°‡å¡ç‰‡åŠ å…¥çŸ¥è­˜åº«...")
            kb = KnowledgeBaseManager()

            # ç²å– paper_idï¼ˆå¦‚æœå¾çŸ¥è­˜åº«ç”Ÿæˆï¼‰
            paper_id = args.from_kb if args.from_kb else None

            added_count = 0
            skipped_count = 0

            for card_file in result['card_files']:
                # è§£æå¡ç‰‡
                card_data = kb.parse_zettel_card(card_file)
                if card_data:
                    # æ·»åŠ åˆ°çŸ¥è­˜åº«
                    add_result = kb.add_zettel_card(card_data)
                    if add_result.status == 'inserted':
                        added_count += 1
                        # å»ºç«‹è«–æ–‡-å¡ç‰‡é—œè¯
                        if paper_id and add_result.card_id > 0:
                            kb.link_paper_to_zettel(paper_id, add_result.card_id, 1.0)
                    elif add_result.status == 'duplicate':
                        skipped_count += 1

            print(f"   âœ… æ–°å¢ {added_count} å¼µå¡ç‰‡")
            if skipped_count > 0:
                print(f"   â­ï¸  è·³é {skipped_count} å¼µé‡è¤‡å¡ç‰‡")

        # å‘é‡åµŒå…¥
        if not args.no_embed and not args.no_add_to_kb:
            try:
                from integrations.vector_db import VectorDatabase
                from integrations.embedder import get_embedder

                print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥...")
                vector_db = VectorDatabase()
                embedder = get_embedder(provider='google')

                embedded_count = 0
                for card_file in result['card_files']:
                    card_data = kb.parse_zettel_card(card_file)
                    if card_data and card_data.get('content'):
                        # ç”ŸæˆåµŒå…¥
                        embedding = embedder.embed(
                            card_data['content'][:2000],
                            task_type="retrieval_document"
                        )
                        # å­˜å…¥å‘é‡åº«
                        vector_db.upsert_zettel(
                            embeddings=[embedding],
                            documents=[card_data['content'][:2000]],
                            ids=[card_data['zettel_id']],
                            metadatas=[{
                                'title': card_data.get('title', ''),
                                'core_concept': card_data.get('core_concept', ''),
                                'card_type': card_data.get('card_type', 'concept'),
                                'cite_key': cite_key
                            }]
                        )
                        embedded_count += 1

                print(f"   âœ… åµŒå…¥ {embedded_count} å¼µå¡ç‰‡")

            except Exception as e:
                print(f"   âš ï¸  å‘é‡åµŒå…¥å¤±æ•—ï¼š{e}")
                print("   ğŸ’¡ å¯ç¨å¾ŒåŸ·è¡Œ uv run embeddings è£œä¸Š")

        return 0

    except ImportError as e:
        print(f"\nâŒ ç¼ºå°‘å¿…è¦çš„å¥—ä»¶ï¼š{e}")
        print("ğŸ’¡ æç¤ºï¼šè«‹é‹è¡Œ uv sync")
        return 1

    except FileNotFoundError as e:
        print(f"\nâŒ æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{e}")
        return 1

    except ValueError as e:
        print(f"\nâŒ åƒæ•¸éŒ¯èª¤ï¼š{e}")
        return 1

    except Exception as e:
        print(f"\nâŒ æœªé æœŸçš„éŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
