---
title: Memory&Cognition(2020)48:390–399
authors: M.Altmann, Keywords Objectstate, H.Joergensen, A.Zwaan
year: N/A
keywords: 
created: 2025-10-29 16:41:07
---

# Memory&Cognition(2020)48:390–399

## 基本信息

- **作者**: M.Altmann, Keywords Objectstate, H.Joergensen, A.Zwaan
- **年份**: N/A
- **關鍵詞**: 

## 摘要

Tounderstandlanguagepeopleformmentalrepresentationsofdescribedsituations.Linguisticcuesareknowntoinfluencethese
representations.Inthepresentstudy,participantswereaskedtoverifywhethertheobjectpresentedinapicturewasmentionedinthe
precedingwords.Crucially,thepictureeithershowedanintactoriginalstateoramodifiedstateofanobject.Ourresultsshowedthat
theendstateofthetargetobjectinfluencedverificationresponses.Whennolinguisticcontextwasprovided,participantsresponded
faster to the original state of the object compared to the changed state (Experiment 1). However, when linguistic context was
provided,participantsrespondedfastertothemodifiedstatewhenitmatched,ratherthanmismatched,theexpectedoutcomeofthe
described event (Experiment 2 and Experiment 3). Interestingly, as for the original state, the match/mismatch effects were only
revealed after reading the past tense (Experiment 2) sentences but not the future-tense sentences (Experiment 3). Our findings
highlighttheneedtotakeaccountofthedynamicsofeventrepresentationinlanguagecomprehensionthatcapturestheinterplay
betweengeneralsemanticknowledgeaboutobjectsandtheepisodicknowledgeintroducedbythesententialcontext.
Keywords Objectstate .Mentalrepresentation .Languagecomprehension .Tense .Pictureverification

## 研究背景

## 研究方法

## 主要結果

## 討論與結論

## 個人評論

## 相關文獻

## 完整內容

Memory&Cognition(2020)48:390–399
https://doi.org/10.3758/s13421-019-00977-7
The influence of state change on object representations
in language comprehension
XinKang1,2 &AnitaEerland3&GitteH.Joergensen4,5&RolfA.Zwaan6&GerryT.M.Altmann4,5
Publishedonline:17October2019
#ThePsychonomicSociety,Inc.2019
Abstract
Tounderstandlanguagepeopleformmentalrepresentationsofdescribedsituations.Linguisticcuesareknowntoinfluencethese
representations.Inthepresentstudy,participantswereaskedtoverifywhethertheobjectpresentedinapicturewasmentionedinthe
precedingwords.Crucially,thepictureeithershowedanintactoriginalstateoramodifiedstateofanobject.Ourresultsshowedthat
theendstateofthetargetobjectinfluencedverificationresponses.Whennolinguisticcontextwasprovided,participantsresponded
faster to the original state of the object compared to the changed state (Experiment 1). However, when linguistic context was
provided,participantsrespondedfastertothemodifiedstatewhenitmatched,ratherthanmismatched,theexpectedoutcomeofthe
described event (Experiment 2 and Experiment 3). Interestingly, as for the original state, the match/mismatch effects were only
revealed after reading the past tense (Experiment 2) sentences but not the future-tense sentences (Experiment 3). Our findings
highlighttheneedtotakeaccountofthedynamicsofeventrepresentationinlanguagecomprehensionthatcapturestheinterplay
betweengeneralsemanticknowledgeaboutobjectsandtheepisodicknowledgeintroducedbythesententialcontext.
Keywords Objectstate .Mentalrepresentation .Languagecomprehension .Tense .Pictureverification
Introduction
2015;Morford&Goldin-Meadow,1997).Thisabilitytouse
displaced reference may be unique to humans (Hockett,
One of the dominant features of human language communi- 1960; Liszkowski et al., 2009) and is linked to the social-
cationistointentionallytalkaboutabsententitiesinthepast cognitive skills of humans and grammatical system of lan-
and future that are not immediately spatially or temporally guages(Bergen&Chang,2005).Forexample,auxiliaryverbs
near the speaker and the listener (Cuccio & Carapezza, such as Bwill^ and Bwere^ in English are used to indicate
whether an event occurred before or after the moment of
speaking or events under discussion. Altmann and Kamide
(2007)revealedthatvisualattentioncanbedirecteddifferent-
* XinKang
ly to the visual scene depending on whether the sentences
xin.kang@cuhk.edu.hk
were presented in past-tense or the future-tense conditions.
AnitaEerland Participants launched more anticipatory eye movements to-
a.eerland@uu.nl wards a full glass of beer in the future tense (e.g., The man
will drink...) than in the past tense (e.g., The man drank...).
1 LinguisticsandModernLanguages,TheChineseUniversityofHong
Bergen and Wheeler (2010) showed that when we process
Kong,HongKongSAR,China
languagethatdescribesperceivablescenesorperformableac-
2 BrainandMindInstitute,TheChineseUniversityofHongKong,
tions,theactivationofperceptualandmotorsystemswasin-
HongKongSAR,China
fluenced bythe grammatical markers oftense.For example,
3 DepartmentofLanguages,LiteratureandCommunication,Utrecht
when hand motion was described in progressive sentences
University,Utrecht,TheNetherlands
(e.g., John is closing the drawer), there was a facilitation
4 DepartmentofPsychologicalSciences,UniversityofConnecticut,
effectformanualactioninthesamedirectionofparticipants,
Storrs,UnitedStates
but no such effect was found when the sentences were in
5 InstitutefortheBrainandCognitiveSciences,Universityof
perfecttense(e.g.,Johnhasclosedthedrawer).
Connecticut,Storrs,UnitedStates
Thesefindingsareinlinewiththeoriesofmental/situation
6 DepartmentofPsychology,Education,andChildSciences,Erasmus
models(Johnson-Laird,1983;vanDijk&Kintsch,1983)and
UniversityRotterdam,Rotterdam,TheNetherlands

MemCogn(2020)48:390–399 391
perceptual-symboltheoriesofcognition(Barsalou,1999)that representations so as to integrate the most recent information
understandinglanguageinvolvestheconstructionofamental and deactivate irrelevant information. It is not always the case
situation as a Bsimulation^ of real-world experiences in the thatwehavetoencodeeventsinassociationwithotherobjects.
spatiotemporalframework,thoughtowhatdegreeperceptual Linguisticinformation,suchasthetenseofsentences,canalsobe
systemsareinvolvedintheorganizationofobjectknowledge used as a cue for Btime shift^ (e.g., Altmann & Kamide,
in the brain is still under debate (see Mahon & Caramazza, 2007; Ferretti, Kutas, & McRae, 2007; Madden & Zwaan,
2011). According to these theories, concepts of objects are 2003). Besides, previous studies have not clarified whether the
perceptual symbols that arise during perceptual and motor object-state has been tracked, maintained, and updated in the
experiences, which can later activate previous experiences eventmodels.Forexample,anobjectmaygothroughchanges
and the relevant neural systems. For example, if we think duetoanexternalaction(e.g.,Thechefchoppedtheonion).An
aboutBeatinganapple,^wemayactivatetheneuralsystems onionwouldlookdifferentbeforeandafteritischopped.Inthis
of vision, action, touch, taste, and smell that are engaged in case, the end state of the onion can be distinguished from its
ourpreviousexperiences.Thissimulation,ormentalmodels, initialstateandintermediatestatesfromthefeaturesoftheonion
mayincludevisualinformationofaredandroundobject,and itself.Dowealsoencodetheconflictingstatesoftheonioninour
sensorimotorinformationofeatingjuicyandcrunchypieces. eventmodels?
Usingthepictureverificationparadigm,StanfieldandZwaan Sofar,thereislimitedempiricalevidenceoftheencodingof
(2001)askedparticipantstoreadsentenceslikeBThecarpenter object state-change in language comprehension (but
poundedthenailintothewall,^andtoverifywhetheranobject see Altmann, 2017; Hindy, Altmann, Kalenik, & Thompson-
displayed on a picture (e.g., a nail) was mentioned in the sen- Schill, 2012; Solomon, Hindy, Altmann, & Thompson-Schill,
tence.Critically,theobjectinthepictureeithermatchedormis- 2015). Hindy et al. (2012) revealed that reading sentences that
matchedtheimpliedorientation.Althoughtheobject’sorienta- describedachangeofstateprovidesachallengetoourcognitive
tionwasirrelevanttothetask,participantsreactedfastertothe system;multiplerepresentationsoftheobjectindifferentstates
picturedobject(e.g.,ahorizontallyorientednail)thatwascom- may be activated and we have to choose the situationally
patiblewithitsimpliedorientationasdescribedinthesentence appropriateone.Solomonetal.(2015)furtherrevealedthatcom-
(BThecarpenterhammeredthenailintothewall^)thanthein- petitionbetweenobjectstates(e.g.,anonioninitsoriginalstate
compatibleorientation(BThecarpenterhammeredthenailinto oritssubsequentchoppedstate)isonlyrevealedwhenthestates
thefloor^).Suchmatch/mismatcheffectsbetweenlinguisticin- areassociatedwiththesameobject,butnotadifferentversionof
formation and visual presentation were found when different thatobject(e.g.,oneonioninitsoriginalstate,andanotheronion
properties of objects were manipulated, including orientation inachoppedstate).Thus,itislikelythatwhenachangeofstate
(Stanfield&Zwaan,2001;Wassenburg&Zwaan,2010),shape event occurs, the object is linked to multiple Bstates^ of itself
(Huettig & Altmann, 2007; Yee, Huffstetler, & Thompson- acrosstime–beforeandafterthischange.Therefore,anobjectin
Schill,2011;Zwaan,Stanfield,&Yaxley2002),motiondirection themodifiedstatehasitsownBhistory^thatincludesitsassoci-
(Zwaan, Madden,Yaxley, &Aveyard, 2004), size (deKoning, ation with its prior original self and with changes to its states
Wassenburg, Bos, & van der Schoot, 2017), color (Connell, across time. Altmann and Ekves (2019) further proposed the
2007; Hoeben-Mannaert, Dijkstra, & Zwaan, 2017; Huettig & Bevents as intersecting object histories^ (IOH) model that
Altmann, 2011; Zwaan & Pecher, 2012), visibility (Yaxley & encodingevents(whetherwedirectlyexperiencethemorlearn
Zwaan,2007),distance(Winter&Bergen,2012),andnumerical about them through language) involves constructing dynamic
congruence(Patson,2016;Šetić&Domijan,2017). representationsofintersectingobjecthistories.Ifmentalsimula-
However, in these studies event models are not established tionsofsituationsareanintegralpartofunderstandinglanguage,
around the target objects alone but draw information from the can we expect match/mismatch effects after the object experi-
surrounding environment such as location (e.g., a nail into the encesachangeofstate?
floor/wall),otherobjects(e.g.,wine–wineglass),andtime(e.g., Inthepresentstudy,weaimedtoexplorewhetherobjectstate-
anhourlatervs.amonthlater).Theoriesofeventmodelshave changeinfluencesthespeedofpictureverification.Weexpected
recognized that events can be encoded across multiple dimen- to find quicker response times when the object representation
sions (Zwaan, Langston, & Graesser, 1995; Zwaan & matchedthepictureprobecomparedtowhenitmismatchedthe
Radvansky, 1998; Zwaan, 2016), including location (e.g., probe.Experiment1wasintendedtoestablishbaselineresponses
Glenberg, Meyer, & Lindem, 1987; Kukona, Altmann, & toprobepicturesthatshowedconflictingstatesoftargetobjects.
Kamide, 2014; Radvansky, 2005; Radvansky & Copeland, In Experiment 2, we manipulated object state-change by using
2006; Radvansky & Copeland, 2010), time (Radvansky, twodifferentverbs–oneindicatingaminimal/nochangeandthe
Zwaan, Federico, & Franklin, 1998; Speer & Zacks, 2005; other a substantial change. An example is The woman chose/
Zwaan,1996),goals,andagents.Weconstruct,update,andre- dropped the ice cream. The task for participants was to verify
trievethesituationmodelsbasedonthesedimensions.Whena whether the probe picture that appeared afterwards was men-
change occurs in any dimension, we update our mental tioned in the sentence they just read. Our hypothesis was that

392 MemCogn(2020)48:390–399
despitetheirrelevanceofobjectstatestotheverificationtask,the 32 high-frequency object names (e.g., ice cream, banana,
object states that are activated in language would influence the rope,candle)andpairedeachnamewithoneoftwopictures
responsestoprobepictures.Thus,wepredictedthatparticipants of the object – one showing the object in the original state
would react faster to a probe picture when it matched the de- (e.g.,anuprightice cream) and one showingthe objectina
scribed state of the target object than when it mismatched the modifiedstate(e.g.,adroppedicecream).
objectstate.Experiment3furtherexploredwhetherthetenseof
sentenceswouldfurthermediatetheactivationofobjectstatesin
Method
languagecomprehensionwhenthesentenceswereinfuturetense.
DatawerecollectedviaAmazon’sMechanicalTurk(MTurk,
http://www.mturk.com) using the sentence-picture verification Participants We recruited 118 participants (54 female, mean
paradigmfollowingZwaanandPecher(2012).Allthematerials age 36.19 years, range 19–64) through MTurk. All partici-
and rawdata for our study can be found on the Open Science pants were residents of the USA and received US$1.50 for
Framework (OSF) (https://osf.io/cvrm3/). The key independent their participation, which lasted approximately 15 min. One
variablewaswhetherthestateofthepicturewascompatibleor participant was excluded for reporting a non-English native
incompatiblewiththeoriginalstateandmodifiedstateofobject language. With the exclusion of this participant our sample
describedinthesentences.Oneachtrial,participantsreadaword included117nativeEnglishspeakers.
(e.g.,icecream)orasentence(e.g.,Thewomandroppedtheice
cream)andthenindicatedwhetherasubsequentpictureshowing Materials Each participant saw one of two lists that
an ice cream was mentioned in the text. Visual probes were counterbalanced items and conditions of experimental trials.
committed to a particular shape of the target object and thus CrucialtothegoalofExperiment1,theobjectname(e.g.,ice
allowed us to assess the activation levels of different forms of cream)intheexperimentaltrialscouldbefollowedbyapic-
thesameentity.Accuracyandreactiontimestotheprobepictures ture showing this object either in its original state (e.g., an
wererecorded.Responsetimes(RTs)werecalculatedovercor- upright ice cream) or in its modified state (e.g., a dropped
recttrialsonlyandRTsthatwereshorterthan300msorlonger icecream)thatarecausedbyexternalforcesbutnotaninter-
than3,000mswereexcluded.Thelinearmixed-effectsmodels nalaction(e.g.,bloomingflowers)(seeWhite,1991, for the
(LMMs) using the lme 4 package (Bates et al., 2015; Baayen, distinction between external/internal causal attribution).
Davidson,&Bates,2008)ofR(RCoreTeam,2016)wereused Figure1illustratestwoexamplepairsofprobepictures.
forstatisticalanalysis.Thelsmeanspackage(Lenth,2016)was We created four practice trials (including two Byes^ re-
usedtoconductposthoccomparisonsforsignificantinteraction sponses and two Bno^ responses), 32 experimental trials re-
effectswithTukeyadjustmentsofp-values.Table1summarizes quiringByes^responses(e.g.,theobject’snameBicecream^
fixedeffectsofLMMsinallthreeexperiments. followedbyapictureofanicecream),and32fillersrequiring
Bno^ responses(e.g.,theobject’snameBbox^ followedbya
pictureofaball).Allpictureswerefromacommercialclipart
Experiment 1 website and wereeditedtobestmatch the intended statesof
the object. The pictureswere resized toa maximum of3 in.
heightand3in.width.
We conducted our first experiment using the word-picture
verification paradigm to identify the baseline responses to-
ProcedureTheexperimentwaspresentedonlineintheQualtrics
wardsourpicturestimuli.Thisallowedustodeterminewheth-
survey research suite (http://www.qualtrics.com). Each trial
eronestatewouldberespondedtodifferentlyfromtheother
statewhenonlytheobject’snamewasmentioned.Weselected started with the presentation of a left justified and vertically
centered fixation cross on the computer screen for 1,000 ms,
Table 1 Fixed effects estimated with linear mixed models in all immediately followed by an object name (e.g., ice cream),
experiments centered atthe same location asthe fixation cross. Participants
pressed the spacebar when they had read and understood the
Fixedeffects Coefficient SE t p
object name. After the keypress, the object name (e.g., ice
Experiment1 Picturetype 117 18 6.53 <.001 cream) was replaced by a fixation-cross that appeared for 500
Experiment2 Picturetype 153 18 8.58 <.001 ms,andthenimmediatelyfollowedbyapicture(e.g.,anupright
Eventtype 83 18 4.69 .615 ice cream). Participants were instructed to indicate as fast and
accuratelyaspossiblewhethertheobjectdisplayedinthepicture
Interaction 153 25 6.12 <.001
matched the object name they just read (yes/no) by pressing a
Experiment3 Picturetype 175 49 5.18 <.001
buttononthekeyboard(m-key/c-key,respectively).Allexperi-
Eventtype 151 34 4.48 .001
mental trials required a Byes^ response, whereas all filler trials
Interaction 145 47 3.06 .002
requiredaBno^response.Thenexttrialstarted500msafterthe

MemCogn(2020)48:390–399 393
Fig.1 TwoexamplepairsofprobepicturesusedinExperiments1–3.Theoriginalstatedepictsacanonicalorprototypicalformoftheobject,whilethe
modifiedstatewasusuallycausedbyanexternalaction(e.g.,drop)
responsewasgiven.Experimentalandfillertrialswerepresented MaterialsandprocedureWecreatedfourlistsofstimuli(two
inrandomorder. types of events x two types of pictures) to counterbalance
items and conditions. The procedure of Experiment 2 was
Resultsanddiscussion
identicaltothatofExperiment1.Participantsread32exper-
imentalsentencesthateitherdescribedasubstantialchangeof
We estimated the fixed effects of Picture type (Original vs. anobject’sstate(e.g.,BThewomandroppedtheicecream^)or
Modified) with subjects and items as random effects in the minimal/nochange(e.g.,BThewomanchosetheicecream^).
firstmodel. After reading the sentences, participants pressed the SPACE
barandapictureprobeappearedshowingeithertheoriginal
model1< −lmer(RT~Picture+(1|Subject)+(1|Item))
stateorthemodifiedstateofthatobject.Inadditiontothese32
experimental items that required Byes^ responses, 32 filler
Thesecondmodelisarandom-intercept-and-slopesmodel items that required Bno^ responses were added (e.g., BThe
withoutfixedeffects. mankickedtheball^;apictureofabox).Itemswerepresented
inrandomorder.
model2< −lmer(RT~1+(1|Subject)+(1|Item))
Resultsanddiscussion
The models were fit by restricted maximum likelihood
(REML).Toassessthegoodnessoffit,wecomparedthemodels
We adopted the same statistical analysis procedure as
usingtheχ2-distributedlikelihoodratioanditsassociatedp-val-
Experiment 1. The fixed effects were Picture type (Original
ue. The model with a smaller Akaike Information Criterion
vs.Modified)andEventtype(Substantialchangevs.Minimal
(AIC)andtheBayesianInformationCriterion(BIC)wasconsid-
change). Random effects included subjects and items. The
eredasabetterfit.Theresultsshowedthatparticipantsresponded
goodnessoffitwasassessedbycomparingtheAICandBIC
significantlyfastertotheoriginalstate,χ2(2)=41.177,p<.001,
valuesandχ2-distributedlikelihoodratioanditsassociatedp-
suggestingtheoriginalstate(LSMEANS:893±50ms)seemsto
value.WefoundasignificantfixedeffectofPicturetype,χ2
haveanadvantageinresponsetimescomparedtothemodified
(1)=35.85,p<.001withfasterreactiontimestotheoriginal
state(LSMEANS:1009±50ms)(seeFig.2)
state thantothe modifiedstate.Nofixed effectoftheEvent
typewasfound.Nonetheless,therewasasignificantinterac-
tionbetweenPicturetypeandEventtype,χ2(1)=37.322,p<
Experiment 2
.001. Post hoc comparisons indicated that the original state
wasverifiedfasterwhenthesentenceimpliedaneventinvolv-
InExperiment2,weexaminedwhetherthelinguisticcontext
ing a minimal change of state (LSMEANS: 1,091 ± 33 ms)
maymodulatepictureverificationresponses.
thanasubstantialchangeofstate(LSMEANS:1,161±34ms;
p < .001), while the modified state was verified faster when
Method thesentenceimpliedaneventinvolvingasubstantialchange
ofstate(LSMEANS:1,161±33ms)thanaminimalchangeof
ParticipantsWerecruited227participants(100female,mean state(LSMEANS:1,244±34ms,p<.001)(seeFig.3).
age 35.07 years, range 18–65) through MTurk. All partici- Therefore,itseemsthatamatchadvantageoftheoriginal
pants were residents of the USA and received US$2.00 for stateandmodifiedstatewasfoundwhentheywerepresented
theirparticipation,whichlastedapproximately25min.Thirty- aftertheconditionthatindicatedthe appropriate endstateof
one participants indicated a language other than English as theobject.Insum,theresultsofExperiment2suggestthatthe
theirnativelanguage.Withtheexclusionoftheseparticipants, linguistic context has an impact on the activation of object-
oursampleincluded196nativeEnglishspeakers. state representations. The original state of an object was

1400
1200
1000
Modified Original
Probe pictures
verifiedfasterwhenthesentencesdescribedaminimalchange the cues for such event sequences. Our findings show that
ofstate,butwhenasubstantialchangeofstatewasdescribed these explicit cues may not be necessary as the states of the
themodifiedstatewasverifiedfaster.Despitethefactthatthe objectcanbedescribedbyusingtheverbs(e.g.,drop),which
original state was verified faster than the modified state in will also trigger the activation of the corresponding object
Experiment 1, the modified state gained a match advantage statethatistheappropriateendstateoftheevent.
whenitwastheexpectedendstateoftheevent.
Ourfindingsareconsistentwithpreviousresearchshowing
Experiment 3
thatcontextuallyappropriateperceptualinformationaboutde-
scribedobjectsisactivatedinlanguagecomprehension(e.g.,
Stanfield&Zwaan,2001;Zwaan,Stanfield,&Yaxley,2002; The first two experiments showed that (1) without any lin-
seealsoHoeben-Mannaertetal.,2017),andtheevidenceon guistic context, people mentally represent the original state
the competition between multiple object states in language of an object, and (2) the modified state has a match advan-
comprehension (e.g., Hindy et al., 2012). Importantly, this tagewhenlinguisticcontext indicates a changecomparedto
experimentdemonstratesthattheinternalstructureofanarrat- no change. When we read the past tense version of a sen-
edsequenceofeventscanbemappedwiththerepresentation tence (e.g., The woman dropped the ice cream), relative to
ofobjects.Previousstudieshaveoftenspecifiedthelocation the time of the hearer, the event has happened in the past,
(e.g.,onthewall/floor)orthetime(e.g.,after1day/1year)as meaning that the ice cream is already in its dropped state.
)sm(
semit
esnopseR
394 MemCogn(2020)48:390–399
Fig.2 Meanresponsetimesof
theprobepicturesafterreading
theobjectnameinExperiment1.
DataareshownasLSmean±SE.
They-axisshowstheresponse
timestoprobepicturesinmilli-
seconds(ms)
Picture
Modified
Original

1500
1400
1300
1200
1100
1000
Modified Original
Probe pictures
However,ifasentenceisinthefuturetense(e.g.,Thewom- InExperiment3,weaimedtoinvestigatewhetherthetenseof
anwilldroptheicecream),relativetothetimeofthehearer, asentencemodulatestheactivationofthemostprominentstates
the ice cream is original, and although a change in state is of the object. Previous studies have shown that grammatical
described, if the hearer were to act on the ice cream, it tensemayplayaroleinconstructingmentalrepresentations.In
would be in the original state. Thus, theoretically we would Bergen and Wheeler (2010), participants read sentences that
inhibit the activation of the changed state of the ice cream wereinthepresentprogressivetense(Experiment1:e.g.,Carol
and keep the original state as being more accessible. When istakingoff/puttingonherglasses)orinthepresentperfecttense
the participant-centric current state of the world entails an (Experiment2:e.g.,Carolhastakenoff/putonherglasses)and
originalice-cream,but a future state of the world entailsthe decidedifthedescribedactionrequiredmovementofthehand
dropped ice cream – will the representation associated with towardorawayfromthebody.Theyfoundanaction-sentence
the current state be the more accessible, or will the repre- congruencyeffectfortheprogressivesentencesinExperiment1
sentationwiththeas-yetun-encounteredfuturestatebemore butnotthe perfect sentences in Experiment 2,arguingthat the
accessible? actions in Experiment 2 were already completed and hence
)sm(
semit
esnopseR
MemCogn(2020)48:390–399 395
Fig.3 Meanresponsetimesof
theprobepicturesafterreading
past-tensesentencessuchasBThe
womandropped/chosetheice
cream^inExperiment2.Dataare
shownasLSmean±SE.They-
axisshowstheresponsetimesto
probepicturesinmilliseconds
(ms)
Event
Minimal
Substantial

1500
1400
1300
1200
1100
1000
Modified Original
Probe pictures
requirednosimulationoftheaction.Ifthisisthecase,consider nativelanguage.Withtheexclusionoftheseparticipants,our
BThewomanwilldroptheicecream,^whichmightestablishtwo sampleincluded205nativeEnglishspeakers.
conflictingstatesoftheobject(i.e.,thecurrentoriginalstateand
thefuturemodifiedstate).Willtherebeamatchadvantageforthe Materials and procedure Experiment 3 was identical to
originalstategiventhatapossiblechangeofstatehasnothap- Experiment 2 with the exception that all single sentences in
penedyet? thisexperimentusedfuturetenseratherthanpasttense.
Method Resultsanddiscussion
ParticipantsWerecruited211participants(104female,mean WefollowedthesamestatisticalprocedureasinExperiment2.
age 33.87 years, range 18–69) through MTurk. All partici- TheresultssuggestedthattherewasafixedeffectofPicturetype,
pants were residents of the USA and received US$2.00 for χ2(1)=18.18,p<.001thattheoriginalpictureswereresponded
their participation, which lasted approximately 25 min. Six tofasterthanthemodifiedpictures.Therewasafixedeffectof
participants indicated a language other than English as their Eventtype,χ2(1)=10.65,p=.001thatthepicturefollowinga
)sm(
semit
esnopseR
396 MemCogn(2020)48:390–399
Fig.4 Meanresponsetimesof
theprobepicturesafterreading
thefuture-tensesentencessuchas
BThewomanwilldrop/choosethe
icecream^inExperiment3.Data
areshownasLSmean±SE.The
y-axisshowstheresponsetimes
toprobepicturesinmilliseconds
(ms)
Event
Minimal
Substantial

MemCogn(2020)48:390–399 397
substantial change was verified faster than a minimal change. closelinkbetweentheconsequencesoftheactionandthegram-
Importantly,therewasasignificantinteractionbetweenPicture maticaltensesofsentences.Thistightcouplingbetweenaction
typeandEventtype,χ2(1)=9.36,p=.002.Posthoccompari- andknowledgeofobjectssupportstheIOHmodel(Altmann&
sonsshowedthattherewasnosignificantdifferenceinverifica- Ekves, 2019) that language comprehension involves activating
tion time between a minimal change (LSMEANS: 1,175 ± 49 situatedobjectstatesbeforeandafterobjectstate-change.
ms)andasubstantialchange(LSMEANS:1,169±49ms,p= Onelimitationofthisstudyisthatwemeasuredtheactiva-
.998) when the probe picture indicated an original state of the tion of object representation at the end of sentence reading,
object. However, the modified state was verified significantly whichmayonlybeabletocapturepartoftheactivationpro-
faster,whenthesentenceindicatedasubstantialchangeofstate cessing. Another potential confound was that the degree of
event (LSMEANS: 1,199 ± 49 ms) than a minimal change of changewasmanipulatedbyusingtwodifferentverbs.Thus,
stateevent(LSMEANS:1,349±49ms,p<.001)(seeFig.4). theeffectsthatweobservedmightbedrivenbythesemantic
These results are partly consistent with the findings of associationsbetweentheactionsandtheperceptualproperties
Experiment2inthattherewasamatchadvantageforthemod- ofthe objects (e.g.,Bach,Nicholson,& Hudson, 2014).For
ified state in the change situation compared to the no-change example,thedroppedicecreamcouldbeassociatedwiththe
situation. That is, when a picture of a Bdropped^ ice cream is Bdrop^actionbutnottheBchoose^action.Withoutanysim-
presented to participants, they might associate the picture with ulationofthemotororperceptualpropertiesofthesituation,
theBdrop^action,butnotnecessarilywiththeBchoose^action. one may even establish the link between the object and the
However,asopposedtoExperiment2,theoriginalstatedidnot consequencesoftheaction.
show any match advantage in the minimal change condition In conclusion, our experiments demonstrate that perceptual
comparedwiththesubstantialchangecondition.Previousempir- propertiesofobjectscanbeactivatedinlanguagecomprehension
ical studies have shown facilitatory effects between action and andmodulatedbythecontentofthelinguisticinput.Theinter-
affordances of objects (e.g., Symes et al., 2007). Our findings playbetweengeneralsemanticknowledgeaboutobjectsandthe
maybeaccountedbytheequalaffordanceoftheoriginalstatefor episodicknowledgeintroducedbythesententialcontextiscap-
aminimalchangeandasubstantialchangeinthefuturetense.By tured by dynamics of event representation in language
comparison,inthepasttense,theoriginalstatematchedtheend comprehension.
stateoftheminimalchange,butitdidnotaffordfurthersubstan-
tialchangesanddidnotmatchtheconsequences,leadingtothe Dataaccessibilitystatement Thematerialsanddataforalltheexperiments
canbefoundontheOpenScienceFramework(https://osf.io/cvrm3/).
match/mismatcheffect.
Author contributions Contributed to conceptionand design: XK, AE,
GHJ,RAZ,GTMA
General discussion
Contributedtoacquisitionofdata:XK,GHJ,GTMA
Contributed to analysis and interpretation of data: XK, AE, GHJ,
RAZ,GTMA
In this study, we reported findings of three experiments that
Draftedand/orrevisedthearticle:XK,AE,GHJ,RAZ,GTMA
exploredtheactivationofobjects’mentalrepresentationsinlan-
Approvedthesubmittedversionforpublication:XK,AE,GHJ,RAZ,
guage comprehension. More specifically, we investigated the GTMA
influenceofobject-state(originalvs.modified)thatwasmanip-
ulatedbydegreeofchangeoftheevent(aminimalchangevs.a Funding information This research was supported by an Overseas
substantialchange)andgrammaticaltense(pasttensevs.future ResearchScholarshipfromtheUniversityofYorkawardedtoXinKang.
tense)onpictureverificationresponses.Ourstudyshowedthat
Compliancewithethicalstandards
theoriginalstatewasrespondedtofasterthanthemodifiedstate
when only object name was presented (Experiment 1).
Competing interests The authors declare that they do not have any
Nonetheless,whencontextualinformationwasprovided,thede-
competinginterests.
scribedsituationinlanguagemodulatedtheresponses.Objectsin
the modified state were verified more quickly when they was
described to experience a substantial change than a minimal
change sentences in both past tense (Experiment 2) and future References
tense (Experiment 3). However, objects in their original state
were only verified more quickly when they were described to Altmann,G.T.M.(2017).Abstractionandgeneralizationinstatistical
experienceaminimalchangethanasubstantialchangecondition learning:implicationsfortherelationshipbetweensemantictypes
in past tense sentences (Experiment 2) but not in future-tense and episodic tokens. Philosophical Transactions of the Royal
SocietyofLondon.SeriesB,BiologicalSciences,372(1711).
sentences. Our results suggested that the activation of the con-
Altmann, G.T. M., & Ekves, Z.(2019). Events asintersectingobject
textuallyappropriateobjectrepresentationwasmodulatedbythe
histories: A new theory of event representation. Psychological
degree of change. Our findings also indicated that there was a Review.

398 MemCogn(2020)48:390–399
Altmann, G.T. M., & Kamide,Y. (2007). The real-time mediation of Morford, J. P., & Goldin-Meadow, S.(1997).FromHere and Nowto
visualattentionbylanguageandworldknowledge:Linkingantici- There and Then: The Development of Displaced Reference in
patory(andother)eyemovementstolinguisticprocessing.Journal HomesignandEnglish.ChildDevelopment,68(3),420.
ofMemoryandLanguage,57,502–518. Mahon,B.Z.,&Caramazza,A.(2011).Whatdrivestheorganizationof
Bach,P.,Nicholson,T.,&Hudson,M.(2014).Theaffordance-matching objectknowledgeinthebrain?TrendsinCognitiveSciences,15(3),
hypothesis:howobjectsguideactionunderstandingandprediction. 97–103.
FrontiersinHumanNeuroscience,8,254. Nikole D. Patson, (2016) Evidence in support of a scalar implicature
Barsalou,L.W.(1999).Perceptualsymbolsystems.TheBehavioraland account of plurality.. Journal of Experimental Psychology:
BrainSciences,22(4),577–609;discussion610–660. Learning,Memory,andCognition42(7):1140-1153
Bates,D.,Mächler,M.,Bolker,B.,&Walker,S.(2015).FittingLinear Bach, P., Nicholson, T., Hudson, M. (2014) Theaffordance-matching
Mixed-EffectsModelsUsinglme4.JournalofStatisticalSoftware, hypothesis:howobjectsguideactionunderstandingandprediction.
Articles,67(1),1–48. FrontiersinHumanNeuroscience8
Baayen,R.H.,Davidson,D.J.,&Bates,D.M.(2008).Mixed-effects Radvansky, G. A. (2005). Situation models, propositions, and the fan
modeling with crossed random effects for subjects and items. effect.PsychonomicBulletin&Review,12(3):478-483.
JournalofMemoryandLanguage,59(4),390–412. Radvansky,G.A.,&Copeland,D.E.(2006).Walkingthroughdoorways
Bergen, B., & Chang, N. (2005). Embodied construction grammar in causesforgetting:Situationmodelsandexperiencedspace.Memory
simulation-based language understanding. In J.-O. Ostman & M. &Cognition,34(5),1150-1156.
Fried (Eds.), Construction Grammars: Cognitive Grounding and Radvansky, G. A. & Copeland, D. E. (2010). Reading times and the
TheoreticalExtensions(147–190).Amsterdam:Benjamins detection of event shift processing. Journal of Experimental
Bergen,B.,&Wheeler,K.(2010).Grammaticalaspectandmentalsim- Psychology,Learning,Memory,andCognition,36,210-216.
ulation.BrainandLanguage,112(3),150–158. R Core Team (2016) R: A Language and Environment for Statistical
Computing. R Foundation for Statistical Computing, Vienna,
Connell,L.(2007).Representingobjectcolourinlanguagecomprehen-
Austria.https://www.R-project.org/.
sion.Cognition,102(3),476-485.
Radvansky, G. A., Zwaan, R. A., Federico, T., & Franklin, N. (1998).
Cuccio,V.,&Carapezza,M.(2015).Isdisplacementpossiblewithout
Retrieval from temporally organized situation models. Journal of
language? Evidence from preverbal infants and chimpanzees.
PhilosophicalPsychology,28(3),369–386. Experimental Psychology: Learning, Memory, and Cognition, 24,
1224-1237.
deKoning,B.B.,Wassenburg,S.I.,Bos,L.T.&vanderSchoot,M.
Šetić, M., & Domijan,D.(2017). Numerical congruency effect inthe
(2017.Mentalsimulationoffourvisualobjectproperties:similari-
sentence-pictureverificationtask.ExperimentalPsychology,64(3),
tiesanddifferencesasassessedbythesentence-pictureverification
159-169.
task.JournalofCognitivePsychology.29,420-432.
Solomon,S.H.,Hindy,N.C.,Altmann,G.T.M.,&Thompson-Schill,S.
Ferretti, T. R., Kutas, M., & McRae, K. (2007). Verb aspect and the
L.(2015).CompetitionbetweenMutuallyExclusiveObjectStates
activation of event knowledge. Journal of Experimental
Psychology.Learning,Memory,andCognition,33(1),182–196. in Event Comprehension. Journal of Cognitive Neuroscience,
27(12),2324–2338.
Glenberg,A.M.,Meyer,M.,&Lindem,K.(1987).Mentalmodelscon-
Speer,N.K.,Zacks,J.M.(2005).Temporalchangesaseventboundaries:
tribute to foregrounding during text comprehension. Journal of
Processing and memory consequences of narrative time shifts.
MemoryandLanguage,26,69–83.
JournalofMemoryandLanguage,53,125-140.
Hindy,N.C.,Altmann,G.T.M.,Kalenik,E.,&Thompson-Schill,S.L.
Stanfield,R.A.,&Zwaan,R.A.(2001).Theeffectofimpliedorientation
(2012).Theeffectofobjectstate-changesoneventprocessing:doob-
derivedfromverbalcontextonpicturerecognition.Psychological
jects compete with themselves? The Journal of Neuroscience: The
Science,12,153-156.
OfficialJournaloftheSocietyforNeuroscience,32(17),5795–5803.
Symes, E., Ellis, R.,& Tucker, M. (2007). Visual object affordances:
Hockett, Charles F. (1960). The origin ofspeech, Scientific American, objectorientation.ActaPsychologica,124(2),238–255.
203,88-111.
Van Dijk, T.A., & Kintsch, W. (1983). Strategies of discourse
Hoeben-Mannaert,L.,Dijkstra,K.,&Zwaan,R.A.(2017).Iscoloran
comprehension.NewYork:AcademicPress.
integralpartofarichmentalsimulation?Memory&Cognition,45,
Wassenburg,S.I.,&Zwaan,R.A.(2010).Readersroutinelyrepresent
974-982.
implied object rotation: the role of visual experience. Quarterly
Huettig,F.,&Altmann,G.T.M.(2007).Visual-shapecompetitionduring JournalofExperimentalPsychology,63(9),1665–1670.
language-mediatedattentionisbasedonlexicalinputandnotmodulated
White, P. A. (1991). Ambiguity in the internal/external distinction in
bycontextualappropriateness.VisualCognition,15(8),985–1018.
causal attribution. Journal of Experimental Social Psychology,
Huettig,F.,&Altmann,G.T.M.(2011).Lookingatanythingthatisgreen 27(3),259–270.
whenhearingBfrog^:Howobjectsurfacecolourandstoredobject
Winter, B., & Bergen, B. (2012). Language comprehenders represent
colourknowledgeinfluencelanguage-mediatedovertattention.The object distance both visually and auditorily. Language and
QuarterlyJournalofExperimentalPsychology,64(1),122–145. Cognition,4(1),1–16.
Johnson-Laird,P.N.(1983).Mentalmodels.Cambridge,MA:Harvard Yaxley,R.H.,&Zwaan,R.A.(2007).Simulatingvisibilityduringlan-
UniversityPress. guagecomprehension.Cognition,105(1),229–236.
Kukona,A.,Altmann,G.T.M.,&Kamide,Y.(2014).Knowingwhat, Yee,E.,Huffstetler,S.,&Thompson-Schill,S.L.(2011).Functionfol-
where, and when: event comprehension in language processing. lowsform:Activationofshapeandfunctionfeaturesduringobject
Cognition,133(1),25–31.
identification. Journal of Experimental Psychology: General,
Lenth,R.(2016).Least-SquaresMeans:TheRPackagelsmeans.Journal 140(3),348.
ofStatisticalSoftware,Articles,69(1),1–33.
Zwaan, R. A., Langston, M. C., & Graesser, A. C. (1995). The
Liszkowski, U., Schäfer, M., Carpenter, M., & Tomasello, M.(2009). ConstructionofSituationModelsinNarrativeComprehension:An
Prelinguisticinfants,butnotchimpanzees,communicateaboutab- Event-IndexingModel.PsychologicalScience,6(5),292–297.
sententities.PsychologicalScience,20(5),654–660. Zwaan, R. A. (1996). Processing narrative time shifts. Journal of
Madden,C.J.&Zwaan,R.A.(2003).Howdoesverbaspectconstrain Experimental Psychology: Learning, Memory, and Cognition. 22
eventrepresentations?Memory&Cognition,31,663-672. (5):1196-1207.

MemCogn(2020)48:390–399 399
Zwaan,R.A.(2016).Situationmodels,mentalsimulations,andabstract Zwaan,R.A.,&Radvansky,G.A.(1998).Situationmodelsinlanguage
concepts in discourse comprehension. Psychonomic Bulletin & andmemory.PsychologicalBulletin,123,162-185.
Review,23(4),1028–1034. Zwaan, R. A., Stanfield, R. A., & Yaxley, R. H. (2002). Language
Zwaan,R.A.,Madden,C.J.,Yaxley,R.H.,&Aveyard,M.E.(2004). comprehenders mentally represent the shapes of objects.
Movingwords: dynamic representations in language comprehen- PsychologicalScience,13(2),168–171.
sion.CognitiveScience,28(4),611–619.
Zwaan, R.A., & Pecher, D. (2012). Revisiting Mental Simulation in Publisher’s note Springer Nature remains neutral with regard to
LanguageComprehension:SixReplicationAttempts.PLoSONE,7,
jurisdictionalclaimsinpublishedmapsandinstitutionalaffiliations.
e51382.

## 引用

```

```
