---
title: AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
authors: Annelies Kleinherenbrink, Jed Brown, Marcela Suarez, Groote Beverborg, Lucy Avraamidou, Andrea Reyes, Olivia Guest, Dagmar Monett, Ileana Camerino, Juliette Alenda
year: N/A
keywords: highereducation, artificialintelligence, digitaltechnology, criticalanaly-
created: 2025-11-23 18:05:46
---

# AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia

## 基本信息

- **作者**: Annelies Kleinherenbrink, Jed Brown, Marcela Suarez, Groote Beverborg, Lucy Avraamidou, Andrea Reyes, Olivia Guest, Dagmar Monett, Ileana Camerino, Juliette Alenda
- **年份**: N/A
- **關鍵詞**: highereducation, artificialintelligence, digitaltechnology, criticalanaly-

## 摘要

Under the banner of progress, products have been uncritically adopted or
evenimposedonusers—inpastcenturieswithtobaccoandcombustionengines,andin
the21stwithsocialmedia.Forthesecollectiveblunders,wenowregretourinvolvementor
apathyasscientists,andsocietystrugglestoputthegeniebackinthebottle.Currently,we
aresimilarlyentangledwithartificialintelligence(AI)technology.Forexample,soft-
wareupdatesarerolledoutseamlesslyandnon-consensually,MicrosoftOfficeisbun-
dledwithchatbots,andwe,ourstudents,andouremployershavehadnosay,asitisnot
consideredavalidpositiontorejectAItechnologiesinourteachingandresearch.This
iswhyinJune2025,weco-authoredanOpenLettercallingonouremployerstoreverse
andrethinktheirstanceonuncriticallyadoptingAItechnologies.Inthispositionpiece,
a)
weexpoundonwhyuniversitiesmusttaketheirroleseriouslyto counterthetechnology
b)
industry’smarketing,hype,andharm;andto safeguardhighereducation,critical
thinking,expertise,academicfreedom,andscientificintegrity.Weincludepointersto
relevantworktofurtherinformourcolleagues.
Keywords:highereducation;artificialintelligence;digitaltechnology;criticalanaly-
sis;openletter;policy
1

## 研究背景

## 研究方法

## 主要結果

## 討論與結論

## 個人評論

## 相關文獻

## 完整內容

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
AGAINST THE UNCRITICAL ADOPTION OF ‘AI’
TECHNOLOGIES IN ACADEMIA
Olivia Guest1,2, Marcela Suarez1, Barbara C. N. Müller3, Edwin van
Meerkerk4, Arnoud Oude Groote Beverborg5, Ronald de Haan6,
Andrea Reyes Elizondo7, Mark Blokpoel1,2, Natalia Scharfenberg1,2,
Annelies Kleinherenbrink1,8, Ileana Camerino1, Marieke
Woensdregt1,2, Dagmar Monett9, Jed Brown10, Lucy Avraamidou11,
Juliette Alenda-Demoutiez12, Felienne Hermans13, and Iris van
Rooij1,2,14
1DepartmentofCognitiveScienceandArtificialIntelligence,RadboudUniversity,TheNetherlands
2DondersInstituteforBrain,Cognition,andBehaviour,RadboudUniversity,TheNetherlands
3Communication&Media,BehaviouralScienceInstitute,RadboudUniversity,TheNetherlands
4RadboudInstituteforCultureandHistory,RadboudUniversity,TheNetherlands
5PedagogicalandEducationalSciences,RadboudUniversity,TheNetherlands
6InstituteforLogic,LanguageandComputation,UniversityofAmsterdam,TheNetherlands
7CWTS&LUCAS,FacultiesofSocialSciences&Humanities,LeidenUniversity,TheNetherlands
8GenderandDiversity,RadboudUniversity,TheNetherlands
9ComputerScienceDept.,BerlinSchoolofEconomicsandLaw,Germany
10DepartmentofComputerScience,UniversityofColorado,USA
11InstituteforScienceEducationandCommunication,UniversityofGroningen,TheNetherlands
12DepartmentofEconomicsandBusinessEconomics,RadboudUniversity,TheNetherlands
13VrijeUniversiteitAmsterdam,TheNetherlands
14DepartmentofLinguistics,CognitiveScience,andSemiotics,AarhusUniversity,Denmark
Abstract: Under the banner of progress, products have been uncritically adopted or
evenimposedonusers—inpastcenturieswithtobaccoandcombustionengines,andin
the21stwithsocialmedia.Forthesecollectiveblunders,wenowregretourinvolvementor
apathyasscientists,andsocietystrugglestoputthegeniebackinthebottle.Currently,we
aresimilarlyentangledwithartificialintelligence(AI)technology.Forexample,soft-
wareupdatesarerolledoutseamlesslyandnon-consensually,MicrosoftOfficeisbun-
dledwithchatbots,andwe,ourstudents,andouremployershavehadnosay,asitisnot
consideredavalidpositiontorejectAItechnologiesinourteachingandresearch.This
iswhyinJune2025,weco-authoredanOpenLettercallingonouremployerstoreverse
andrethinktheirstanceonuncriticallyadoptingAItechnologies.Inthispositionpiece,
a)
weexpoundonwhyuniversitiesmusttaketheirroleseriouslyto counterthetechnology
b)
industry’smarketing,hype,andharm;andto safeguardhighereducation,critical
thinking,expertise,academicfreedom,andscientificintegrity.Weincludepointersto
relevantworktofurtherinformourcolleagues.
Keywords:highereducation;artificialintelligence;digitaltechnology;criticalanaly-
sis;openletter;policy
1

O.Guestetal.
1 Overview
ThecultureofAIisimperialistandseekstoexpandthekingdomofthemachine.TheAI
communityiswellorganizedandwellfunded,anditsculturefitsitsdreams:ithashigh
priests,itsgreedybusinessmen,itscannypoliticians.TheU.S.DepartmentofDefense
is behind it all the way. And like the communists of old, AI scientists believe in their
revolution;theoldmythsoftragichubrisdon’ttroublethematall.
TonySolomonidesandLesLevidow(1985,pp.13–14)
This paper sets out our expert position on artificial intelligence (AI) technologies permeating the
highereducationsector,demonstratinghowthisdirectlyerodesourabilitytofunction(seealsoour
, Guest, van Rooij, et al. 2025). The harms to our fields and students that directly re-
Open Letter
sult from the technology sector corrupting our practices unchecked and unimpeded are manifold:
from conflicts of interest that go unreported or are worn as badges of honour by colleagues (Mo-
hamed Abdalla and Moustafa Abdalla 2021), to the mushrooming of chatbots in software we are
coercedtouse,suchasinMicrosoftOffice.Thisishighlyproblematic,asacademiaismeanttobea
refugeforknowledgeproductionindependentfromulteriormotives,weavingtogetherteachingand
research.Researchfundingandacademicfreedomarepresentlyunderaworldwideattack(ALLEA
2025;Kinzelbachetal.2025;KNAW2021,2025).Thetechnologyindustryistakingadvantageofus,
sometimesevenspeakingthroughus,toconvinceourstudentsthattheseAItechnologiesareuseful
(ornecessary)andnotharmful.Therefore,wearguethatuniversityleadersandadministratorsmust
act to help us collectively turn back the tide of garbage software, which fuels harmful tropes (e.g.
so-called lazy students) and false frames (e.g. so-called efficiency or inevitability) to obtain market
penetrationandincreasetechnologicaldependency.
WhenitcomestotheAItechnologyindustry,werefusetheirframes,rejecttheiraddictiveand
brittle technology, and demand that the sanctity of the university both as an institution and a set
of values be restored. If we cannot even in principle be free from external manipulation and anti-
scientificclaims—andinsteadremainpassivebydefaultandwelcomecorrosiveindustryframesinto
ourcomputersystems,ourscientificliterature,andourclassrooms—thenwehavefailedasscientists
andaseducators.
2 Marketing,hype,&harm
Inanygivenprofessionalfield,specializedjargonisoftennecessaryinordertoexchange
information more succinctly and specifically; it makes communication clearer. But in
a cultish atmosphere, jargon does just the opposite: Instead, it causes speakers to feel
confusedandintellectuallydeficient.Thatway,they’llcomply.
AmandaMontell(2021,pp.136–137)
AIhasalwaysbeenamarketingphrasethaterodesscientificinquiryandscholarlydiscussionbyde-
sign,leavingthedooropentopseudoscience,exclusion,andsurveillance(cf.BirhaneandGuest2021;
Guest2025;GuestandForbes2024;vanRooij,Guest,etal.2024;Wendling2002).Fromitsincep-
tion in the 1950s, the phrase ‘artificial intelligence’ was used to sell research, to spice up existing re-
searchprogrammesandattractfunding(AAUP2025;Bender2024;Bloomfield1987;Heffernan2019;
Markeliusetal.2024;McCorduck2004).
Weproposethata2month,10manstudyofartificialintelligencebecarriedoutduring
thesummerof1956atDartmouthCollegeinHanover,NewHampshire.Thestudyisto
proceedonthebasisoftheconjecturethateveryaspectoflearningoranyotherfeature
2

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
of intelligence can in principle be so precisely described that a machine can be made
to simulate it. An attempt will be made to find how to make machines use language,
formabstractionsandconcepts,solvekindsofproblemsnowreservedforhumans,and
improvethemselves.Wethinkthatasignificantadvancecanbemadeinoneormoreof
theseproblemsifacarefullyselectedgroupofscientistsworkonittogetherforasummer.
JohnMcCarthyetal.(1955,p.2)
Thisproposalprovedtootemptingtoignoreforcolleaguesandfunders—bothinthe“2month”
speedofdeliveryandtheloftygoalofmachinescapturing“everyaspectoflearning”and“featureof
intelligence.” It shows that since the start imprecise jargon was used to make exaggerated promises
withthegoaltopleaseinvestors,claimsthatfundamentallyremainpromisestothisday.
Although some differentiate AI and non-AI systems by appealing to generative models versus
othertypesofAI,weareconvincedthatthisdoesnotbringclaritytothediscussion,andwecanfall
headfirstintomisuseofterminologyandfosteringindustryhype(seeTable1andFigure1;cf.Guest
2025).Grantingthatdistinction,forexample,makesclassifierssuchas ,formally
BernoullinaiveBayes
agenerativemodel,AItechnologysimilartohypedapplications(Efron1975;Jebara2004;Mitchell
1997;NgandJordan2001;XueandTitterington2008).However,astatisticalmodelliketheBernoulli
naiveBayesclassifier,whichisusedtoanalysedata,isunrelatedtoindustryhype.Bythesametoken,
spellchecksoftware(whichhasnothistoricallybeencomposedofgenerativenorstochasticmodels)
also falls under AI in some definitions, but not under others. Similar terminological problems also
holdforphraseslike‘agenticAI’(Chawlaetal.2024;HosseiniandSeilani2025)—systemsthatcan
autonomouslyadapttheirenvironment,makecontext-sensitive‘decisions’,andactuponthemwith-
outanyhumanintervention.Formally,systemslikethermostats,microwaveovens,andtrafficlights
are agentic in this sense and fall under AI, but are not products we wish to proscribe. Informally,
however,‘agentic’ismisusedtoinduceanthropomorphisationthatwecannotendorse(cf.Bandura
2001;Barrow2024;Helfrich2024).
ThereisnothingprivilegedaboutgenerativeAI,noranyAItechnology,inanypedagogicalorso-
ciotechnicalsense(seeTable1).Importantly, technologyunderourpurviewasacademics,ought
all
tofallunderthesamecriticalconsiderations.Thus,toframegenerativeAIasuniqueordramatically
differenttootherAIsystemsappearsanti-intellectual.RecallthatgenerativeAIisameretechnicaldif-
ference(i.e.whichstatisticaldistributionasystemiscapableof)andnotsomesubstantivesociotechni-
caldeparture.Andsonon-generativeAIcanbehighlyproblematic,suchascomputervisionsystems
whichareusedbythemilitaryandpolice(BirhaneandPrabhu2021;Falletti2024;Wood2024).Such
systemsalsocomprisestolendata,requireenslavedpeopletotagthedata,andproducebiasedresults
(Birhane,Dehdashtian,etal.2024;Birhane,Prabhu,etal.2023;Kallurietal.2025;Taitetal.2022).
The Euler diagram in Figure 1 demonstrates that such hyped labels — Large Language Model
(LLM),ArtificialNeuralNetwork(ANN),generativemodel,chatbot—areinterwovenincompli-
cated ways such that their referents remain ambiguous (cf. Guest 2025). Importantly, this defiance
holdsunderanyrearrangementofthesetsandelements:onecannotusethesewordswithoutencoun-
teringadditionalproblemsandfosteringambiguity(Alkhatib2024).Wecannotescapethisquagmire
withmorejargon.Andso,weareconvincedthatwhenthetechnologyindustrypresentsusecasesfor
thelabelgenerativeAI(suchasforLLMs,butnotBernoullinaiveBayes;Figure1),thisisastrategy
toelicitconfusedresponsesagainst‘generativeAI,’deflectingattentionfromotherproblematicAI
systems(Table1).Thisfeedsintothehypeandobstructsamoregeneralcritiqueofsimilarunethical
orunwantedAIsystems(cf.Guest2025).Shouldwecontinuedownthisroad,thetechnologyindus-
trywillslipthroughsuchadistinction,skippingfromterminologytoterminology,consolidatingits
power.Ithasindeeddonesomanytimesbeforebyusingpreviousphrasesasbuzzwordslikebigdata,
machinelearning,deepneuralnetworks,andpermutationsthereof.
3

O.Guestetal.
Tofurtherdemystifythemarketingphrase‘AI’,wecanexaminethephrase’sconstituentwords.
Ontheonehand, intelligenceisitselfbadlyunderstood.Whenwecompareartificial‘intel-
artificial
ligence’withotherartificialsystems,weseethatforexample,artificialheartsdoindeedpumpblood
(Dretske1994;KristanandKatz2006;Millikan2021;Powell1970;Schellenberg2018).Thisisbecause
pumpingbloodisastraightforwardlyunderstoodaspectofaheart,artificialorotherwise.However,
definingthefunctionofasystemdoesnottranslatesoeasilytoAI.Wecannotsaywhatthefunction
ofintelligenceinthegeneralcaseis(Blokpoel2018;Chirimuuta2018;Egan1999,2017,2018;Figdor
2010;GuestandMartin2023;Hardcastle1996;Richetal.2021;vanRooij,Guest,etal.2024).Asintel-
ligenceisnotwelldefined,falseclaimsofAIsystems’cognitiveabilities,suchassuggestionsthatsuch
systemscancommunicate,read,orgivefeedback,seemappealingatfirstglance.However,through
suchclaimsfakepurposeisinvented,whichcanbeexposedbycognitivescience(Guest2025;Guest
andMartin2025b;Guest,Scharfenberg,etal.2025;vanRooij,Guest,etal.2024).Thisfakepurposeis
illustratedbythefactthatAIoftendoesnotfunctionasitsaysonthetin(Bainbridge1983;Brennanet
al.2025;Eaton2025;Rajietal.2022),leadingtocharacterisationsofAIas“snakeoil”(Narayananand
Kapoor2024),a“con”(BenderandHanna2025),“fake”(Kaltheuner2021),and“fascist”(McQuillan
2022).
Ontheotherhand, hasaracist,sexist,classist,andableistinheritancethatithasnot
intelligence
managedtoshakeoff,fromsuperficialpseudosciencetoeugenicsandgenocide(Dennis1995;Gould
1981; Norrgard 2008; Reddy 2007; Saini 2019). It is important to be aware that this sordid history
rearsitsheadinAI’spresent,makingthesesystemsespeciallyharmfultominoritisedandvulnerable
groups(Allen2017;M.Andrewsetal.2024;Bates2025;Benjamin2019,2024;Birhane2022;Birhane,
Prabhu,etal.2023;Blasetal.2025;Brennanetal.2025;Dhaliwaletal.2024;Erscoietal.2023;Evans
2020;ForbesandGuest2025;GebruandTorres2024;Guest2025;M.Hicks2017;McQuillan2025;
SpantonandGuest2022;S.M.Tayloretal.2023;vanderGunandGuest2024).
Forallthesereasons,wetaketheprincipledpositionthatjargoninfusedwithtechnologyindustry
hype,suchasshowninTable1,doesnotmeaningfullyexplain.Similarly,separatingAIasageneral
termintogoodandbadleadsnowhereexcepttoblurringclarityandsupportinghype.Westriveto
remaincriticalofthevocabularythetechnologyindustrycooptsanddeploys,andtoremainrespectful
ofscientificterminology.
3 Highereducation,criticalthinking,expertise,&academicfreedom
ThecultureofAIencouragesafirm,evensnide,convictionthatit’sjustamatteroftime.
Itthrivesonexaggerationandrefusestoexamineitsownfailures.
TomAthanasiou(1985,p.18)
When it comes to AI technology used in a university context, it is important to focus on the rela-
tionshipbetweenatechnologyandsocietyatlarge.Thevalueofscholarlyanalysesofsociotechnical
relationshipscanbeseenincasessuchasthefollowing.IntheUK,aschoolshootingin1996,theDun-
blanemassacre,ledtostricterguncontrollaws.Sincethen,thesociotechnicalrelationshipbetween
citizensandgunshasremainedunchanged,thereforehandgunprivilegeshavenotbeenreintroduced
tothepublic(N.Brown1996;Shapiroetal.2022).Thisrelationshipisdifferenttothatcapturedby
therighttobeararmsintheUSA.Suchanalysesillustratehowdifferentsocietiesmaycreatedifferent
legalframestomatchhowtheyperceivetheirrelationshiptotechnology.
Furthermore,problematisingsociotechnicalrelationshipsitselfallowsforreclaimingAIasasci-
entificfieldfromthegripsofindustryorhype(BirhaneandGuest2021;GuestandForbes2024;van
Rooij,Guest,etal.2024;Wendling2002).Moreover,itallowsforrulingoutreclaimingasafunction
ofopinionsaboutpossibleandimpossiblechangestosociety,thetechnology,andtheirrelationship
4

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
LLLLMM
AANNNN
BBEERRTT
SSiirrii
EELLIIZZAA
JJaabbbbeerrwwaacckkyy CChhaattGGPPTT GGPPTT AAlleexxNNeett
AA..LL..II..CC..EE..
BBMM
GGAANN
cchhaattbboott
QQDDAA LLDDAA
BBeerrnnoouullllii
ggeenneerraattiivveemmooddeell
nnaaiivvee BBaayyeess
AAII
Figure1.Acartoonsettheoreticviewonvariousterms(seeTable1)usedwhendiscussingthesupersetAI
(blackoutline,hatchedbackground):LLMsareinorange;ANNsareinmagenta;generativemodelsare
inblue;andfinally,chatbotsareingreen.Wheretheseintersect,thecoloursreflectthat,e.g.generativead-
versarialnetwork(GAN)andBoltzmannmachine(BM)modelsareinthepurplesubsetbecausetheyare
bothgenerativeandANNs.Inthecaseofproprietaryclosedsourcemodels,e.g.OpenAI’sChatGPTand
Apple’sSiri,wecannotverifytheirimplementationandsoacademicscanonlymakeeducatedguesses(cf.
Dingemanse2025).Undefinedtermsusedabove:BERT(Devlinetal.2019);AlexNet(Krizhevskyetal.
2017);A.L.I.C.E.(Wallace2009);ELIZA(Weizenbaum1966);Jabberwacky(Twist2003);lineardiscrim-
inantanalysis(LDA);quadraticdiscriminantanalysis(QDA).
(Adams2021;Avraamidou2024;ForbesandGuest2025;Whittaker2021).Toillustrate,considerdriv-
inginthegeneralcaseversusdrivingapatienttohospital.Obviously,bothproduceaseriesofknown
pollutants.However,drivingapatienttohospitalhasadifferentmoralweight.Importantly,anexpert
paramedicdriverhasbeentaughttodriveanambulanceregardlessoffuelusageinemergencysitua-
tions.However,thedriverwillnotbetaughttodisregardfuelusageinothercasesnoravoidpublic
transportforpersonaltravel.Similarly,AIsystemshavenuancesthatweasexpertsmustanalyseand
impartonourstudents.
Inthissection,wetacklevariouspositionsontheAI-universityrelationshipthatappeartopass
withoutcritiqueinacademicandwiderspheres.Westateourpositionineachcase.
5

O.Guestetal.
Table1.Belowsomeofthetypicalterminologicaldisarrayisuntangled.Importantly,noneoftheseterms
areorthogonalnordotheyexclusivelypickoutthetypesofproductswemaywishtocritiqueorproscribe.
TERM DESCRIPTION RESOURCES
Thephrase‘artificialintelligence’wascoinedbyMc- Avraamidou(2024),Benderand
Carthy et al. (1955) in the context of proposing a Hanna(2025),Bloomfield(1987),
Artificial summer workshop at Dartmouth College in 1956. Boden(2006),Brennanetal.
(2025),Crawford(2021),Guest
Intelligence Theyassumedsignificantprogresscouldbemadeon
(2025),Hao(2025),McCorduck
(AI) makingmachinesthinklikepeople.Inthepresent,AI (2004),McQuillan(2022),Mon-
hasnofixedmeaning.Itcanbeanythingfromafield ett(2021),Vallor(2024),andvan
ofstudytoapieceofsoftware. Rooij,Guest,etal.(2024).
First proposed in McCulloch and Pitts (1943), it is a
mathematical model, comprised of interconnected
Abraham(2002),Bishop(2021),
Artificialneural banksofunitsthatperformmatrixmultiplicationand Boden(2006),Dhaliwaletal.
non-linearfunctions.Thesestatisticalmodelsareex- (2024),GuestandMartin(2023,
network(ANN)
posed to data (input-output pairs) that they aim to 2025a),Hamilton(1998),Stinson
(2018,2020),andWilson(2016).
reproduce. While held to be inspired by the brain,
suchclaimsaretenuousormisleading.
Anengineeredsystemthatappearstoconversewith
the user using text or voice. Speech synthesis goes
Bates(2025),Dillon(2020),
back hundreds of years (Dudley 1939; Gold 1990; Elder(2022),Erscoietal.
Chatbot Schroeder1966)andWeizenbaum’s(1966)ELIZAis (2023),Schlesingeretal.(2018),
considered the first chatbot (Dillon 2020). Modern Strengersetal.(2024),Turkle
(1984),andTurkleetal.(2006).
versionscancontainANNsinadditiontohardcoded
rules.
A proprietary closed source chatbot created by
Andhov(2025),Birhaneand
OpenAI. The for-profit company OpenAI has been
Raji(2022),Dupré(2025),Gent
steepedinhypefrominception.Itdoesnotprovide
(2024),M.T.Hicksetal.(2024),
source code for most of its models, violating open Hill(2025),Jackson(2024),
ChatGPT
science principles for academic users. OpenAI re- Kapooretal.(2024),Liesenfeld,
ported $5 billion in losses in 2024 (Reuters 2025), Lopez,etal.(2023),Mirowski
(2023),Perrigo(2023),Titus
andhasreceived$13billionfromMicrosoft(Levine
(2024),andWidderetal.(2024).
2024).
A specification on the type of statistical distribu-
tionmodelled;typicallycontrastedwithdiscrimina-
tivemodel.ANNscanbegenerative(e.g.Boltzmann Efron(1975),Jebara(2004),
Generative Mitchell(1997),NgandJordan
machines)ordiscriminative(e.g.convolutionalneu-
model (2001),andXueandTitterington
ralnetworksusedforclassifyingimages).Inthecon-
(2008).
textofgenerativeAIorgenerativepre-trainedtrans-
former(GPT),thisphraseisusedinconsistently.
Bender,Gebru,etal.(2021),
Amodelthatcapturessomeaspectoflanguage,with
BirhaneandMcGann(2024),
theterm‘large’denotingthatthenumberofparam-
Dentellaetal.(2023,2024),
Largelanguage eters exceed a certain threshold. Modern chatbots Leivada,Dentella,etal.(2024),
areoftenLLMs,whichuseANNs,alongwithagraph- Leivada,Günther,etal.(2024),
model(LLM)
ical interface so that users can input so-called text LuitseandDenkena(2021),Sho-
jaeeetal.(2025a),Villalobos
‘prompts.’LLMscanbegenerative,discriminative,or
etal.(2024),andWangetal.
neither.
(2024).
6

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
3.1 Rejectionofexpertise,ironicallyincludingourown
Beinginacolonizingdisciplinefirstdemandsandthenencouragesanattitudethatmight
becalledintellectualhubris.Furthermore,sinceyoucannotmasterallthedisciplinesthat
you have designs on, you need confidence that your knowledge makes the ‘traditional
wisdom’ of these fields unworthy of serious consideration. Here too, the AI scientist
feels that seeing things through a computational prism so fundamentally changes the
rulesofthegameinthesocialandbehaviouralsciencesthateverythingthatcamebefore
isrelegatedtoaperiodofintellectualimmaturity.
SherryTurkle(1984,p.230)
EveryfieldthatcomesintocontactwithAIdiscoursebecomesinfectedevenwithinAIasafieldof
study(recall Table1).Ourcolleagues haveembracedthesesystems, uncriticallyincorporatingthem
intotheirworkflowsandtheirclassrooms,withoutinputfromexpertsonautomation,cognitivesci-
ence, computer science, gender and diversity studies, human-computer interaction, pedagogy, psy-
chology, and law to name but a few fields with direct relevant expertise (Sloane et al. 2024). Mean-
while, technology companies have rushed to invest in ‘AI ethics’ or ‘AI safety’ to their
ethics wash
claims, thereby “laundering accountability” (as Abeba Birhane explains in Arseni 2025) and “dis-
tracti[ng]fromrealAIethics”(Crane2021),whilecensoringacademicsandthus,violatingacademic
freedom(GebruandTorres2024;Gerdes2022;Goudarzi2025;Munn2023;Ochigame2019;Suarez
etal.2025;Tafani2023).
AI extractivism is at play further afield from the subversion described above — it also directly
causesenvironmentalandsocialharms:water,energy,andoccupationoflandareallneededfordata
centres (Goetze 2024; Gray and Suri 2019; Hao 2025; Loe 2023; Luccioni et al. 2024; Markelius et
al. 2024; Parshley 2024; Perrigo 2023; Rowe 2023; Suarez et al. 2025; Tan 2025; Valinsky 2024). Yet,
industrysuggestsAItechnologycanbeusedtomitigatetheclimatecrises(Temple2024).Anditis
creeping into societythrough data colonialism, stimulatingthe extraction and commodificationof
data,givingtechfirmsimmensesocialpower,andthroughlabourexploitationandsocialinjustices
(Altenried2022;Aroraetal.2023;ColónVargas2025;O’Neil2016;Ricaurte2019).Intheacademic
context,promotingtheuseofLLMsdoesnotalignwithuniversityvaluesandecologicalsustainabil-
ity campaigns. Hence, we cannot remain complicit with the greenwashing rhetoric and actions of
thetechnologyindustry(Atkin2025).ResistingAItechnologiesmeansrefusingtotakearoleinthe
continuingdevastationoftheenvironmentandtheexploitationoflabour.
WhenwespeakoutagainsttheintroductionofAIproductsinourclassroomsweare“ridiculed
withimpunity”(Mirowski2023,p.740).However,asDjoerdHiemstra(2023)explains: arenot
we
the villains (cf. Schipper 2025). Sounding the alarm about AI as an educational technology is the
onlysensiblethinguntilandunlesswediscussthe ofeducationregardingAI.Then,itisclear
purpose
thattheauthors’pedagogicalgoalsandAIuseareincompatible.Whatisurgentlyneeded,instead,is
,suchaswelayoutinthispaper(HeegandAvraamidou2024;McQuillan2022;
CriticalAILiteracy
McQuillan et al. 2024; Monett and Paquet 2025; Suarez et al. 2025; Whittaker 2021). Importantly,
—encouragingAIusewhilebeing‘awareoftherisks’—mustbeavoided:
criticalwashing
WhenwecritiqueAI,weshoulddosowithintellectualhonestyandinaprincipledway.
[R]eflectingontheharmsofAIisnotitselfharmreduction.Itmayevencontributeto
rationalizing, normalizing, and enabling harm. Critical reflection without appropriate
actionisthusquintessentiallycriticalwashing.
MarcelaSuarezetal.(2025,par.7)
Infact,thevastmajorityofresearchonAIineducationonlyexaminesissuesconnectedtoautoma-
tionandassessment,andnotlearning(Avraamidou2024).Weproposethatresearchexploringtheuse
7

O.Guestetal.
ofAIineducationisshiftedfromatechnicalapproachtoasocioculturalandprocessapproachthat
aimstorebalancequalification,socialisation,andsubjectification(Biesta2021).Thisshouldinclude
conceptssuchasequity,language,multiculturalism,identity,affectivedomainsoflearning,citizen-
shipandsocialjustice,forabetterunderstandingofwhatmightbetherole—ifany—ofAItools
inteachingandlearning.WecallontheeducationaltechnologycommunitytodemystifyAIsystems
andinsteadapproachthosewithmorecriticalityandhumility(cf.Tullyetal.2025).Indoingso,we
needtoshiftourattentionfromtechnologyindustryadvertisingtorobustevidence-basedresearch
ondevelopmentalprocesses.
Unfortunately,academiccontributions,fromthehumanitiestomathematics,andeverythingin
between,areallvulnerabletoAItechnology:productsexistorarebeingdevelopedthatclaimtobe
abletodisplacemanyformsofacademiclabour(Guest2025).Whilemostoftheseclaimsarebasedon
thinair,administratorsandpolicymakersseethemasopportunitiestofurthercutcostsandincrease
efficiency,inlinewiththedetrimentalneoliberalideologythatsuffuseshighereducation,furtherfos-
teringrejectionofexpertiseoftheirstaff(Baletal.2014;Bouchard2024;GillandDonaghue2016).
Importantly,suchdehumanisationbyAIcanhappenregardlessofintent(BirhaneandGuest2021;
Brennanetal.2025;Erscoietal.2023;Heffernan2024;McQuillan2022;O’Neil2016;Rhee2018;van
derGunandGuest2024).AreviewoftheliteratureshowsthatAIsystemsarebiasedandcantake
partin discriminatorypracticesthatreinforce andnormalizedominating hierarchiesregardingcul-
ture,race,andgenderwhileposingandbeingperceivedasneutralandobjectivetools(Avraamidou
2024).Werejectthisdebasinganddismantlingofexpertise,anddehumanisationofscholars,andre-
mainvigilantagainsttheerosionofacademiccontributionstounderstandingtheworld(CDHTeam
andRuddick2025;Crawley2025;Helfrich2024;Reedetal.2001;Sano-Franchinietal.2024).
3.2 Wedonothaveto‘embracethefuture’&wecanturnbackthetide
Itmustbethesheermagnitudeof[artificialneuralnetworks’]incompetencethatmakes
themsopopular.
JerryA.Fodor(2000,p.47)
Related to the rejection of expertise is the rejection of imagining a better future and the rejection
ofself-determinationfreefromindustryforces(HajerandOomen2025;Stengers2018;vanRossum
2025).NotonlyAIenthusiasts,butevensomescholarswhoseexpertiseconcentratesonidentifying
andcriticallyinterrogatingideologiesandsociotechnicalrelationships—suchashistoriansandgen-
derscholars—unfortunatelyfallpreytotheteleologicalbeliefthatAIisanunstoppableforce.They
embraceitbecausealternativeresponsesseemtoodifficult,incompatiblewithindustrydevelopments,
ornon-existent.Insteadoffallingforthis,weshould“refuse[AI]adoptioninschoolsandcolleges,
andrejectthenarrativeofitsinevitability.”(Reynoldsonetal.2025,n.p., alsoBenjamin2016;Cam-
poloandCrawford2020;CDHTeamandRuddick2025;Garciaetal.2022;Kellyetal.2025;Lysen
and Wyatt 2024; Sano-Franchini et al. 2024; Stengers 2018). Such rejection is possible and has his-
toricalprecedent,tonamejustafewsuccessfulexamples:Amsterdammerskickedoutcars,rejecting
thatcyclingthroughtheDutchcapitalshouldbedeadly.Organisedworkersdiedfortheeight-hour
workday,theweekendandotherworkers’rights,andgovernmentsbannedchlorofluorocarbonsfrom
fridgestomitigateozonedepletionintheatmosphere.Andweknowthateventhetideitselffamously
turnsback.Peoplecanundothings;andwewill(cf.Albanese2025;Boztas2025;KohnstammInsti-
tuut2025;vanLaarhovenandvanVugt2025).Besides,therewillbenofuturetoembraceifwedeskill
ourstudentsandselves,andallowthetechnologyindustry’simmensecontributionstoclimatecrisis
and environmental destruction to continue unimpeded (Benjamin 2024; Brennan et al. 2025; Mc-
Quillan2025;Suarezetal.2025;Tafani2024b).
8

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
WhenwearetoldthatwecannotbanAI—itisjusttooattractive—likewithallindustryhype
weshouldbothquestionthepremisesandcautionthat:
The idea of “irreversibility” points to the observation that, while technological trajec-
toriesareneverself-determiningorinevitable,thedifficultiesofundoingtechnological
projectsgrowovertime(Callon1990).
LucySuchman(2019,p.55)
It is exactly because problems continue to grow that we must speak out now. The repetition that
somehowthingsaresetinstoneneedstobeurgently,vociferously,andvigilantlycountered,especially:
thepublicdiscoursethatgoeslikethis:‘ChatGPThashappenedandit’sthewayforward
andweshouldembraceitandweshouldlearntobecreativeaboutourassessments’.I’m
notagainstbeingcreativeaboutassessments,buttheideaofembracingChatGPTseems
incrediblytoxic.Imean,dopeoplenotreadhowthesethingsaremade?Theydepend
oneyewatering—thisistheirownterm—costsofcarbonemissions.Theyarebuilton
massive exploitative ‘ghost labour’; crowdsourced and outsourced labour that follows
thepatternsofcolonialrelations(Bender,Gebru,etal.2021).
DanMcQuillanetal.(2024,p.3)
Shouldwefailtoturnthetide,weatleasttookaprincipledstandwhichisoneofourcoreduties
to society: to say what we think is the ideal thing to do based on our shared expertise. The rest of
societymightignoreus(oftentoourcollectiveperil).Butsayitwemust(Fuentes2024).
3.3 AhistoricismandtheAIhypecycles
WhenIstartedwritingaboutsciencedecadesago[...]Ieditedanarticleinwhich[acom-
puterscientist]predictedthatAIwouldsoonreplaceexpertsinlaw,medicine,finance
andotherprofessions.Thatwasin1984.
JohnHorgan(2020,n.p.)
Whenweengagewiththepublic,wenoticepeoplethinkthatAI,asafieldoratechnology,appeared
onthesceneinthelastthreeyears.Andtheyexperienceconfusionandevendissonancewhenthey
discover the field and the technologies have existed for decades, if not centuries or even millennia
(Bloomfield1987;Boden2006;Bogost2025;Guest2025;Hamilton1998;Mayor2018).Suchahistori-
cismfacilitates“theAI-hypecyclesthathavelongbeenfuelledbyextravagantclaimsthatsubstitute
fictionforscience.”(Heffernan2025,n.p.Duarteetal.2024).Wehavebeenherebefore,bothwithen-
tanglementsofAIandstatisticswithindustrycorruptingouracademicprocesses,andwithso-called
AIsummers:hypecyclesthatpivotfromfundingboomstocompletebustsandcessationofresearch
(Bassett and Roberts 2023; Boden 2006; Law 2024; Lighthill et al. 1973; Merchant 2023; Olazaran
1996;Perez2002;P.SmithandL.Smith2024;Thornhill2025).
Tounderstandhowindustrytriestoinfluenceindependentresearchfortheirbenefit,wecanlook
topastexamplesofentanglementofindustryandstatistics.RonaldA.Fisher,aeugenicistand“the
founderofmodernstatistics”(Rao1992),havingbeenpaidbythetobaccoindustry,claimedthatbe-
cause‘correlationisnotcausation’thattherefore‘smokingdoesnotcauselungcancer’(Fisher1958;
Stolley1991).Theparallelbetweentobaccoandtechnologydoesnotendhere:“bothindustries’in-
creasedfundingofacademiawasasareactiontoincreasinglyunfavourablepublicopinionandanin-
creasedthreatoflegislation.”(MohamedAbdallaandMoustafaAbdalla2021,p.2;alsoseeKnoester
et al. 2025) The histories of eugenics, statistics, computing, and modern AI are highly interwoven
9

O.Guestetal.
andinexorablyintertwined(e.g.IBMfacilitatedtheHolocaust;Black2012;recallsection2:
Market-
).Tracingthesegenealogies,findingoutwhatissalvageableisourjobasscientists
ing,hype,&harm
(Guest2024,2025).AndasAmyWendling(2002)explains“ifourexperienceofmachineshasbeen
outsideofourexperiencesofexploitation,thishasoccurredonlyonthemarginsofthevastnessofthis
exploitation,andisthereforeconditionedbyit.”(p.172;alsoseeBiesta2021;DrimmerandNygren
2025;Moore1997;Watters2023)
Forthesecondpointabove,onhowAIhypecyclesappeartogohotandcoldeveryfewyears,it
isalsorifewithvaluableteachingmoments.Forexample,anewsstorylikethiswouldnotbeoutof
placeinthepresent:
TheNavy revealedthe embryoof anelectronic computertoday thatit expectswillbe
abletowalk,talk,see,write,reproduceitselfandbeconsciousofitsexistence.
TheNewYorkTimes(1958,n.p.)
This early example of AI hype was about the perceptron (an early ANN; recall Table 1; Hay et al.
1960;Rosenblatt1958).FrankRosenblatt(1958),whoismostassociatedwiththis,“los[t]hundreds
ofthousandsofdollarsayearingovernmentfunds”(Lefkowitz2019)duetothesubsequentAIwin-
ter(Boden2006;Dreyfus1965;Haigh2023;Lighthilletal.1973;McCorduck2004;Olazaran1996).
These winters are triggered by over-promising and under-delivering; typical capitalist bubbles that
weareallfamiliarwith,fromthedot-combubbleattheendofthe1990stothesubprimemortgage
crisisstartingin2007.Notonlywoulditbeunprofessionaltoparticipateinsuchre-occurringfolly,
itwouldalsodamageourpedagogytoallowanothercycle.TheforeseeableAIwinterwilltakewith
itentirecurricula,academicprocessesandpractices,andeducators’andlearners’livelihoods.Instead,
wesupporthistoricalawarenessofthediscourseofinevitabilitydiscussedherein.
Thisahistoricismisnotlimitedtotheapplicationof toeducation,wehaveseenasimilarpush
AI
of other technologies such as automated teaching machines, by (amongst others) B.F. Skinner (Bi-
esta2021;DrimmerandNygren2025;Watters2023).Despitealmostacenturyoftrials,teachingand
grading by computers have not reached classrooms, and the arguments made in favour of teaching
machinesmirrortheseusedforAItoday.Forexample,Presseycontrastedhismachineswith“mass
media”(bywhichhemeantradio)stressinghissystemswere“personalized.”Therealeffectseemsto
be“thatithasbeenthemeansofturningtheattentionofmanypsychologistsfromresearchonanimal
learninginthelaboratorytoanexaminationofhumanlearningintheclassroomsituation.”(Hoko
1986)Inotherwords,ratherthancontributingtoteachingandlearning,automationintheclassroom
wasbenefitingthecreatorsoftechnology.
3.4 Anthropomorphismandothercircularreasoning
While opacity is a distinguishing feature of many other areas of science and technol-
ogy,themythssurroundingcomputingmaystemlessfromthefactthatitisanopaque
esotericsubjectandmorefromthewayinwhichitcanbeseentoblurtheboundarybe-
tweenpeopleandmachines(Turkle1984).Tobesure,mostpeopledonotunderstand
theworkingsofatelevisionsetorhowtoprogramtheirvideocassetterecordersprop-
erly,butthentheydonotusuallybelievethatthesemachinescanhaveintelligence.The
publicmythsaboutcomputingandAIarealsonodoubtduetothewaysinwhichcom-
putersareoftendepictedinthemassmedia—e.g.asanabstractsourceofwisdom,or
asamechanicalbrain.
BrianP.Bloomfield(1987,p.72)
Thereiscircularreasoningatplaywhenwesuggestandassumemachinescanthink,reason,orargue
likehumanscan,andtherefore,treatthem—andtestthem—likehumans.Withinhuman-machine
10

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
interaction research, often, AI technology output is compared to human performance, mistakenly
assumingsuchbenchmarksareinformativeaboutAI’scapabilities.However,correlationswithhu-
manoutputmeanlittletosubstantiateclaimsofhuman-likeness,especiallywhentheinputtotheAI
modelstestedistheoutputofhumancognitioninthefirstplace.Therearesomanycasesofthisfrom
dailylifeandthehistoryofsciencethatitappearsshockingsuchresultsaretakensouncriticallyto
becognition(Bernardi2024;Guest2025;GuestandMartin2023;Placani2024;vanRooijandGuest
2025).Anexamplefromthe1960s:
Weizenbaum(1966)wasafraidofthisnewrhetoricaltrendofAIbeingseenashuman
bythepublic,blamingitonbothoverhypingbyscientistsandthegullibilityoftheusers
(cf. Dillon 2020, who argues that Weizenbaum’s own rhetoric also fuelled the fire of
what came to be known as the ELIZA effect). Anthropomorphisation of AI systems,
typifiedbywhathappenedwithELIZAcausedmanyatthetimetobeexcitedaboutthe
prospectofreplacingtherapistswithsoftware.Morethanhalfacenturyhaspassedsince
thenandtheideaofanautomatedtherapistisstillpalatabletosome,likely(thankfully)
legallyandethicallyimpossiblewithouthumansupervision,andstillverymuchoutof
reachtechnically.
LeliaErscoietal.(2023,pp.22–23)
Toaddinsulttoinjury,manymetaphoricalorjargonisticphrases(especiallyusedtodescribeANNs;
seeTable1)—liketrain,learn,hallucinate,reason—areappliedtomachinesandresultindistorting
howweperceivethesemachines:humanisingthemwhiledehumanisingus(Barrow2024;DeVrioet
al.2025;Erscoietal.2023;Heffernan2024;Kambhampatietal.2025;Placani2024;Polo2024;Raether
2025;Rhee2018;Shojaeeetal.2025b;vanderGunandGuest2024;cf.K.AndrewsandMonsó2021;
Libell2014).AsGuestandMartin(2025a,p.8)explain:
Amirror—notevenanAImirror—isnotwhatitreflects(Vallor2024).Thesejumps
inlogiccanbefoundinmanyjocularstories,e.g.whenapersonfirstencountersatelevi-
sion,wouldtheyassumethedevicecontainedsmallpeople?Orwouldapersonassume
somebodywastrappedinsideatelephonebecauseitemitshumanvoices?
Althoughwe donotfullyunderstand humanthinking,thisdoes notlicenceattributing think-
ingtowhichevermachineortechnology,uncriticallyandthroughanthropomorphisation.Suchar-
guments from ignorance lack all scientific rigour. The only argument from ignorance that science
permitsiscaution,moreresearch,andcareasappropriateactionswhensomethingistrulyunknown.
Wetakeastandagainstsuchanthropomorphismandinappropriateconclusions,andquestionwhy
theparalleltomachinesistakensolightlyinsuchaharmfulcontext,riskingdeskillinganddehuman-
izationofusandourstudents.
3.5 Supposedlystudentsareallcheatingnow
NoseriousscholarorscientistintheirrightmindwouldwantLLMstoproducetheir
texts;andhence,alsonostudentpursuinganacademiceducationwouldwanttodoso.
IrisvanRooij(2022,para.7)
Students have always cheated. Bending and breaking the rules is human nature. And by the same
token, educators are not police. We are not here to obsessively surveil our students — education is
basedonmutualtrust.Therefore,ourdutyistobuildmutuallysharedvalueswithourstudentsand
colleagues.Especiallywheneducationisnotvalued,weaseducatorsareobligedtoshowourstudents
11

O.Guestetal.
thattheyarenotjustheretoreceiveadegree:educationismorethanqualification(Biesta2021).Itis
aboutpreparingstudentstobecomeacapableandactivemembersofsociety.
Weemphasizethattherearetwovictimsofplagiarism:theoriginalauthorswhoseworkistaken
withoutcreditandtheaudiencewhoisbeingdeceived.
Plagiarism, at its most fundamental level, is a lie. It is the taking of works or ideas of
othersandpassingthemoffasyourown,eitherdirectlyorindirectly.Themisdeeditself
isinthelie,the“Icreatedthis”whenitisknowntobeuntrue.
However,thatlieisn’tbeingtoldtotheoriginalvictim.It’salieaboutthevictim,claim-
ing that they didn’t create it or their contributions didn’t matter, but it’s not a lie to
them.Instead,it’salietotheaudience,whichisthesecondvictimandtheactualtarget
ofthecon.
JonathanBailey(2019b,n.p.)
Whenaghostwriteroressaymillisused,consenthasbeenobtainedbytheoriginalauthor(usually
inexchangeforpayment),butacceptabilityremainscontingentonthesocialcontractwiththeaudi-
ence.Ghostwritingisusuallyacceptablebecause“[w]eallknowthatpoliticiansdon’twritetheirown
speechesandcelebritiesrarelywritetheirownbooks”(Bailey2019b).Incontrast,
pressreleaseplagia-
(Bailey2019a)deceivestheaudiencebypresentingtheworkofabiasedsourceasbeingthatof
rism
the(perceivedtobeunbiased)journalist.Academicintegritystandards,enshrinedinuniversityrules
andscholarlyjournalpolicies,establishtheunequivocalcontractthatstudents’andresearchers’work
issolelytheirown.Thereisnodebatethatuseofanessaymillconstitutesviolationofthesepolicies.
Use of an LLM-based chatbot (recall Table 1) to complete an assignment, presented as student
work,isanaffronttothe‘firstvictim’aswellasthe‘secondvictim’.Thisautomatedplagiarismgoes
againsttheprinciplesofscientificintegrity,whichserveasthebasisofourteachingandacademicprac-
tice(vanRooij2022).LLMandchatbotuseintheclassroommeansacceptingthatbothstudentsand
teacherscanopenlyappropriateworkthatisnottheirs,andrequiresdisclosingtosociety(asecondary
audience)thatthinkingandintegrityarenotrequired.UsingAIproductstogenerateacademiccon-
tentisagainstanyconceivablesetofruleswealreadyhaveinplacetoregulatefraudandmakesurethat
studentsactually,whenfollowingtherules,learnwhattheyareexpectedtolearn.Failuretoseethis
buysintothehypeandifretrofittedontopastcasesbringsupessaymillsasapermissibleeducational
‘tool’—clearlyanti-pedagogicalandutterlybizarre.
Promoting the use of LLMs in the classroom will only increase illiteracy in young adults and
teenagersanddeepenthecrisisineducation;further,itwillboosttechnology-industrydependence
(ForbesandGuest2025;Lambeets2025;Meelissenetal.2023;U.S.DepartmentofEducation,Na-
tional Center for Education Statistics 2024). Writing — as visual and performing arts; all forms of
human expression — forms a bedrock of the learning process (Warner 2025).. And many students,
regardless of the mantra that supposedly they are all using it, can tell AI is harmful (Abrams 2025;
Drapkin 2023; Eichenberger et al. 2025; Huntington 2025; Isayas 2025b; Kaplan 2024; Klee 2025;
Landymore2025;Montgomery2024;Neville2025;Pejcha2023;Purtill2025;Roose2024;Schoene
andCanca2025;Tafani2024b;J.Taylor2025;Tiku2025;Wei2025;Xiang2023)anduseless(Bearne
2025; Bond 2025; Doetie Talsma 2025; Otis et al. 2025; Pahwa 2025; Soler 2025). In one survey by
Study.com(2025),forinstance,“72%ofcollegestudentsbelievedthatChatGPTshouldbebanned
fromtheircollege’snetwork”(alsoseeAkolekaretal.2025;Morris2025;TechEquity2025).
Despiteallthecurrenthysteriaaroundstudentscheating,theyaren’ttheonestoblame.
Theydidnotlobbyfortheintroductionoflaptopswhentheywereinelementaryschool,
and it’s not their fault that they had to go to school on Zoom during the pandemic.
12

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
Theydidn’tcreatetheA.I.tools,norweretheyattheforefrontofhypingtechnological
innovation.[...]
NoneofthestudentsIspokewithseemedlazyorpassive.
HuaHsu(2025,n.p.)
Thequoteabovetoucheson,andneutralises,oneofthemanymarketingstrategiestointroducesuch
so-calledtechnologiesintheclassroom(e.g.Chow2025).Technologycompaniesarenotshyoffalsely
claimingthatstudentsarelazyorlackwritingskills.Suchamantraservesonlytosellproducts—or
coverupandexcuseoverworkingthembyourcolleagues—withnoreflectiononreality.Wecondemn
thoseclaimsandreassertstudents’agencyvis-à-viscorporatecontrol.
3.6 DowehavetoteachAIbecauseotherwiseourstudentswillnotgetjobs?
Headlineafterheadlineproclaimed“TheRobotsAreComingforOurJobs,”instories
abouthyper-intelligentAIandlogisticsautomation.Willallthesetrendseventuallylead
toaworldwherethebotsandalgorithmsdoourdirtywork,makingourliveseasierand
more prosperous? Or will the machines push us out of our jobs and deposit us into a
dystopia?Wearechewingoverthemachineryquestionalloveragain,inbarelyupdated
language.
BrianMerchant(2023)
Of course, we have to teach our students AI technologies. Teaching about AI technologies
about
shouldbejustlikehowweteach‘nosmoking’orthecausallinksbetweenlungcancerandcigarette
smoke;yet,wedonotteachstudentshowtorollcigarettesandsmokethem.Infact,thewholeselling
pointofthetechnologyindustryisthatmodernAItechnologiesareliketalkingtoanotherperson,
oftenaservant.Thus,whattrainingistheretoreallyhaveundersuchaframe?Whatistheretoteach
withrespecttotypingsometextintoaboxandthenmindlesslycopy-pastingtheoutput?Suchaskil-
lessrelationshipdisregardsourpedagogicalcommitmenttofosteracriticalstanceinourstudentsand
colleagues(cf.PrevitaliandFagiani2015).Somecounteractthatstudentscanandmust“useAIcriti-
cally/responsibly”,e.g.byjudgingtheoutputforthemselves(cf.Barr2025).Goingonestepfurther,
someevenmaintainthatsuchexercisesareusefultotraincriticalthinkingitself,therebybuyinginto
theusefulnessofAIdespiteadmittingtoitsuntrustworthiness,glossingoverthemanyproblemswe
describehere.
Inthinkingaboutimplicationsforthedesignoflearningenvironmentsandcurriculumdesign,we
firstneedtopauseandthinkaboutwhatwereallywouldlikeAItoolstodo,or,putdifferently,what
mightbetheaddedvalueoftheuseofAItoolsineducation—ifany?Inthinkingaboutthefutureof
education,weoughttobeengagingwithculturallyrelevantandsustainablepedagogiesthathavethe
potentialtoembracethediversityoflearners’identities,culturalcapital,andmigrationbackgrounds
throughculturallyandpersonallymeaningfullearningexperiences(Bamberetal.2017;Barabetal.
1999;MacPartlandetal.1971).Hence,takingteachersorstudentsoutofasocialcontextandinreturn
givingthemAIproducts,wouldbedisastrousforeducationandforsocietymoregenerally.
Relatedly,the(extreme)obfuscationoflabourappearstobeadefiningfactorofAItechnology
(Altenried2022;Aroraetal.2023;L.M.Brown2023;ColónVargas2025;GrayandSuri2019;Guest
2025; O’Neil 2016; Perrigo 2023; Pfaffenberger 1988; Ricaurte 2019). AI stands in contrast to a tool
likeasawinvolvedinthepredominantlyovertlabourofwoodworking(thatis,tocutwood),where
thepersoncuttingalsoputsinlabourwithactualcontrolovertheoutputofthelabour;oftenmore
than the creator of the saw. AI users, on the other hand, are customers much more like the person
buyingtheendproductofwoodworkthancarpentersthemselves.Ifnotinsomesensemoreso,as
13

O.Guestetal.
theyremainunawareof,andareeventrickedintothinkingtheyperformedtherelevantlabour.This
distortioncanbeseeninoftenusedobfuscatoryphraseslike‘promptengineer’,whichimplylabour
andskill(Guest2025;Watters2023).Beingacustomernotonlyrequiresnotraining,isnotaskill,but
alsoisacompletelydifferentlabourrelationmasqueradingasskill.Thus,seeingstudentsmerelyas
customersofAIproductsdeskillsnotonlythem,butalsousasteachers(asthereisnothingtoteach),
andultimatelysocietyatlarge(asnoonewillbelefttobeabletowriteandthink).Thisisreflectedin
theadvertisingdeployedbyAIcompanieswhoclaimpromptsareakinto‘talkingtoacomputer’and
requirenoskillslikeprogrammingtodoso.
Whatfutureandwhatjobswilltherebeifmosthumancapacitiesreallywillbedoneawaywith?
Crucial professions necessary to maintaining a well-functioning society, democracy, healthcare and
justicesystems,woulddeteriorateanddegenerate.Thenecessarycreative,empathic,andintellectual
skillsneededtoensuretheseprofessionscanservetheirsocietalpurposes,andupholdrelevantstan-
dards,wouldbelost(Budzyńetal.2025).Ironically,inaworldfullofAIdisplacements(Guest2025)
andAImisinformation,actually skillwouldbeneededtocatch,counter,andcompensatefor
more
theproblemsandmistakesintroducedbyAItechnologies(Bainbridge1983),butasAItechnologies
increasinglyinfiltrateacademia,studentswillberobbedoftheopportunitytolearnthosenecessary
skills.Wetakeastandagainstsuchdevelopmentsinwhichstudentscannotlearn—bydefinition—
andrejecttheframesthatAIuseisnecessarytoobtainajob.
3.7 AIismorelikeacalculatorthanyouthink
“ButIjustuseAIforboilerplate!”youwhimper,clutchingyourCo-Pilotsubscription.
Listentoyourself.Ifyou’rewritingthesameboilerplateeverydaylikesomeindustrial-
age cog monkey, automate it yourself. Write a library. Invent a macro. Reclaim some
dignity.IfAI’sdoingyour“boringparts”,whatexactlyisleftforyoutodo?[...]
Whenyououtsourcethethinking,yououtsourcethelearning.
Jj(2025,n.p.)
ThereareabsolutelyimportantdifferencesbetweenanLLMandacalculator,notablythesecondis
notstochasticoutside,forexample,thebatteryrunningoutoracosmicrayflippingabit.Contrary
toanLLM,undernormalconditions,acalculatorperformspre-specifiedfunctionsreliably(forrel-
evantanalyses,seeGuest2025).But—andhereinliestherub—webancalculatorswhenteaching
children addition and other basic arithmetic operations for a reason (cf. Lodge et al. 2023). Other-
wise,theywouldnotlearnthesearithmeticoperations,andcalculatorsdonothelptounderstandthe
basicmathematicalrules.Forthesamereasons,wealsodonotallowtheuseofspellchecksoftware
forchildrenlearningtospell,orkeyboardtypingwhenlearningtowritebyhand(Iharaetal.2021;
Lambert2024;Longcampetal.2005;MuellerandOppenheimer2014;Rascoe2024).Thesamerea-
soningappliestobanningAIproductsineducation(cf.Bond2025;ForbesandGuest2025;Guest
2025;Weatherbed2025):
LLMsdonotimproveone’swritingabilitymuchliketakingataxidoesnotimproveone’sdriving
ability.Studentsshouldhonetheirwriting,thinking,andotheracademicskillsateveryopportunity.
Asteachers,weareduty-boundtohelpthemrealisewhytheyshould.Importantly,writingcreatesa
spaceforstudentstoassimilateandcreateknowledgeindependentlyofindustryinfluence,andgives
students a way to empower their voices. Given the technology industry’s concentration of power,
infrastructure,andcontrol,wemustpromotewritingatuniversityalongwithteachingcriticalAIlit-
eracy.Whatholdsforwritingis,ofcourse,trueforanycognitiveskillto-be-learnedineducation,such
asprogrammingskills(Beckeretal.2025;cf.GuestandForbes2024)andthesetoosufferdeskillingif
notcontinuouslypractised:
14

AgainsttheUncriticalAdoptionof‘AI’TechnologiesinAcademia
IstaredatmyterminalfacingthoserederrormessagesthatIhatetosee.AnAWS[Ama-
zon Web Services] error glared back at me. I didn’t want to figure it out without AI’s
help.
After 12 years of coding, I’d somehow become worse at my own craft. And this isn’t
hyperbole—thisisthenewrealityforsoftwaredevelopers.
NamanyayGoel(2025,n.p.)
Toshowhowseriousthesituationhasbecome,oneneedonlythinkaboutourlastroundofmark-
ingessaysbyAIundergraduatestudents.Whatjumpsoutofthepage,forus,issomethingthatcon-
tradictstherhetoricourcolleaguespromote,namely,itisevidentthatstudentsneed essaywork
more
assigned to them, not less (Kosmyna et al. 2025). Almost every essay was poor on some dimension
that does not befit students in their final years of undergraduate study: the writing is often super-
ficial,thelanguagedoesnotreflectstudents’stageandknowledge,citationsarefrequentlymisused,
and(mostshockinglybecauseitissoeasy),thereferencestyleisnotappliedcorrectly.Thismeansthat
theconstellationofskillsrequiredtowriteagoodacademicessayhasnotbeennurturedenoughor
hasatrophied.WhatthismeansisalsothatregardlessoffactualLLMusebythestudents,
theirability
,andnot,asmanyseemtoclaim,atceilingwhereonecannotdifferentiate
towriteessaysisonthefloor
agoodessayfromaplagiarisedorotherwisedishonestattemptofanessay.Importantly,thetraining
ofwritingskillsshouldbedoneinthecontextofcriticalreckoningwiththenormsandpressuressur-
roundingtheworkexpectedofstudents(i.e.highstudyload,so-calledstudentexcellence,financial
pressuretograduate,etc.).
Inthiscontext,itisalsoimportanttobewaryofargumentsthatwronglypositionLLMsas,mak-
ing education more democratic, accessible, and equitable by removing language barriers, removing
unequalaccesstomentorship,andincreasediversity,equityandinclusioningeneral.LLMsarenei-
therarealnorjustsolutiontotheseissuesgiventhemyriadproblemsandfalsehoodsweraisehere,
giventhefactthattheharmsassociatedwithLLMsfeeddirectlyintotherootsoftheseinequal-
and
itiestobeginwith(Sano-Franchinietal.2023).Whena(perceived)lackofwritingskillsispenalized
alongracist,ableist,orotherwisediscriminatorylines(FloresandRosa2015),studentsmaybedriven
toLLMsbecausetheyallegedlyproduce‘professional’text.Weneedtocommittocreatinganenvi-
ronmentinwhichsuchrhetoricandinjusticearetackledattheirroots.
4 ProtectingtheEcosystemofHumanKnowledge:FivePrinciples
Wemustprotectandcultivatetheecosystemofhumanknowledge.AImodelscanmimic
theappearanceofscholarlywork,buttheyare(byconstruction)unconcernedwithtruth
—theresultisatorrentialoutpouringofuncheckedbutconvincing-sounding“infor-
mation”. At best, such output is accidentally true, but generally citationless, divorced
fromhumanreasoningandthewebofscholarshipthatitstealsfrom.Atworst,itiscon-
fidentlywrong.Bothoutcomesaredangeroustotheecosystem.
OliviaGuest,IrisvanRooij,etal.(2025,n.p.)
Knowledgeproductionissupposedtobesafeguardedby(inter)nationalcodesofconductforresearch
integrity(Allea2023;KNAWetal.2018).Suchcodesforbid,forinstance,fabricationofdata,falsifica-
tionofresults,plagiarism,and,generally,distortionofthescientificrecord.Manyarguethatnewrules
arerequiredtoregulateacademicAIuse,butpre-existingguidelinesfitthebill(cf.Tafani2024a).For
instance,theNetherlandsCodeofConductforResearchIntegrity(KNAWetal.2018)isbasedon5
coreprinciples—eachofwhichspeakstoAIusageinoneormoreways(cf.Dingemanse2024):
15

O.Guestetal.
impliesthatwedonotsecretlyuseAItechnologieswithoutdisclosure,andthatonedoes
Honesty
notmakeunfoundedclaimsaboutthepresumedcapabilitiesofAItechnologies(thisalsofollows
from ;seeexamplefromMITEconomics2025,whereperhapstoolittletoolatewas
Responsibility
done).
demands,amongothert

## 引用

```

```
