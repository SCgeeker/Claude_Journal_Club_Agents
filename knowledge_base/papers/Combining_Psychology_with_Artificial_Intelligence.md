---
title: Combining Psychology with Artificial Intelligence:
authors: Combining Psychology, Artificial Intelligence
year: N/A
keywords: theoreticalpsychology, artificialintelligence, cognitivescience, computationalism
created: 2025-11-19 22:38:33
---

# Combining Psychology with Artificial Intelligence:

## 基本信息

- **作者**: Combining Psychology, Artificial Intelligence
- **年份**: N/A
- **關鍵詞**: theoreticalpsychology, artificialintelligence, cognitivescience, computationalism

## 摘要

None

## 研究背景

## 研究方法

## 主要結果

## 討論與結論

## 個人評論

## 相關文獻

## 完整內容

Combining Psychology with Artificial Intelligence:
What could possibly go wrong?
IrisvanRooij1,2,3 andOliviaGuest1,2
1DepartmentofCognitiveScienceandArtificialIntelligence,RadboudUniversity,TheNetherlands
2DondersInstituteforBrain,Cognition,andBehaviour,RadboudUniversity,TheNetherlands
3DepartmentofLinguistics,CognitiveScience,andSemiotics&InteractingMindsCentre,AarhusUniversity,Denmark
ThecurrentAIhypecyclecombinedwithPsychology’svariouscrisesmakeforaperfectstorm.
Psychology,ontheonehand,hasahistoryofweaktheoreticalfoundations,aneglectforcom-
putationalandformalskills,andahyperempiricistprivilegingofexperimentaltasksandtesting
for effects. Artificial Intelligence, on the other hand, has a history of conflating artifacts for
theoriesofcognition,orevenmindsthemselves,anditsengineeringoffspringlikestomove
fast and break things.Many of our contemporaries now wantto combine the worst of these
twoworlds.Whatcouldpossiblygowrong?Quitealot.DoesthismeanthatPsychologyand
ArtificialIntelligencecanbestpartways?Notatall.Thereareveryfruitfulwaysinwhichthe
twodisciplinescaninteractandtheoreticallyinformtheinterdisciplinarystudyofcognition.
Buttoreapthefruitsoneneedstounderstandhowtosteerclearofpotentialtraps.
Keywords:theoreticalpsychology,artificialintelligence,cognitivescience,computationalism,
epistemology
Psychology has been living through various crises that manparticipantswith‘artificialminds’thatareamenableto
have left the field grappling with its scientific status. Crises standardpsychologicalexperimentalmethods.Itseems,thus,
can lead to positive change, for instance, when they stimu- thatPsychologycanjustkeepdoingwhatithasbeendoing—
late a reflective re-imagining of theoretical foundations and e.g., effects hunting (Cummins, 2000; van Rooij & Baggio,
epistemological practices. However, crises can also leave a 2021)—andnodeepre-imaginingofourdiscipline’sfounda-
fieldvulnerabletofalseprophetsthatpromiseillusoryquick- tionsandepistemologymayappeartobeneeded.However,
fixes. Right when Psychology is vulnerable, society is go- theseappearancesandpromisesareallfalse.Inthisbriefre-
ing through an AI hype cycle. This AI hype cycle’s impact view we explain how and why. We end with guidance on
seemsevenworsethantheonesthatcamebefore.Withadev- how a fruitful interface between Psychology and Artificial
astating ecological footprint and the exploitation of hidden Intelligenceispossiblethatdoesnotfallinthesetraps.
labour,hyped-AIservestoamplifydiscriminationandother
social, economic and environmental injustices. Psychologi- 1 Trapstoavoid
calscientistspredominantlyprefertoignoresuchreal-world
harmsandinsteadask:‘HowcanAIbenefitus?’1Thisisun- 1.1 AIsystemsarenotminds
derstandable.2 After all, hyped-AI promises to deliver can-
If one reads the news and advertisements from the tech-
didate theories and statistical inferences through automated
nology industry (sometimes disguised as scientific papers),
processes, also known as machine learning. This is music
one could be led to believe that we are on the verge of
to the ears of Psychology, which wants good theories and
creating genuine artificial minds. For decades the domain-
good statistical practices, but whose scientific practitioners
generalityofcognitionwasrecognizedasmakingcognition
predominantly lack theoretical, computational, and statisti-
hard—andperhapsimpossible—toexplain,model,orrepli-
cal skills. Hyped-AI even promises that it can replace hu-
catecomputationally(Fodor,2000;Pylyshyn,1987;Ryle&
Tanney, 2009; van Rooij et al., 2019). But these days many
people have come to believe that by training on massive
Iris van Rooij Correspondence concerning this article
should be addressed to Iris van Rooij, Donders Centre for Cog- 1For notable exceptions, see Guest (2024), Birhane and Guest
nition, Faculty of Social Science, Radboud University, Thomas (2021),andPratheretal.(2022).
vanAquinostraat4,6525GDNijmegen,TheNetherlands.E-mail: 2We do not mean to say it is ethical, but merely that we un-
i.vanrooij@donders.ru.nl derstandthepsychologicalandsocio-scientificfactorsbehindthis
desire.

2 VANROOIJANDGUEST
Table1
Typology of traps, how they can be avoided, and what goes wrong if not avoided. Note that all traps in a sense constitute
category errors (Ryle & Tanney, 2009) and the success-to-truth inference (Guest & Martin, 2023) is an important driver in
most,ifnotall,ofthetraps.
trapstoavoid howtoavoid problemsifnotavoided
AIsystemsarenotminds realiseAIsystemsaredecoys dehumanisation,shoddy
science
AIsystemsarenottheories realiseAIsystemsaredecoys, theoreticaldeterioration,
predictionisnotexplanation, pseudo-explanation,fallacious
correlationdoesnotimply metatheoreticalcalculi,
cognition,tasksarenot overclaiming,obfuscationof
capacities,andAIsystems human-in-the-loop
cannotscale
CogScicannotbeautomated thinkdeeply,slowscience,take theoreticalcul-de-sacs,
computationalismseriously,be pseudoscience,deskilling,
non-makeist proliferationofdecoys,creation
oftheothertraps
amounts of human data it is possible to create AI systems 2019). There is no benefit in making it worse by replacing
that can think and act in a domain-general way, just like thepeoplewhomwewishtostudywithdecoys.
humans. The intuition seems to be that as long as one has
enough human data to train one’s AI systems, those sys- 1.2 AIsystemsarenottheories
temswillasymptotetohuman-level/-likebehavior.Suchen-
visionedhuman-levelAIisalsoknownasArtificialGeneral So AI systems cannot be minds. But can these engi-
Intelligence(abbreviatedAGI). neeredsystemsbetheoriesofhowcognitionworks?Itseems
Recently van Rooij,Guest, et al. (2024) haveshown that prima facie that training neural networks—or other cogni-
training AI systems to scale up to human-level cognition is tively inspired3 computational architectures—on cognitive
intractable. This has two implications. First, creating AGI
tasksand/orhumandataproducesviablecomputationalthe-
throughmachinelearninginherentlyconsumesastronomical oriesofhowcognitionworks.Afterall,ifsuchanAIsystem
amountsofresources—soonerwillthesundieoutthanthat
canmimichumanbehaviorandpredict4humanperformance
we will create AGI, and in the mean time we will just be oncognitivetasks,thenhumancognitionmustworkmoreor
pollutingourplanet andexploitingun(der)paidlabour.Sec- less analogously to how the AI system works, right? Many
ond,anyAIsystemsthatcanbecreatedintheshort-termare peopleseemtobelievethatthisimplicationholds.However,
butdecoys—thesesystemscantrickusintothinkingtheyare nomatterhowintuitivelyappealing,thebeliefisfundamen-
likehumanminds,buttheyareanythingbut(Guest&Martin, tallymistaken,forseveralreasons.
2023).Eventhoughthesedecoyscanappearimpressiveand Prediction is not explanation. Being able to predict hu-
trick us, they are not hard to unmask through careful tests manbehaviordoesnotimplybeingabletoexplainthewhyor
(Dentellaetal.,2024)orevencommonsenseprobes.
Itisthusworrisomethatsomeresearchersseemtobelieve 3Formodernconnectionism,appealsto‘neuralplausibility’or
that AI systems can replace human participants in experi- describing systems as ‘cognitively inspired’ are often made with-
out much basis (Guest & Martin, 2024), so not too much weight
mentalresearch(e.g.Dillionetal.,2023).ConfusingAIsys-
shouldbegiventothem.Wemerelymentionthemtoacknowledge
tems for human minds is not only a category error (Ryle &
thatthesearecommonintuitiveappealsmadebyproponentsofAI
Tanney, 2009) and dehumanising (Bender, 2024; Erscoi et
systemsastheoriesofcognition.
al., 2023), it is also a recipe for shoddy science (Guest &
4As per the Ingenia Theorem (van Rooij, Guest, et al., 2024)
Martin, 2023). After all, AI systems are decoys that cannot
we know AI systems fundamentally cannot predict human-level
possibly approximate human cognition and behavior in any performanceoncognitivetasksinadomain-generalsense,evenif
reliable way (van Rooij, Guest, et al., 2024). The method- such systems may predict or mimic human performance on well-
ological crisis in psychology has been bad enough (Flis, circumscribedtasks.

VANROOIJANDGUEST 3
howofthatbehavior.Thatpredictionandexplanationaredis- studiedinthepsychologicallabsorsuchasformthebasesof
sociable is easily illustrated by considering the tides (Cum- trainingAIsystemsthroughmachinelearning)thesemodels
mins, 2000; see also Blokpoel and van Rooij, 2021–2025, should minimally be computationally tractable (van Rooij,
Chapter2):Wecouldpredictthetideslongbeforewecould 2008). At present, no computationally tractable account ex-
explain them (i.e., in terms of the gravitational pull of the istsforsubstantiveanddomain-generalcognitivecapacities,
moon).Eventoday,weusetidetables,i.e.,largelookupta- such as reasoning, communication, decision-making, plan-
bles that map dates and times of day to positive or negative ning,analogizing,categorisationandconceptformation(van
levels of the tide. Using such tide tables for different loca- Rooij et al., 2019) nor will any such tractable accounts be
tionsonearthonecanquitepreciselypredictthetidesatany forthcoming via machine learning (van Rooij, Guest, et al.,
timeoftheday.Yet,no-onewouldclaimthattidetablesex- 2024) or otherwise (Rich et al., 2021). Hence, if someone
plain the tides. Similarly, a huge look-up table (or a com- claims their AI system is a ‘theory’ of cognition, they are
pressed version that interpolates/guesstimates for some un- overstatingthescopeandcapacitiesofthesystem(vanRooij
known/unseeninput-entries,likearegressionmodel,aneural et al., 2019) and obfuscating the system’s limits, including
network,oralargelanguagemodel)thatmoreorlesspredicts thehuman-in-the-loopneededtomakesuchsystems‘work’
whatbehaviorspeoplewilldisplayindifferentsituationsand (Guest&Martin,2025).
conditions does not provide an explanation for why the be-
havior is as it is, nor of how cognition works (van Rooij, 1.3 Cognitivesciencecannotbeautomated
2022).
Psychology has undergone some important cultural
Correlation does not imply cognition (Guest & Martin,
changesduetotheso-calledreplicationcrisis.6Insteadofim-
2023,p.224).Somemayobjectthateventhoughprediction
provingPsychology’stheoreticalfoundationsandepistemo-
ofoutwardbehaviorisinsufficientforamodeltobeexplana-
logicalpracticesbyadoptingconceptual,computational,and
tory,surelywheninternalparametersofthemodelcorrelate
formaltoolsfromComputationalCognitiveScience(Guest,
withbraindatathatshowsthemodelmatchesthemechanis-
2024;Guest&Martin,2021;Navarro,2019,2021;vanRooij
ticworkingsofbrains/minds.Unfortunately,thisinferenceis
&Baggio,2020,2021;vanRooij,Devezer,etal.,2024),the
mistaken, too. As shown by Guest and Martin (2023), it is
overwhelmingresponseinthemainstreamhasbeentopush
invalidtoinferfromcorrelationsbetweenamodelandbrain
forstatisticalmethodologicalreformthatcentersarigidpro-
data that the model works like the brain. This follows from
ceduralisationofempiricalresearch(seealsoDevezeretal.,
multiple realisability5: Just like both a digital clock and an
2021;Szollosietal.,2020,forcritiques).Thismovehasfur-
analogclockcantellthetime,andonewillbeabletocorre-
thercementedhyperempiricism7 intoPsychologyandithas
latepartsfromonewiththeother,theyoperateinfundamen-
leftthefieldvulnerabletoaviewthatsciencecanbeproce-
tallydifferentways(Fig.2inGuest&Martin,2023).
duralisedandmaybe,toalargeextent,evenautomated.
Capacities are not tasks. Even if multiple realisability
RightatthetimethatPsychologyisvulnerable,hyped-AI
cannot be ruled out, it may seem that AI systems that can
enters the scene and makes false and misleading promises
(be made to) perform like humans on cognitive tasks pro-
that both theory-generation and scientific inference can be
videatleastpossibletheoriesofhowcognitioncould work.
automated using machine learning. For Psychology such
However,thisinferenceisnotlicensedeither.Computational
promises are very attractive, especially since its practition-
models of tasks, and task performance, are not yet theories
ers often lack theory building and advanced statistics skills.
of cognition (Guest & Martin, 2021; Morrison & Morgan,
However, a common expression applies here: ‘if something
1999).Theoriesofcognition,minimally,shouldprovidepos-
seems too good to be true, then it probably is’. Cognitive
sibleexplanationsofoneormoresubstantivehumancapaci-
science cannot be automated, because theory generation is
ties,suchasvision,decision-making,reasoning,orcommu-
nication(Cummins,2000;Egan,2018;vanRooij&Baggio, 5Theprincipleofmultiplerealisabilityisfoundationaltocom-
2021). While it is true that in (hyperempiricist) Psychology putationalism(i.e.,theideathatcognitionis,orcanbeunderstood
these capacities are typically studied by having people per- as,aformofcomputation).Itisironicthatespeciallythosewhobe-
formvarioustasks,computationally(ormoreoften,statisti- lieveAIsystemscanbemindsortheoriesofhowcognitionworks
cally)modelingtaskperformancedoesnotyieldexplanatory ignore the fundamental principle of multiple realisability in their
theories of capacities. This is so, not only because tasks do metatheoreticalcalculus(seealsoGuest&Martin,2025;Guestet
al.,2025).
not map one-to-one, or in any other straightforward way, to
6See,forinstance,Noseketal.,2022.ButseealsoDevezeret
substantive cognitive capacities, but even if they could, the
al.,2021;Irvine,2021;Szollosietal.,2020forcritiquesofhowthis
models would not be able to scale up to situations of real
crisishasbeenconceivedandaddressedbythemainstream.
worldcomplexity.
7Here,byhyperempiricismwemeantheideathatonlyempirical
AIsystemscannotscale.Inorderforcomputationalmod- observationcanbeusefultounderstandingcognition,andthatany
elsofcognitiontobeabletoscalefromtoyscenarios(suchas othersourceofevidenceiseitheroflesserimportorirrelevant.

4 VANROOIJANDGUEST
provably intractable (Rich et al., 2021; van Rooij, Guest, et Philosophy
al., 2024) and scientific inference cannot be reduced to sta-
tisticalinference(Guest&Martin,2023;Navarro,2019).
Hyped-AIpromisesarenotharmless(Guest,2024).While Psychology Linguistics
automation may give the false impression of rigor and effi-
ciency, it leads to conceptual and scientific deskilling, dete-
riorates reflexive theorizing, and can make us blind for im-
portant scientific paths we’d need to go down (Rich et al.,
2021). Also, since building theories of substantive (human-
Artificial
level)cognitivecapacitiesiscomputationallyintractable,any Anthropology
efficientproceduralizedwayofgeneratingtheoriescanonly Intelligence
producedecoys,leadingtotheothertraps(vanRooij,Guest,
et al., 2024). Last but not least, automated scientific infer-
Neuroscience
encescancausedeepscientificinconsistenciesandtheoreti-
Figure1
calconfusions(Guest&Martin,2023;Guestetal.,2025)and
can give false credibility to harmful pseudoscientific ideas
AvisualdepictionoftheconnectionsbetweentheCognitive
and practices (Birhane & Guest, 2021; Spanton & Guest,
Sciences. Solid lines denote stronger interdisciplinary ties;
2022)
anddashedlinesdenoteweakerones.Thisfigureisderived
fromtheoriginalputforthbytheSloanFoundationin1978
2 Apossiblepathforward and reproduced from Figure 4 in Pléh and Gurova (2013).
Different versions of it over time have used ‘Artificial intel-
Inthisbriefreviewwefocusedonwhatallcangowrong
ligence’ (as above) instead of ‘Computer Science’ and vice
when combining Psychology with Artificial Intelligence in
versa(cf.Miller,2003).
thoughtlessways.Werealizethereadermayappreciateguid-
ance for traveling the winding, branching, and open-ended
roadthatiscognitivesciencewithoutfallingintosaidtraps.
Step 1 in avoiding the traps is to be aware of them and to computational constraints as well. Lacking any efficient re-
beabletorecognizethem‘inthewild’(e.g,intheliterature liable procedure for generating explanatory theories, all we
or in scientific practices). To assist with this we provide in candoispostulate(oftenblatantlywrong)theoriesandrig-
Table1anoverviewofthenatureofeachofthetraps,what orouslyanalyzetheirexplanatoryscopeandlimits.Byusing
canbedonetoavoidthem,andtheproblemsthatarisewhen whatever insights we may draw from such analyses we ad-
one doesn’t. Step 2 is to develop a research approach that vanceourscientificunderstanding(ofourlackofunderstand-
removestherootcausesofthetrapsandpreventsthemfrom ing)onesmallstepatatime.Goodscienceisslow(Stengers,
arisinginthefirstplace.We(andothers)haveproposedthat 2018)andifcognitivesciencewantstotakeAIastheoretical
such a cognitive science is possible even within a compu- psychologybackonboard,thenitneedstotakecomputation-
tationalist framework, if we reconceptualise Artificial Intel- alismseriously.
ligence (or Computer Science more broadly) as “a provider
of computational tools (frameworks, concepts, formalisms, 3 Conclusion
models, proofs, simulations, etc.) that support theory build-
ing in cognitive science” (van Rooij, Guest, et al., 2024, p. Psychology and Artificial Intelligence (or, more broadly,
616),butwithoutconfusingthetheoreticalpossibilityofex- ComputerScience)are twoofthesixtraditionaldisciplines
plaining human cognition computationally with the practi- constituting the interdisciplinary study of cognition, called
calfeasibilityof(re)makinghumancognitioninfactualcom- CognitiveScience(theotherfourbeingPhilosophy,Linguis-
putationalsystems(a.k.a.makeism,seeBox2invanRooij, tics,Neuroscience,andAnthropology;seeFig.1).Overthe
Guest,etal.,2024).Wecoinedthisalternativecomputation- last three decades Psychology came to dominate Cognitive
alistapproachnon-makeism. Science with its hyperempiricist tendencies (Gentner, 2010,
Non-makeist AI takes computationalism more seriously 2019), while Artificial Intelligence retracted from the field
than makeist AI (Guest et al., 2025), as it bites all the bul- (Forbus, 2010) taking most computational theory building
letsimpliedbycomputationalistaxioms,suchasmultiplere- tools with it. Currently, we are witnessing a rapprochement
alisability of computation and fundamental limits imposed of the two disciplines. While theoretical strengthening of
by computational intractability. “Cognitive science is itself CognitiveScienceiswelcome,greatcautionisneededtopre-
a cognitive activity" (Rich et al., 2021, p. 3034). It, thus, ventanewstatusquothatisworsethantheoldone.Compu-
followsfromcomputationalismthatcognitivescientists’ex- tationalconceptsremainvaluableforcarefullycraftingtheo-
planations,inferences,andtheorybuildingarealllimitedby riesinCognitiveScience(Guest&Martin,2021;vanRooij

VANROOIJANDGUEST 5
&Baggio,2021),buttheycanonlyflourishifwea)donot Egan, F. (2018). Function-theoretic explanation and the
confuseAIsystemsformindsortheories,b)donotconfuse searchforneuralmechanisms.InExplanationandintegra-
machinelearningforthescientificmethod,andc)understand tioninmindandbrainscience(pp.145–163).OxfordUni-
thatourcomputationalmodelscanonlytrackthescopeand versityPress.
limitsofourunderstanding. Erscoi, L., Kleinherenbrink, A., & Guest, O. (2023). Pyg-
malion displacement: When humanising AI dehumanises
4 Recommendedreadings women.SocArXiv.https://doi.org/10.31235/osf.io/jqxb6
Flis, I. (2019). Psychologists psychologizing scientific psy-
Guest, O. (2024). What makes a good theory, and how do
chology:Anepistemologicalreadingofthereplicationcri-
wemakeatheorygood?ComputationalBrain&Behavior,
sis.Theory&Psychology,29(2),158–181.
7(4),508–522.
Fodor,J.(2000).Theminddoesn’tworkthatway:Thescope
Guest,O.,&Martin,A.E.(2021).Howcomputationalmod-
andlimitsofcomputationalpsychology.MITpress.
eling can force theory building in psychological science.
Forbus,K.D.(2010).AIandcognitivescience:Thepastand
PerspectivesonPsychologicalScience,16(4),789–802.
next30years.TopicsinCognitiveScience,2(3),345–356.
Guest,O.,&Martin,A.E.(2023).Onlogicalinferenceover
Gentner,D.(2010).Psychologyincognitivescience:1978–
brains,behaviour,andartificialneuralnetworks.Computa-
2038.TopicsinCognitiveScience,2(3),328–344.
tionalBrain&Behavior,6(2),213–227.
Gentner,D.(2019).Cognitivescienceisandshouldbeplu-
Guest, O., Scharfenberg, N., & van Rooij, I. (2025). Mod-
ralistic.TopicsinCognitiveScience,11(4),884–891.
ern alchemy: Neurocognitive reverse engineering. PhilSci.
Guest, O. (2024). What makes a good theory, and how do
https://philsci-archive.pitt.edu/id/eprint/25289
wemakeatheorygood?ComputationalBrain&Behavior,
van Rooij, I., & Baggio, G. (2021). Theory before the test:
7(4),508–522.
How to build high-verisimilitude explanatory theories in
Guest, O., & Martin, A. (2025). Are neurocognitive repre-
psychological science. Perspectives on Psychological Sci-
sentations ‘small cakes’? https://philsci-archive.pitt.edu/
ence,16(4),682–697.
24834/
vanRooij,I.,Guest,O.,Adolfi,F.,deHaan,R.,Kolokolova,
Guest,O.,&Martin,A.E.(2021).Howcomputationalmod-
A., & Rich, P. (2024). Reclaiming AI as a theoretical tool
eling can force theory building in psychological science.
forcognitivescience.ComputationalBrain&Behavior,7,
PerspectivesonPsychologicalScience,16(4),789–802.
616–636.
Guest,O.,&Martin,A.E.(2023).Onlogicalinferenceover
brains,behaviour,andartificialneuralnetworks.Computa-
References
tionalBrain&Behavior,6(2),213–227.
Bender,E.M.(2024).Resistingdehumanizationintheageof Guest, O., & Martin, A. E. (2024). A metatheory of classi-
“AI”. Current Directions in Psychological Science, 33(2), cal and modern connectionism. PsyArXiv. https://osf.io/
114–120. preprints/psyarxiv/eaf2z_v1
Birhane,A.,&Guest,O.(2021).Towardsdecolonisingcom- Guest, O., Scharfenberg, N., & van Rooij, I. (2025). Mod-
putationalsciences.Kvinder,Køn&Forskning,29(2),60–
ern alchemy: Neurocognitive reverse engineering. PhilSci.
73. https://philsci-archive.pitt.edu/id/eprint/25289
Blokpoel, M., & van Rooij, I. (2021–2025). Theoretical Irvine, E. (2021). The role of replication studies in the-
modeling for cognitive science and psychology. https:// orybuilding.PerspectivesonPsychologicalScience,16(4),
computationalcognitivescience.github.io/lovelace/
844–853.
Cummins,R.(2000).“Howdoesitwork?”versus“whatare Miller, G. A. (2003). The cognitive revolution: A historical
thelaws?”:Twoconceptionsofpsychologicalexplanation. perspective.Trendsincognitivesciences,7(3),141–144.
InExplanationandcognition(pp.117–144).MITPress. Morrison, M., & Morgan, M. (1999). Models as mediators.
Dentella,V.,Günther,F.,Murphy,E.,Marcus,G.,&Leivada, Perspectives on Natural and Social Science. Cambridge
E. (2024). Testing AI on language comprehension tasks UniversityPress.
reveals insensitivity to underlying meaning. Scientific Re- Navarro, D. J. (2019). Between the devil and the deep blue
ports,14(1),28083. sea: Tensions between scientific judgement and statistical
Devezer, B., Navarro, D. J., Vandekerckhove, J., & Ozge model selection. Computational Brain & Behavior, 2(1),
Buzbas,E.(2021).Thecaseforformalmethodologyinsci- 28–34.
entificreform.RoyalSocietyopenscience,8(3),200805. Navarro, D. J. (2021). If mathematical psychology did not
Dillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can exist we might need to invent it: A comment on theory
AIlanguagemodelsreplacehumanparticipants?Trendsin buildinginpsychology.PerspectivesonPsychologicalSci-
CognitiveSciences. ence,16(4),707–716.

6 VANROOIJANDGUEST
Nosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Szollosi, A., Kellen, D., Navarro, D. J., Shiffrin, R., van
Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Rooij, I., Van Zandt, T., & Donkin, C. (2020). Is prereg-
Struhl, M., Nuijten, M. B., et al. (2022). Replicability, ro- istration worthwhile? Trends in cognitive sciences, 24(2),
bustness,andreproducibilityinpsychologicalscience.An- 94–95.
nualreviewofpsychology,73(1),719–748. vanRooij,I.(2008).Thetractablecognitionthesis.Cognitive
Pléh, C., & Gurova, L. (2013). Existing and would-be ac- science,32(6),939–984.
counts of the history of cognitive science: An introduc- vanRooij,I.(2022).Psychologicalmodelsandtheirdistrac-
tion.PléhCsaba–Gurova,Lilia–Ropolyi,László(2013ed.) tors.NatureReviewsPsychology,1(3),127–128.
New Perspectives on the History of Cognitive Science. van Rooij, I., & Baggio, G. (2020). Theory development
AkadémiaiKiadó,Budapest. requires an epistemological sea change. Psychological In-
Prather, R. W., Benitez, V. L., Brooks, L. K., Dancy, C. L., quiry,31(4),321–325.
Dilworth-Bart, J., Dutra, N. B., Faison, M. O., Figueroa, van Rooij, I., & Baggio, G. (2021). Theory before the test:
M., Holden, L. R., Johnson, C., et al. (2022). What can How to build high-verisimilitude explanatory theories in
cognitivesciencedoforpeople?CognitiveScience,46(6), psychological science. Perspectives on Psychological Sci-
e13167. ence,16(4),682–697.
Pylyshyn, Z. W. (1987). The robot’s dilemma: The frame van Rooij, I., Blokpoel, M., Kwisthout, J., & Wareham, T.
probleminartificialintelligence. (2019).CognitionandIntractability:AGuidetoClassical
Rich, P., de Haan, R., Wareham, T., & van Rooij, I. (2021). and Parameterized Complexity Analysis. Cambridge Uni-
How hard is cognitive science? Proceedings of the annual versityPress.
meetingofthecognitivesciencesociety,43(43). van Rooij, I., Devezer, B., Skewes, J., Varma, S., & Ware-
Ryle, G., & Tanney, J. (2009). The concept of mind. Rout- ham, T. (2024). What makes a good theory? interdisci-
ledge. plinaryperspectives.ComputationalBrain&Behavior,1–
Spanton, R. W., & Guest, O. (2022). Measuring trustwor- 5.
thiness or automating physiognomy? a comment on safra, vanRooij,I.,Guest,O.,Adolfi,F.,deHaan,R.,Kolokolova,
chevallier, gr\ezes, and baumard (2020). arXiv preprint A., & Rich, P. (2024). Reclaiming AI as a theoretical tool
arXiv:2202.08674. forcognitivescience.ComputationalBrain&Behavior,7,
Stengers,I.(2018).Anotherscienceispossible:Amanifesto 616–636.
forslowscience.JohnWiley&Sons.

## 引用

```

```
