---
title: What Does ‘Human-Centred AI’ Mean?
authors: Olivia Guest, What Does
year: N/A
keywords: artificial intelligence, cognitive science, sociotechnical relationship
created: 2025-11-19 22:38:17
---

# What Does ‘Human-Centred AI’ Mean?

## 基本信息

- **作者**: Olivia Guest, What Does
- **年份**: N/A
- **關鍵詞**: artificial intelligence, cognitive science, sociotechnical relationship

## 摘要

Whileitseemssensiblethathuman-centredartificialintelligence(AI)
meanscentring“humanbehaviourandexperience,”itcannotbeanyotherway.
AI, I argue, is usefully seen as a relationship between technology and humans
whereitappearsthatartifactscanperform,toagreaterorlesserextent,human
cognitivelabour.Thisisevincedusingexamplesthatjuxtaposetechnologywith
cognition,interalia:abacusversusmentalarithmetic;alarmclockversusknocker-
upper;cameraversusvision;andsweatshopversustailor.Usingnoveldefinitions
andanalyses,sociotechnicalrelationshipscanbeanalysedintovaryingtypesof:
displacement(harmful),enhancement(beneficial),and/orreplacement(neutral)
ofhumancognitivelabour.Ultimately,allAIimplicateshumancognition;nomat-
terwhat.ObfuscationofcognitionintheAIcontext—fromclockstoartificial
neuralnetworks—resultsindistortion,inslowingcriticalengagement,pervert-
ingcognitivescience,andindeedinlimitingourabilitytotrulycentrehumans
andhumanityintheengineeringofAIsystems.Toevenbegintode-fetishiseAI,
wemustlookthehuman-in-the-loopintheeyes.
Keywords: artificial intelligence; cognitive science; sociotechnical relationship;
cognitivelabour;artificialneuralnetwork;technology;cognition;human-centred
AI
1 Introduction
[M]odels have to be used before they will give up their secrets. In this sense,
they have the quality of a technology — the power of the model only becomes
apparentinthecontextofitsuse.(Morrison&Morgan,1999,p.12)
We are experiencing a point in history that considers itself separate, unique, a zenith of
humancivilisation,presentedasdisconnectedfromthepastthroughaseriesoftechnological
sea changes. In extreme cases, we are detached from even the last few months: the newest
versionofapieceofartificialintelligence(AI)softwareisthedefinitiveone,everythingelse
is irrelevant. And so findings in AI are held to expire. Our AI students describe their own
knowledgeandskills—eventheirwholedegreeitself—ashavingupcomingsell-bydates.
Research in AI is thus often framed as unmoored from historical, ethi

## 研究背景

## 研究方法

## 主要結果

## 討論與結論

## 個人評論

## 相關文獻

## 完整內容

What Does ‘Human-Centred AI’ Mean?
Olivia Guest1,2
1DepartmentofCognitiveScienceandArtificialIntelligence,
RadboudUniversity,TheNetherlands
2DondersInstituteforBrain,Cognition,andBehaviour,
RadboudUniversity,TheNetherlands
Abstract:Whileitseemssensiblethathuman-centredartificialintelligence(AI)
meanscentring“humanbehaviourandexperience,”itcannotbeanyotherway.
AI, I argue, is usefully seen as a relationship between technology and humans
whereitappearsthatartifactscanperform,toagreaterorlesserextent,human
cognitivelabour.Thisisevincedusingexamplesthatjuxtaposetechnologywith
cognition,interalia:abacusversusmentalarithmetic;alarmclockversusknocker-
upper;cameraversusvision;andsweatshopversustailor.Usingnoveldefinitions
andanalyses,sociotechnicalrelationshipscanbeanalysedintovaryingtypesof:
displacement(harmful),enhancement(beneficial),and/orreplacement(neutral)
ofhumancognitivelabour.Ultimately,allAIimplicateshumancognition;nomat-
terwhat.ObfuscationofcognitionintheAIcontext—fromclockstoartificial
neuralnetworks—resultsindistortion,inslowingcriticalengagement,pervert-
ingcognitivescience,andindeedinlimitingourabilitytotrulycentrehumans
andhumanityintheengineeringofAIsystems.Toevenbegintode-fetishiseAI,
wemustlookthehuman-in-the-loopintheeyes.
Keywords: artificial intelligence; cognitive science; sociotechnical relationship;
cognitivelabour;artificialneuralnetwork;technology;cognition;human-centred
AI
1 Introduction
[M]odels have to be used before they will give up their secrets. In this sense,
they have the quality of a technology — the power of the model only becomes
apparentinthecontextofitsuse.(Morrison&Morgan,1999,p.12)
We are experiencing a point in history that considers itself separate, unique, a zenith of
humancivilisation,presentedasdisconnectedfromthepastthroughaseriesoftechnological
sea changes. In extreme cases, we are detached from even the last few months: the newest
versionofapieceofartificialintelligence(AI)softwareisthedefinitiveone,everythingelse
is irrelevant. And so findings in AI are held to expire. Our AI students describe their own
knowledgeandskills—eventheirwholedegreeitself—ashavingupcomingsell-bydates.
Research in AI is thus often framed as unmoored from historical, ethical, social, and legal
precedents.
The speed of the “ultra rapid computing machine,” as Wiener (1948, 1950) de-
scribes computers, becomes a metaphor for the speed of change and of techno-
logicalprogress.Thisnotionofcondensedtimeoperatesasafurtherdiscursive
regularityintwoways.First,itformsanoveralltemporalbackdropagainstwhich
various cybernetic dramas are played out. Second, condensed time becomes a
measureoftheperformanceofhumansandmachines.
Hughes (1985) offers a telling example of the first manifestation of condensed
time:
In the scant two hundred years since the early Industrial Revolution,
Westernmanhastotallyrescaledandchangedthefaceandfabricofhis
environment. Indeed, the changes have proceeded at such an acceler-
atedpacethatwemightusetheword“old”or“outmoded”toreferto
lastmonth’scomputermodel.(p.205)
1
5202
luJ
92
]IA.sc[
2v06991.7052:viXra

O.Guest
Thissenseofcondensingtime—ofspeed,ofrapidchange—imbuesvirtuallyall
thepopularliteratureexamined.Itbecomesacontextualoperator,statedbutnot
questioned.(Hamilton,1998,p.193)
What Sheryl N. Hamilton describes above is more than seven decades old. But if this has
been going for decades, two-thirds of a century or longer still, does this not undermine its
verypremise?Howcanwebothbeatauniquepointinhistory,andtrappedinanendless
cyclethatbeganwiththeparallelingofhumansandclockwork?
The process of uncondensing time indubitably requires slowing down (Stengers, 2018)
and radically centring the human and decentring the “ultra rapid computing machine.”
(Hamilton,1998)Todothis,someproposeto(conceptually)reengineer(Guest,2024;Nado,
2021)orreimaginethesemachinesandourrelationshipstotheminteraliathroughasubfield
known as human-centred AI. For a pertinent example, Andy J. Wills (2025), in the call for
thisspecialissue,describeshuman-centredartificialintelligence(HCAI)asplacing“human
behaviourandexperienceattheheartof[AI]research.”Anexampleofthis,hesays,couldbe
caseswhereinitis“claimedthatartificialneuralnetworks(ANNs)nowperformathuman
levelsinavarietyoftasks”.Hegoesontoask:
CanANNseffectivelyandsafelybeusedtosupporttheworkofhighlytrainedpro-
fessionals—for example, radiologists, therapists, legal advisors, or researchers?
Canweeffectivelyadapttheskillsandtechniquesofbehaviouralresearch,previ-
ouslyappliedtohumansandotheranimals,tobetterunderstandthe‘psychology’
ofcomplexblack-boxANNs?
Relatedly, Yvonne Rogers (2022) states the goal of HCAI as “designing AI systems that
enhancehumancapacitiesandimprovetheirexperiencesratherthanreplacingthemthrough
automation[,alongwiththeaspirationof]reimagininghuman-machineinteractioninallits
guises[,whilenegotiating]thecreepingcreepinessofAI”(p.255).Industryplayers,suchas
IBM,makeadifferentbutnotentirelyincompatibleconceptualisation:
Human-Centered AI (HCAI) is an emerging discipline intent on creating AI
systems that amplify and augment rather than displace human abilities. HCAI
seekstopreservehumancontrolinawaythatensuresartificialintelligencemeets
ourneedswhilealsooperatingtransparently,deliveringequitableoutcomes,and
respectingprivacy.(Geyeretal.,2022,n.p.)
Regulatorybodies,liketheEuropeanUnion,alsohaveaperspective:
Thehuman-centricapproachtoAIstrivestoensurethathumanvaluesarecentral
to the way in which AI systems are developed, deployed, used and monitored,
byensuringrespectforfundamentalrights,[...]whichareunitedbyreferenceto
acommonfoundationrootedinrespectforhumandignity,inwhichthehuman
beingenjoysauniqueandinalienablemoralstatus.(Tambiama,2019,p.3)
OverallweseethatHCAI—asaspecialisationforstudents(e.g.“Human-CenteredAItrack,
MScHuman-TechnologyInteraction,EindhovenUniversityofTechnology”,2025;“Human-
CentredAItheme,MScDataScienceandArtificialIntelligenceTechnology,TUDelft”,2025),
as a subfield for scholars (e.g. “HCAIM Consortium”, 2025; Holzinger, 2025; “Human-
centered Artificial Intelligence, Utrecht University”, 2025; Rogers, 2022; Stanford Institute
forHuman-CenteredAI,2019;Wills,2025)ortechnologyindustryworkers(e.g.Geyeretal.,
2022)alike,andasaconcernandmissionforregulators(e.g.Pirozzoli,2024;Tambiama,2019)
—interweavesfourrelatedthemes:
1. supporting or enhancing human skills, both without displacement of said skills and
withoutviolationoffundamentalhumanrights;
2. imbuing systems with various so-called human-aligned values, including those of
explainabilityandtransparency;
3. focussing on human behaviour as a benchmark, i.e. the idea of human-like or -level
performance;
4. implicating behavioural, or otherwise psychological, methods in the study of these
systemsasifonequalepistemicfootingwithhumans.
2

WhatDoes‘Human-CentredAI’Mean?
In this paper, I turn this frame on its head (cf. Andersen et al., 2023; Bannon, 2011;
Bishop, 2021; Nick Dyer-Witheford, 2019; Rogers, 2022; Ryan, 2024; Schmager et al., 2025;
Shneiderman,2022;Steinhoff,2021;Walton&Nayak,2021).Usingaunique(re)definitionof
AIthatreleasesusfromacorrelationist1grip,wethenexaminethreetripletsascasestudiesof
techno-socialrelationshipsbetweencognitionandartifacts.Topresagethecominganalyses,
hereinAIisanytechno-socialrelationshipthatoutsourcestomachinesoralgorithmssome
part, however small, of human cognitive labour (cf. van Rooĳ et al., 2024). I demonstrate
that AI is human-centric, not because it behaves like or is designed to be like humans, but
becauseitrequiresaghostinthemachine,oftenliterallyanobfuscatedhuman-in-the-loop
toproperlyfunction(alsoseeGuest&Martin,2025)becauseAIishumansalbeitinfetishised
(Braune, 2020; Morris, 2017; Mota & Cosentino Filho, 2024), obfuscated forms (e.g. Erscoi
et al., 2023). That is, AI “is in reality produced by relations among people [even though
it] appears before us in a fantastic form as relations among things” (Pfaffenberger, 1988, p.
250).AI’s“technologicalveil”hideshumancognitivelabour(Mota&CosentinoFilho,2024).
I bring this anthropological, sociotechnical and broadly computational cognitive scientific
angletounderstandingAI,thatisunlike“theskillsandtechniquesofbehaviouralresearch,
previouslyappliedtohumansandotheranimals[,whichclaimtohelpus]betterunderstand
the‘psychology’ofcomplexblack-boxANNs”(Wills,2025,n.p.cf.RaleyandRhee,2023).In
factbehaviouralprobingofsuchsystemsusingsuchexperimentaltechniquesassumestheir
psychological standing to be equal to, or comparable to, biological organisms: it begs the
question (see for relevant analyses: Forbes & Guest, 2025; Guest & Martin, 2023, 2024; Raji
etal.,2022).
The perspective I bring here answers questions upstream to analysing the behavioural
outputs of such systems, instead focussing on in principle analyses, freeing us from a cor-
relationist account which delivers flawed reasoning and uninterpretable results (Guest &
Martin, 2023, 2024; Guest, Scharfenberg, & van Rooĳ, 2025). The contradiction between ar-
tifice, artificiality, machines, and the machinic and intelligence, cognition, and humanity is
problematisedanddissectedbythemethodherein.Thesetwocanappearbothasopposites
and as identical; at odds as analytical constructs and inexorably intertwined. For example,
“[f]or a long time, the human was something else altogether; it is not so long ago that it
became a machine—a calculating one no less.” (Mauss, 1923, pp. 176–177; translated by
LePage-Richer,2024,p.20)Somegofurtheralongthisroute,remarkingthat“thehistoryof
thesciencesisnowreachingapoint,inallitsbranches,whereeveryscientifictheorycanbe
takenasamachine”(Guattarietal.,1984,p.112);andarguing“thatscientificmodelshave
certainfeatureswhichenableustotreatthemasatechnology.”(Morrison&Morgan,1999,
p.35)Andothers—coincidingwiththeregulators’worries—noticethat“[m]achinerydoes
not just act as a superior competitor to the worker, always on the point of making [them]
superfluous.Itisapowerinimicalto[them],andcapitalproclaimsthisfactloudlyandde-
liberately,aswellasmakinguseofit.”(MarxMemorialLibrary,2024,n.p.)Whichisit?Are
humansmachines,ormachinicinsomeimportantway,sotheycanberecreatedinmachines?
Aremachinessomehowhuman-like,createdbyusinourimage?Letmetellyou.
2 RadicallyRedefiningAI
[I]tisimpossibletocreateanabsolutelyreliableautomaticsystem,andsooneror
laterpeoplefacethenecessitytoactafterequipmentfails.[...]Ifthecosmonaut
losessuchskillsbecauseof[their]passiverole[duetobeingtypicallylimitedto
monitoringandobservationonly],theprobabilityof[their]choosingandcarrying
out the right procedure in an emergency would be small. This contradiction is
inherentinautomaticcontrolsystems.(Ponomareva,1998,n.p.)
Aspractitionersofscience,wearedutyboundtothinkaboutwhat‘artificial’and‘intelligence’
mean. What does it mean to propose an artificial version of a human capacity? When we
talkaboutredefiningsomething,wemustrememberthat“definitionshavenoinherenttruth.
Theyareagreedconventionstestedbytheirinternalcoherenceaswellasbytheirrelationship
to common sense, common practice and history.” (Yuval-Davis 2024, p. 790; also see Elgin
1The idea that it is correlations with a given target, like human data derived benchmarks (Pasquinelli 2017;
Schrimpfetal.2020;cf.vanRooĳetal.2024),thatvalidatethesafety(El-Mhamdietal.,2022),appropriateness,or
otherdesirablepropertiesofamodelorsystem.Ingeneral,correlationismmaybeunproblematic,butinasetting
wherecomputationisinvolvedcorrelationscannotfunctionasausefulguide,servingmoreasredherringthan
anythingelse(Guest&Martin,2023,2024,2025;Guest,Scharfenberg,&vanRooĳ,2025).
3

O.Guest
Table1.ThetwostepsrequiredfortheproposedredefinitionofAI.Atthetopisstep1,wherewedecide
whetherarelationshipexistsbetweenatechnologyandhumancognition.Thisrelationship,represented
by the blue-green column between Machine and Human on row 1a, is AI. In 1b are terminological
examples, both non-diagnostic on their own and incomplete as a list, that can aid in the diagnosis
of a sociotechnical relationship as one of AI. The three columns below in step 2 represent three, not
mutually exclusive, types of sociotechnical relationship between humans and artifacts. At this step,
wesketchoutifAIreplaces,enhances,ordisplacescognition(row2a)—withrelevantpropertiesand
theirtypicalvalues,non-exhaustivelyspecified,listedonrows2b–h.
1)Discernrelationship: Doestheartefactrelatetocognitivelabour?
a)entitiesinvolved MACHINE HUMAN
b)potentialterms
algorithm,artificial, ability,behaviour,
automation,benchmark, capacity,cognition,
AI
discriminative,computer, intelligence,labour,learn,
engineering,functional, organism,professional,
generative,mechanism, psychology,reason,skill,
system,technology,tool task,thought,train
2)Characteriserelationship: Howdoestheartefactrelatetocognitivelabour?
a)label REPLACEMENT ENHANCEMENT DISPLACEMENT
b)valence neutral beneficial harmful
c)effectoncognition unaffected reskilling deskilling
d)labourobfuscation minimal possible maximal
e)humanequivalence worseorsame different no
f)human-in-the-loop rare possible common
g)humaninput transparent transparent opaque
h)desiredoutput specified formal unspecified
2017;Nado2021)SomeoftheexistingdefinitionsofAIwhenprobedrevealweaknessesin
theaforementioneddimensions—especiallyundesirablewhenspeakingofformalsystems,
whichallAIsystemsnecessarilyare.Thisistosay,“weaknessfromtheviewpointofformal
symmetry of doctrine [is] strength in the service of rising capitalism.” (Novack, 1968, p.
25) So these formal and common-sense problems with pre-existing AI conceptions form a
coreofstrengthwhenincentivesare,inoppositiontoacademia,onesofprofit-makingforthe
technologyindustry(seevanRooĳetal.,2024,foranexpositionofpossiblemeanings).AIhas
hadsomanyrelatedbutnonethelessdifferentmeaningsoverthedecadesthatperhapsitisa
fool’serrandtoeventryandpinitdown(Boden,2006;Dreyfus,1965;Guest&Martin,2024;
Haigh,2023;Lighthilletal.,1973;McCorduck,2004;Smith&Smith,2024).Andsimilarissues
withterminologyappearwithrelatedtermslike‘braininspired’and‘neurallyplausible’to
namebutafewtermswhichfunctionasweaselwords(Guest&Martin,2024)—aswellas
when‘computational’isusedmetaphoricallyornaivelybycognitiveneuroscientists(Guest
&Martin,2025;Guest,Scharfenberg,&vanRooĳ,2025).
All AI implicates human cognition, as a user, as a human-in-the-loop, and as an in-
spiration. What I propose is that the important aspect is understanding how it does this;
understanding the sociotechnical relationship, as opposed to understanding (e.g. probing,
benchmarking)thetechnologyintheabstract.Theshiftingofthescientificemphasistothe
relationship—whatdoesthemodeldoasafunctionofinteractingwithhumans?—from
what the model is in and of itself is by no means completely alien to cognitive scientists
(Bainbridge,1983).Forexample,cognitivecomputationalmodellersarefamiliar,consciously
4

WhatDoes‘Human-CentredAI’Mean?
Table2.ThefirstcolumnrepresentstheAIrelationship(definedinTable1)betweenusinganabacusand
non-abacusassistedmentalarithmetic.Thesecondcolumnbetweenusinganelectronicormechanical
calculatorandanunassistedadultwhoknowsbasicmathematicaloperationsalready.Thethirdcolumn
betweenusingadigitalcomputerandahumancomputer.ThephotointhethirdcolumndepictsNASA
humancomputersDorothyVaughan,LessieHunter,andVivianAdair(Shetterly,2016a,2016b).
artefact ABACUS CALCULATOR DIGITALCOMPUTER
versus VERSUS VERSUS VERSUS
cognitivelabour MENTALARITHMETIC HUMAN HUMANCOMPUTER
a)label enhancement replacement displacement
b)valence beneficial neutral harmful
c)effectoncognition reskilling unaffected deskilling
d)labourobfuscation none moderate high
e)humanequivalence same better quantity,notquality
f)human-in-the-loop abacist none programmer
g)humaninput full-blowncognition function,numbers code,inputtocode
h)desiredoutput resultofcalculation resultofcalculation resultofcalculation
or otherwise, with what in the philosophy of science is known as the pragmatic view on
scientific theories and models, i.e. models are characterisable by their properties derived
fromtheiruse(Guest&Martin,2021;Morgan&Morrison,1999;Winther,2021).
Without further ado and notwithstanding terminological disarray, Table 1 embodies a
single tripartite definition that acts as an analytical tool for discerning the AI’s properties,
e.g. labour obfuscation, which is the extent of the hidden human-in-the-loop (Crawford,
2021; Guest & Martin, 2025). The radical redefinition I propose comprises two parts. First,
full-blown deflation — any sociotechnical relationship could be AI if it links an artefact to
humancognitionsuchthattheartefactcanbeseenasperformingsomeaspectofacognitive
capacity (cf. Egan, 2025; Guest & Martin, 2025). For this step, all we need to ask ourselves
is: does the technology exist in a relationship with human cognition? If we affirm this, we
can move to the next step. Second, we reinflate AI into three types of relationship, that of
enhancement,ofreplacement,andofdisplacement(seeTable1)ofhumancognitivelabour.
As mentioned, AI is any relationship between technology, tools, models, machines and
humans where it appears as if cognitive labour is offloaded onto such artifacts. Anthropo-
logicalnotionsoftoolsversustechnologiescanhelptounpackwhatisgoingonwithrespect
5

O.Guest
tosuchartifacts:
Toolsarecreationsonalocalised,small-scale,theproductsofeitherindividuals
orsmallgroupsonspecificoccasions.Assuch,theydonotgiverisetosystemsof
controlandcoercion.Technology,ontheotherhand,istheproductoflarge-scale
interlocking systems of extraction, production, distribution and consumption,
andsuchsystemsgaintheirownmomentumanddynamic.(Moore,1997,p.5)
Onthis,wecanreadilyseeanabacuscanbebothatoolandexistinarelationshiptohuman
cognition. A familiar case of this type of offloading is sending off your desired arithmetic
functionandthearguments,e.g.addingtwonumbers,toadigitalcalculator.Inthisexample,
youdonotaddthenumbersyourself.Youdothreethings:knowwhichnumbersyouneed,
know which function you need, and know how to use the machine to offload what would
otherwisebeyourcognitivelabour.Thisisstepone:yes,itisAI.Hadthemachinenotexisted,
youwouldhavehadtoperformthearithmeticyourself,andarithmeticiscognitivelabour,
therefore,yes.TheAIrelationshipcouldbeanyofthethreeinTable1,i.e.moreinformation
is needed to understand what is going on in a specific use-case of a calculator to perform
addition.Letuspickasthehumaninthisrelationship,afamiliaronetousall,achildwho
knowsthesymbolsfornumbersandaddition,andhowtousethecalculator,butdoesnotyet
knowmentalorotherwiseaddition.Theeffectthatoffloadingadditiontothecalculatorhas
in this case is why we ban their use by children who have not yet learned basic numeracy,
i.e. in this case using a calculator embodies a way to avoid learning how to add numbers
from therote learningof the additionof pairsof numbersunder ten tothe rulesfor larger
numbers. As a society then, we decide it is undesirable and mostly the 3rd column of step
2inTable1:a)displacement.Itisb)harmfultothedevelopmentofc)thechild’snumeracy
skillsandsolelyknowinghowtoaddusingacalculatorisnotknowinghowtoaddbecause
problemswillappearwhen,e.g.thenumberstobeaddedarebeyondthemaximumnumber
representable by the calculator, in such a case d) obfuscation of somebody else’s cognitive
labourislikelytohappenasthecalculatoronitsownwithoutsomebodywhoknowsaddition
isnote)equivalenttoahuman.2
Foracalculatorgenerally,typicallythehuman-in-the-loop,involvementofhumanover-
sightordataaftertheuserinput,f)iseitherabsentorminimal(e.g.tochangethebatteries)
—andrelatedly,theinputg)iseasilyidentifiableassuch,i.e.whattheusermusthavedone
toobtainh)thedesiredoutput,inthiscasetheresultofthearithmeticoperationrequested,
which is formally well-specified and verifiable. Importantly, a different relationship to hu-
mansascalculatorstypicallyenjoyisnotdisplacementAI,butlikelyenhancementAI:with
calculatorswelosenone3ofourextantmathematicalskillsasadultsandenjoyashortertime
complexity on numerical operations (see column 2, Table 2). Not all technology has such a
trajectory,asweshallseewithspecificcasesofthisin-depthinthenextsection.
3 ArtefactsversusCognitiveLabour
There can be no doubt that the idea of “intelligent”, “thinking” machines has
capturedtheimaginationofmanypeopleallovertheworld.(Saparina,1966,p.
295)
AIisunlikeatoollikeasawusedtocutwoodwherethepersoncuttingalsoputsinlabour,
oftenmorethanthecreatorofthesaw,tocutwood,inthesensethatasawisinvolvedinthe
predominantly overt physical and cognitive labour of woodworking (Guest, Suarez, et al.,
2025).NotsofortypicalcasesofcontemporaryAI,likechatbots—incontrast:Youdidnot
contribute other than as input, e.g. the so-called prompt, ultimately harming the chance to
learn anything substantial (e.g. Bastani et al., 2024; Guest, Suarez, et al., 2025). It is never
clear if the chatbot’s results really match those desired, e.g. so-called hallucinations — “a
misleading (and anthropomorphizing) term[, which has become mainstream, and thus] a
majorwinforAIhype”(Helfrich2024,p.700;Bishop2021;M.T.Hicksetal.2024).Dueto
their opaque nature, AI relationships hide labour that might be invoked not only like the
sawtoextractrawmaterialsordesignsystems,butalsoinreal-timeasyouusetheartefact,
e.g. you forget that sweatshop workers may be in real-time or the recent past refining the
2Inthecaseofaddingnumbersoutsidethemaximum,apersonwhodoesknowadditioncanusethecalculator
toperformpartsofthesumorresorttopaperoranyothercombinationoftheabove.
3Perhapsskillslikelongdivisionatrophy,butwetoleratethis.
6

WhatDoes‘Human-CentredAI’Mean?
output of the chatbot (Crawford, 2021; Perrigo, 2023; Placani, 2024). So much for a stark
contrast between a tool-human sociotechnical relationship without AI and a relationship
thatinvolvesmodernchatbots,whatabouttechnologiesthataremorecomplexthanasaw?
Below, three triplets are presented for exploring and exemplifying my definition of AI
(fromTable1):
3.1Abacus,Calculator,Computer:allthreeartifacts(inTable2),whichareprototypicalcom-
putationalaidsordevices,divergegreatlyontheirneedfordirecthumaninvolvement,
butnonethelesscansharethesamedesiredoutput(theresultofagivencalculation).
3.2AlarmClock,Camera,GarmentFactory:thesethreeexamples(inTable3)demonstrate
howdivergentanddifferentthecognitivelabourandcapacities(knocker-upper,thehu-
manalarmclock;humanvision;seamstress/tailor)andtheirrelatedartefactsare.
3.3LLM,ImageGenerator,Chatbot: these three (in Table 4) implicate what is typical con-
temporary AI, very deep artificial neural networks trained on extremely large datasets
(a correlationist programme previously dubbed modern connectionism in Guest & Mar-
tin,2024)withthecognitivelabourtheyclaimtocapture,ofwhichallrelationshipsare
characterisedasdisplacement.
3.1 Abacus,Calculator,Computer
Analysing these ancestral forms of computers — which function as aids, in the case of the
abacus, and as perhaps something more independent in the cases of the calculator and
Turing-complete electromechanical and electrical digital computers — as AI per Table 1
brings to light aspects that are central to understanding cognitive labour. For the abacus
versus mental arithmetic AI relationship (see column 1, Table 2), we — surprisingly or not
dependingonourfamiliaritywithabacususe—seeamarkedbenefittomentalarithmetic
and an unambiguous development of a new skill (Lima-Silva et al., 2021; Lu et al., 2023;
Wang, 2020; Xie et al., 2024). Importantly, the examples in Table 2 have been chosen inter
alia because we can keep row h constant: all three have the same desired output in these
cases. An interesting highlight is row g) the abacus is completely unable to perform any
arithmetic operation without the abacist. If you forget how to manipulate the beads, the
abacusismerelydecorative.Thisisverydifferenttotheelectroniccalculator(seecolumn2,
Table2)whereoneneednotbefamiliarwiththeoperationofthecalculatoratall:youonly
needtorecallthesymbolsthatrepresentnumbersandfunctions.Notknowinghowtouse
acalculatorisnighonimpossibleinthemodernworld,evenwithouthavingeverusedone,
since the prerequisite knowledge is reading and button affordances; no specific training is
needed.Toforgethowtouseacalculatoristosuffersignificantcognitiveimpairmentbeyond
beingrustymovingbeadsaround;onewouldneedtolosetheabilitytoreadnumbersand
press buttons — highly unusual. And the opposite, using a calculator can harm children’s
abilitytoaccomplishbasicnumeracy,andsoweproscribeitsuseinprimaryschoolsforthis
reason.Inthegeneralcase,oncementalarithmeticismasteredtheAIrelationshipbetween
calculator and human is overall neutral without offering any new skills but also providing
predictablyspeedyandverifiablycorrectarithmetic.Thethermostatisanothergreatexample
ofnodeskillingonanindividuallevel—beforethatwecouldonlysenseusingourbodiesif
thingsweretoohotortoocold,andwestillcan.
In contrast to these positive and neutral AI relations is the original human-computer
relationship(seecolumn3,Table2).Ahumancomputerwasaperson—oftenawomanin
thepreviouscentury,butlessgenderedpriortothat—whoperformedcalculations,worked
withcomputingmachinery,wroteprogrammingsoftware(Grier,2013;Shetterly,2016b).For
example,duringBritain’swareffortagainsttheNazis:
Arrivingmembersofthe[Women’sRoyalNavalService]weregiventwoweeks
training in binary math, the teleprinter alphabet, sight-reading punched paper
tapes,andthestructureandworkingsoftheTunnyandColossusmachines.[...]
Machinework—andthetheoryandskillsitrequired—wasanintegralcomponent
both intellectually and functionally of [the Second World War’s] codebreaking
process. It was not, as many assumed due to its feminized nature, deskilled
drudgework.(M.Hicks,2017,pp.39–40)
7

O.Guest
Table3.Threeexamples(columns)oftechnosocialsystems(e.g.userandalarmclock)pairedtowhat
camebefore(knocker-upper;column1)ortoaclassicalcognitivecapacity(vision;column2)ortoa
non-sweatshopversionofsimilarskillsandlabour(seamstress/tailor;column3)todemonstratethat
their important properties (rows) can be teased apart and understood if we center humans in our
analyses(recallTable1).
artefact ALARMCLOCK CAMERA GARMENTFACTORY
versus VERSUS VERSUS VERSUS
cognitivelabour KNOCKER-UPPER HUMANVISION SEAMSTRESS/TAILOR
a)label replacement enhancement displacement
b)valence neutral beneficial harmful
c)effectoncognition reskilling unaffected deskilling
d)labourobfuscation minimal moderate maximal
e)humanequivalence worseorsame differentorbetter quantity,notquality
f)human-in-the-loop none user workers
currenttime,ring framing,memoryor pattern,materials,
g)humaninput
time,energysource film,energysource workers,wages
persistentimageor
h)desiredoutput userawake clothes
video
ThesameholdsforthehumancomputersintheUSAattheNationalAeronauticsandSpace
Administration(NASA;Shetterly,2016b):
Earlyon,whentheysaidtheywantedthecapsuletocomedownatacertainplace,
theyweretryingtocomputewhenitshouldstart.Isaid,“Letmedoit.Youtell
mewhenyouwantitandwhereyouwantittoland,andI’lldoitbackwardsand
tellyouwhentotakeoff.”Thatwasmyforte.[...]
But when they went to computers, they called over and said, “tell her to check
andseeifthecomputertrajectorytheyhadcalculatedwascorrect.”SoIchecked
itanditwascorrect.(KatherineJohnson,asquotedinHodges,2008,n.p.)
Andin bothcountriesthese womenwerewritten outof thehistoricalrecord; theirerasure
facilitated by the rise of the electronic computer. This general pattern of displacement of
womenbymachines,whichwehavepreviouslydubbedPygmaliondisplacement(Erscoietal.,
2023),andthatofpeoplebymachinesgenerally,hashadharmfuleffectsonsociety(Adler,
1990;Agar,2003;Sherwood,1985;Wendling,2002),likethepermanentharmtotheBritish
computerindustryinthe20thcentury(M.Hicks,2017).Importantly,“digitalcomputerswere
8

WhatDoes‘Human-CentredAI’Mean?
promotedasmoreefficientandlesserror-pronethanhumansatcalculations.Butinfactthis
comparisonisnot‘like-for-like’since,forexample,calculatingballistictrajectoriesis,when
donebywomen,alsoopentoethicalquestioning.”(Erscoietal.,2023,p.20)
Centringthehumancognitivecomponent,aswellasoutliningtheartefactintherelation-
ship with the definition in Table 1, teases out important differences between the presented
relationships.Forexample,allthreepairshavethesamedesiredoutput,whichistheresult
ofthecalculation(rowh,Table2)theabacusrequiresallofhumancognitiontowork,(rows
f andg),whilethecalculatorreallydoestakeoverarithmetic,andthedigitalcomputercan
takeoverevenmore,assumingtheprogrammercancodeit:“algorithmsarealwaysalready
made, maintained, and sustained by humans.” (Bucher, 2018, p. 52) This also underlines
how easily significant cognitive labour can be obfuscated when we move from left to right
in Table 2: every use of the abacus has obvious manipulation effort while once a computer
isprogrammed,softwarerunswithoutanydirectindicationitwashandcrafted(rowd).In
other words and relevant for our fields, “given the Cartesian legacy of the cognitive sci-
ences,computersarelookedatwithvenerationassoonastheyproducewell-formedoutput
(Weizenbaum, 1976)” (Rasenberg et al. 2023, p. 312; Jucan 2023; Powell 1970). We should
thereforebeonhighalertwhenothers(orwe)programcomputerstoperformcomplextasks,
so as not to be taken in by this and misled into thinking something mystical — something
otherthanamachineobeyingourformalinstructions—hasoccurred.
3.2 AlarmClock,Camera,GarmentFactory
Moving away from arithmetical operations and Turing-complete comparisons, to specific
artefacts outside obviously computational devices: Table 3 depicts the AI relationships be-
tweenalarmclocks,cameras,andgarmentfactoriesandrespectiveselectedcognitivecapac-
ities.Analarmclockisasimpledevicethatweprovidesomebasicinputsto(rowg,column
Table3)forittofunctionaswedesire,e.g.toringataspecifictime(rowh).Totheuntrained
eye,analarmclockmayappearnon-cognitive,andyetdepictedintheblack&whitephoto
incolumn1,Table3:“MrsMarySmithwakesthedockersofLimehouse,London,withher
peashooter in 1931. [...] She was a knocker-upper, a human alarm clock” (Topham, 1931,
n.p.).Thealarmclockcompletelyautomateseveryaspectofherkindofprofession,withthe
exceptionthereisnoguaranteetheuserwillbeawake(rowe,columnTable3).Unlikewitha
humanalarmclock,anartefactcannotpromisethedesiredoutput—weallhaveexperienced
sleepingthroughloudnoisesorsomeotheralarmmalfunction,andontheflip-sidechildren
areoftenwokenbytheirparentstoenuretheymakeittoschool.Additionally,theinclusion
of alarm clock functionality in mobile phones means their use can be further generalised
through the day as reminders, with theinputs staying the same as an old-fashioned alarm
clockandthedesiredoutputalwaysrequiringhumansupervision,e.g.aremindertotakeout
therubbishismerelyareminderandnotaguaranteethebagsaretakenout.Allthisisvery
familiartothoseexperiencingstruggleswiththecognitivecapacityofexecutivefunction.
Aslighttangenthereisusefulonthehistoryofclocks,whichisoneofcontroloftheusers
by the measurement of time, and not the other way round, which reflects and underlines
the need to reorient all AI into human-centric focus. Prior to clocks, human labour was
governedbythenaturalpassingoftimesansmeasurement,e.g.wakingwiththesun.Clocks
arehegemonictools,backbonesofindustrialismandcapitalism:
Theproblemoftheclockis,ingeneral,similartothatofthemachine.Mechanical
time is valuable as a means of co-ordination of activities in a highly developed
society,justasthemachineisvaluableasameansofreducingunnecessarylabour
totheminimum.Botharevaluableforthecontributiontheymaketothesmooth
runningofsociety,andshouldbeusedinsofarastheyassist[people]toco-operate
efficiently and to eliminate monotonous toil and social confusion. But neither
should be allowed to dominate [people’s] lives as they do today. (Woodcock,
1944,p.8)
Thisaspectofmachines,whentheymeasureandcontrolus,isonetobearinmind,andone
whichwewillreturntotimeandagainbelow.
ThecameraisperhapsamoreunderstandableadditiontoTable3withitsrelationshipto
thehumancapacityofvisionwell-known.Thepointhere—aswithalltheotherrelationships
—isnotamechanisticsimilaritybutonebasedonfunctionalcorrespondenceorrole,factual
orperceived(cf.Guest&Martin,2023,2024;Guest,Scharfenberg,&vanRooĳ,2025).Notable
inourrelationshipwiththecameraisthefactithaslargelydeskillednothinginthepresent
9

O.Guest
forthetypicaluser,usingacameraorlookingatitsoutput,doesnotnegativelyimpactour
ability to visually perceive (rows b & c, Table 3). Photographs also serve, especially in the
advent of mobile phone cameras, to help us recollect our memories, enhancing our own
abilitytothinkaboutthepast(rowa).Ofcourse,theuser,thephotographer,mustframeand
perform automatic or manual adjustments to the lens, for any image or video to be of use
(rowg).However,thishumancontribution,whichmanifestsastheuser,iseverpresentinall
ourAIsystemsfromcalculatorstoalarmclockstomuchmorecomplexsystemslikedigital
computers. The more infrequently discussed human-in-the-loop is humans other than the
user,suchascaseslikedigitalcomputers(3rdcolumnofTable2)whichrequiremanyother
people’s labour, not just the user’s (Birhane, Han, et al., 2023; Birhane, Prabhu, et al., 2023;
Birhaneetal.,2024;Couldry&Mejias,2019;Crawford,2021;Kallurietal.,2023,2025;Placani,
2024).Aninfamousexampleofthehuman-in-the-looptechniqueistheorientalistMechanical
Turk, which toured from the late 18th to the mid 19th century, wherein a person hid in a
cabinetunderwhatappearedtobeanautomatonthatplayedchess(Stephens,2023).Infact,
the person below the puppet controlled its movements, giving the human player sitting
acrossittheimpressionthattheywerebeingbeatenatchessbyaclockworkmachine.This
isalsothenamesakeofAmazon’sMechanicalTurk,aplatformonwhichlowpaidworkers
toilto“earnpenniesordollarsdoingtasksthatcomputerscannotyet[andmaynever]easily
do.”(Newman,2019,n.p.)
Thesociotechnicalrelationshipbetweenthegarmentfactory,whichcompriseshumans-in-
the-loop,canbeseenasamoreharmful,andequallyobfuscatory,variantoftheMechanical
Turk. Workers are treated badly in many cases, such as where sweatshop labour is used,
the environmental impact of so many clothes is ignored, and the harmful chemicals are
glossedover.Inthenotsodistantpast,peopleownedfewerclothesandhadthemhand-and
custom-madebyseamstressesandtailors.Wereadilyhaveacceptedthisdisplacementofa
relationshipthatinvolvedaskilledadultmakingusasmallselectionofwell-fittingclothes,
whichtypicallycouldlastawholelifetime,toaworldinwhichweconsumeclothesrelent-
lesslymadeoftenbyworkers,whocanevenbeunderage,andareofteninharmfulconditions
(cf.Crawford,2021;NickDyer-Witheford,2019;Perrigo,2023;Steinhoff,2021;Stephens,2023;
Wendling, 2002). Notwithstanding, bespoke tailoring is to this day understood to be supe-
rior,becauseitfactuallyis,andsopreferredbytherichandfamousandindeedrequiredby
anybodyoutsidetheboundsoffactory-madestandardisedclothingconfigurationsandsizes
(rowe).Eventhesimplerskill(comparedtosewingfromscratch)oftakinginoroutclothes
as our bodies change over time is abandoned (row c) as a function of the garment factory
which produces new clothes cheaply that we can buy instead (row e). We now turn to the
cuttingedgeofcontemporaryAI.
3.3 LLM,ImageGenerator,Chatbot
If we centre the cognitive labour when teasing apart these three AI relations, as Table 1
guides us to do, it falls into our lap how it is displacement, harmful, and deskilling in
everycase:largelanguagemodel(LLMs)versusessaywriting,imagegeneratorversusartist,
and chatbot versus human companionship (rows a–c, Table 4). Importantly, as Rasenberg
etal.(2023,p.312)explain,“whereasinhuman-animalinteractionthereisampleevidence
of reciprocal adaptation, here the adaptation is strikingly one-sided, with [such systems]
essentiallyhelpless,requiringcare(Lipp,2023)andforcingpeopletoadapttotheirconstraints
(Alačetal.,2020;Suchman,2019).”Weareexpectedsomehowtolearnwhatispresentedasa
non-skill,because‘promptengineering’isindeednotaskill,toenableustousetheseopaque
corporate-owned stochastic context-addressable systems. And, as turbo charged versions
of the Mechanical Turk, contemporary AI models “are built on massive exploitative ‘ghost
labour’;crowdsourcedandoutsourcedlabourthatfollowsthepatternsofcolonialrelations
(e.g.,Benderetal.,2021)”(McQuillanetal.,2024,p.3).
The false advertising — there is no engineering in prompt engineering — grows the
longertherhetoricaroundthesesystemsareexaminedbecause,aswehaveseenmanytimes
sofar,“datacanonlydosomuch.[InanyapparentlysuccessfulapplicationofAIt]hereal
workiscarriedoutbythepeopleontheground”(Dorrell,2025,n.p.).Whileintheprevious
century, “computing systems functioned due to vast arrays of human workers, expressed
throughworkfloworganization,operators’actions,andsoftware”(M.Hicks,2017,p.5),in
thepresenttheobfuscatedhuman-in-the-loop—suchasthesweatshopworkerswhoguide
andpowerLLMsandothersuchsystems,orusourselveswhosedataisstolenwithoutour
knowledge — is not respected (Birhane & Guest, 2021; Erscoi et al., 2023; Guest & Forbes,
10

WhatDoes‘Human-CentredAI’Mean?
Table 4. Contemporary AI products and models, such as LLMs, image generators, and chatbots are
framedsuchthattheyareincompetitionwith,orseenasequivalentto,cognitivecapacitieslikeessay
writing,creatingartwork,andprovidingcompanionship.
artefact LLM IMAGEGENERATOR CHATBOT
versus VERSUS VERSUS VERSUS
cognitivelabour ESSAYWRITING ARTIST COMPANIONSHIP
a)label displacement displacement displacement
b)valence harmful harmful harmful
c)effectoncognition deskilling deskilling deskilling
d)labourobfuscation maximal maximal maximal
e)humanequivalence worse worse worse
data,programmers, data,programmers, data,programmers,
f)human-in-the-loop
sweatshopworkers sweatshopworkers sweatshopworkers
g)input so-calledprompts so-calledprompts so-calledprompts
essaymatching imagematching
h)desiredoutput unclear,wellness
prompt prompt
2024;McQuillan,2022;O’Neil,2016).Eventhelowbarhumancomputers’treatmenthasset
is not met by modern AI’s dehumanisation and theft of labour (e.g. Brennan et al., 2025;
Crawford,2021;Goetze,2024;Perrigo,2023;Rhee,2018;vanderGun&Guest,2024).Inthe
time of software updates, the obfuscation of programmers’ labour with seamless updates
grows, while in the past one would physically go get artifacts fixed (or indeed fix them
ourselves).
ThesystemsinTable4,embodyanobfuscationoflaboursocompletetheuserbelievesthe
machinethinksforitself(Polo,2024).Inreality,exploitedsweatshopworkersintheGlobal
Southwhoperformthehuman-in-the-looproledoalotofwhatweconsiderautomatedby
AI (Bainbridge, 1983; Bender et al., 2021; Brennan et al., 2025; Crawford, 2021; McQuillan
etal.,2024;Perrigo,2023;Strauch,2017).
Thereitisadefinitesocialrelationbetween[people],thatassumes,intheireyes,
the fantastic form of a relation between things. In order, therefore, to find an
analogy, we must have recourse to the mist-enveloped regions of the religious
world.Inthatworldtheproductionsofthehumanbrainappearasindependent
beingsendowedwithlife,andenteringintorelationbothwithoneanotherandthe
humanrace.Soitisintheworldofcommoditieswiththeproductsof[people]’s
hands.(Marx,1867)
11

O.Guest
The reasoning problems become evermore severe in our misunderstandings of these most
modernmachines(Guest&Martin,2023,2024,2025;Guest,Scharfenberg,&vanRooĳ,2025).
AsTainaBucher(2018,p.50)explains:“Whenamachinerunssmoothly,nobodypaysmuch
attention, and the actors and work required to make it run smoothly disappear from view
(Latour, 1999).” A next step in this devolution and devaluation of cognitive labour is that
nowtheusertoo,deskilledanddisplaced,alsodisappearsfromview.Whatvoicedoesthe
human, now reduced to only a user, have if their essays (column 1, Table 4), their visual
expression(column2)arejustthecopy-pastedoutputofadevicethatperformspatchwork
plagiarism?Whathumanconnectiondotheyhavewhentheirfriendsandromanticpartners
havebeenreplacedwithinanimateobjects(column3)?
Thetechnopositiveargumentusedtobethatviolenceinvideogameswasnotindicative
or causative of interpersonal violence because video game characters are virtual and users
knowtheinteractionisnotinanywayequivalenttothatwithotherpeopleoutsidethegame.
Ifthatlogicstillholdsthenuserswillgainno,orveryfew,positiveeffectsiftheyarelonely
andneedcompanionship(column3,Table4).Ifthatlogicdoesnothold,andpeopleseethese
entities as possessing minds or as people, much more has unravelled. Indeed, for certain
users,thepsychologicaldamagecausedbyonlyormostlyinteractingwithentitiesknownto
bedesignedtotricktheuserintobelievingtheyarepeopleisimmense(Dillon,2020;Dupré,
2025; Erscoi et al., 2023; Hill, 2025; Jucan, 2023; Placani, 2024; Strengers et al., 2024; Turkle,
1984; Turkle et al., 2006; Weizenbaum, 1966, 1976; even the companies involved accept this
potentialharm:Phangetal.,2025).
Asmentioned,pastworriesaboutsociotechnicalrelationswerealongtheselines:
Inasaneandfreesocietysuchanarbitrarydominationof[humanity’s]functions
byeitherclockormachinewouldobviouslybeoutofthequestion.Thedomina-
tionof[humanity]bythecreationof[humanity]isevenmoreridiculousthanthe
dominationof[humanity]by[humanity].(Woodcock,1944,p.8)
Butinthepresent,andasMarx(1867)notesabove,thereisthedominationofhumansbyother
humansviareligious-,conspiratorial-,orcult-likelogic(Dupré,2025;Guest&Martin,2023,
2024;Hao,2025;Heffernan,2025;Reader,2024;Samuel,2023)andthroughthesemachines,
algorithms,models.Humans’expressionsandsocialrelationsarenotevenmediatedthrough
technology,likewhenusingatextingapplicationtocommunicatewithanotherperson,but
constitutetechnologyassuch.Technology,inthisscheme,controlledbyaprivatecompany
(as all examples in Table 4) produces our so-called self-expressions. These relations are no
longercapturedbyalreadyflawedmetaphorsliketheechochamber—theechohasgone,the
chamberisdevoidofpeople:weneithershoutnorareheard.Weabandonourvoice,forget
howtouseit,andforfeitwhatmakeshumansspecialinallcolumnsofTable4.Incentring
cognitionastheanalyticaltoolinTable1ensures,weareforcedtolookthehuman-in-the-loop
intheeyesandrecognisethattheserelationsareharmfultopeople.
4 MachineHauntology&SpectralTechnology
Ignoring the ghosts in our machines harms us and our understanding of all such systems,
from scientific models (Guest & Martin, 2021; Morgan & Morrison, 1999; Powell, 1970; van
Rooĳetal.,2024)tochatbots(Dillon,2020;Erscoietal.,2023;Jucan,2023;Turkleetal.,2006).
TotrulycentrethehumaninAI,wemustadmitthehuman’sdirectandinherentcentrality,
and such an admission can be facilitated by the radical redefining of AI in Table 1 and the
examples unpacked in Tables 2–4. And so if HCAI wishes to uphold and enact its human-
centred-ness, as a field or perspective, it must then aspire to properly address each of the
fourpointsthatarecoretoitscurrentformulation(listedinsection1,repeatedhere),thenit
must:
1. with respect to supporting or enhancing human skills, both without displacement of
saidskillsandwithoutviolationoffundamentalhumanrights,recogniseandactwhen
displacementAIrelationshipstakeplace;
2. withrespecttoimbuingsystemswithvariousso-calledhuman-alignedvalues,includ-
ing those of explainability and transparency, realise that human-aligned values can
onlyexistinsystemswhereweactivelyupholdthosevalues,theydonotcomeforfree,
andarenotformallyguaranteed,butareconstantlynegotiatedthroughsociotechnical
struggles;
12

WhatDoes‘Human-CentredAI’Mean?
3. withrespecttofocussingonhumanbehaviourasabenchmark,i.e.theideaofhuman-
likeor-levelperformance,steerclearofcorrelationist,suchasnaivecomputationalist
ormodernconnectionist,stancesandroundlyrejectbenchmarksasmeaningful;
4. with respect to implicating behavioural, or otherwise psychological, methods in the
studyofthesesystemsasifonequalepistemicfootingwithhumans,takeheedofserious
warningsaboutourcollectivescientificreasoningascorrelationsareredherringsin
thesearchfortheoreticalunderstanding.
Todothis, asIhavedemonstrated,thedefinition proposedinTable1changes howwesee
artefacts,freeingustoviewmanymoreartefact-humanrelationsashavinghumancognition
attheircentres.Forthefirstpartofmynewproposeddefinition,ifcognitivelabourappearsto
beoutsourcedtoagreaterorlesserextenttoaninanimateobject,wecancallthisrelationship
between technology and cognition: AI. For the second step, even more analysis is needed
wherein we need to discern and evaluate the relationship (recall rows in Table 1) between
humansandagivenuseoftheartefactunderquestion(recallTables2–4).Deflatingallows
ustodothingsthatchasingafterwhatAIcurrentlyisperfadsofthetechnologysectordoes
not—specifically:
a. Wecancentrehumancognition,andthereforewecancentrethestudythereof,cogni-
tivescience,asarelevantdisciplinetounderstandpurportedcasesofartificialcognition
(e.g.vanRooĳetal.,2024).Undercomputationalism,whichthepossibilityofengineer-
ing cognition implicates, correlations and benchmarks are not relevant (e.g. Guest &
Martin, 2025; Guest, Scharfenberg, & van Rooĳ, 2025). This allows us to in principle
reject any argument that uses behavioural or neuroimaging correlation to argue for
human-likenessofanartifact.
b. WecanrejectAIhype,anthropomorphism,mysterianismaboutknownmechanism,4
exaggeration, or fads, removing this rhetoric from being relevant as to what counts
as AI, which is a typical frame with many definitions of AI, often to push products
(e.g.Duarteetal.,2024;Forbes&Guest,2025).Thesamegoesforclaimsaboutneural
orbiologicalplausibilityorinspiration;thesehavenousefulcoherentdefinitions(e.g.
Guest&Martin,2023,2024).
c. We can consider AI in general abstracted terms without requiring specific reference
tocurrentadvancesinAI,e.g.chess-playingalgorithmsareAI,regardlessofwhether
systems are cutting edge or not (sometimes called the AI effect; McCorduck, 2004).
Andsowecaneasilyrejectthatonlyartificialneuralnetsorlargelanguagemodelsor
generative AI are AI, especially when until recently GOFAI (good old-fashioned AI,
also known as symbolic) was canonically AI, hence the name (Guest, Suarez, et al.,
2025).
d. Relatedly, we can grant AI a (pre)history, allowing us to include the Antikythera
mechanism(Freethetal.,2021),astrolabes,sextants,abacuses,andmoreinthetimeline
of AI (e.g. Erscoi et al., 2023; Mayor, 2018). We can uncondense time — allowing
us to slow down and giving us back our history — which is centrally relevant for
understanding our present or possible futures (Hamilton, 1998; Stengers, 2018). As
mentioned,thisissomethingofaphobia,notably:
In English, the use of the word cybernetics raises no difficulties. French-
men with sufficient curiosity, however, were surprised to find it in Littre
and Larousse; and the forgotten writings of Ampere were exhumed. When
someone eventually turned up the new term in Plato, some of the experts
roseinhorror,declaringthatkybernitikishouldonnoaccountbetranslated
’cybernetics’.(Guilbaud,1960)
Takentogether,thesepropertiesandby-productsofTable1allowustoperformtranscen-
dental as well as immanent analyses of AI, such that we can pick out more than artificial
neuralnetworks,orspecificallylargelanguagemodels,orsuchthatwecanperformanalyses
outsidethetiredcontrastsofGOFAIorsymbolicAIversusconnectionistAI(Guest&Martin,
2024).Nomoremystificationispossiblebecauseclarityandsimplicityofdefinitionsiswithin
4Theideathatengineeredmechanisms,likematrixmultiplicationorotheroperationsinartificialneuralnetworks
aresomehowuniquelyunknownorunknowablepropertiesofthesesystems.
13

O.Guest
reach, andbecause these modelsare now correctly positionedon a historicaltimeline, and
subject to scientific investigation outside the correlationist dogma (Guest & Martin, 2024,
2025; Guest, Scharfenberg, & van Rooĳ, 2025). We do not need to passively be led astray,
andincircles,bythetechnologysectoranymore,which“ismostlyconcernedwithbuilding
profitableartifactsandisunconcernedwithabstractdefinitionsofintelligence.”(Heffernan,
2019,p.4)
Insteadwecanfocuson:findingpersistentthemes—e.g.Pygmaliondisplacement:the
displacementofwomenbymachinesandalgorithms,aprocessthatinvolvesdehumanising
the women while humanising the technologies (Erscoi et al., 2023) — through teasing out
properties of the sociotechnical relationship; avoiding hype as we centre human cognition;
andusingexampleartifactsfromthedistantandnearpasttohelpcutthroughexaggerated
claims.Importantly,wecanfocusontheharmsofthesociotechnicalrelationshiponacase-
by-case basis, while also learning from the past without getting bogged down by whether
a specific system is, e.g. generative AI versus a convolutional neural network, which is
discriminative AI (Efron, 1975; Guest, Suarez, et al., 2025; Jebara, 2004; Mitchell, 1997; Ng
&Jordan,2001;Xue&Titterington,2008).Wesidestepbeingtrickedintousingsuchformal
terminology wrongly in service of the technology industry’s spin game, which coopts and
distortsformaltermstocauseconfusionandhype(Duarteetal.,2024;Guest,Suarez,etal.,
2025;Helfrich,2024).Thiskindofprotectionfrommisinformationisespeciallyimportantas
companieslargelydeployclosedsourcemodels,buteveninthecaseofopensourcecodeoften
provide misleading or otherwise lacking documentation, limiting scientific investigation
(Barlas et al., 2021; Birhane, Prabhu, et al., 2023; Birhane et al., 2024; Jackson, 2024; Kalluri
etal.,2025;Liesenfeldetal.,2023;Mirowski,2023;Ojewaleetal.,2025;Widderetal.,2024).
Relatedly, the cyclic reasoning of treating machines as if we have decided already that
they are human-like (points 3 & 4 above) is evident at the birth of AI as a field. As Teresa
Heffernan(2024),explains:
Turing speculated that by the end of the century the “use of words...will have
altered so much that one will be able to speak of machines thinking without
expectingtobecontradicted”(1950,p.442),andmanyoftoday’sAIresearchers
have, following Turing’s lead, altered the meaning of words like — “reading,”
“intuiting,” “feeling,” “dreaming,” and “creating” — to accommodate machine
logic.
And the same for other so-called founding fathers of AI, who when coining ‘Artificial In-
telligence’claimed“thateveryaspectoflearningoranyotherfeatureofintelligencecanin
principle be so precisely described that a machine can be made to simulate it” (McCarthy
etal.,1955,p.2).ThisfoundationaldocumentofAI,whichwasaproposalforatwomonth
long summer conference, shows all the hallmarks we wish to avoid. As

## 引用

```

```
