#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è«–æ–‡è³ªé‡æª¢æŸ¥å‘½ä»¤è¡Œå·¥å…·
æª¢æŸ¥çŸ¥è­˜åº«ä¸­è«–æ–‡çš„å…ƒæ•¸æ“šè³ªé‡ä¸¦ç”Ÿæˆå ±å‘Š

ä½¿ç”¨ç¯„ä¾‹:
    # æª¢æŸ¥æ‰€æœ‰è«–æ–‡
    python check_quality.py

    # æª¢æŸ¥ç‰¹å®šè«–æ–‡
    python check_quality.py --paper-id 1

    # æª¢æŸ¥ä¸¦ç”Ÿæˆè©³ç´°å ±å‘Š
    python check_quality.py --detail comprehensive --output quality_report.txt

    # æª¢æŸ¥ä¸¦è‡ªå‹•ä¿®å¾©å•é¡Œ
    python check_quality.py --auto-fix

    # æª¢æ¸¬é‡è¤‡è«–æ–‡
    python check_quality.py --detect-duplicates --threshold 0.85

    # åƒ…é¡¯ç¤ºæœ‰åš´é‡å•é¡Œçš„è«–æ–‡
    python check_quality.py --critical-only
"""

import sys
import argparse
import json
from pathlib import Path

# Windows ç·¨ç¢¼ä¿®å¾©
import io
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ  src åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from src.checkers import QualityChecker


def main():
    parser = argparse.ArgumentParser(
        description="è«–æ–‡è³ªé‡æª¢æŸ¥å·¥å…· - æª¢æŸ¥çŸ¥è­˜åº«ä¸­è«–æ–‡çš„å…ƒæ•¸æ“šè³ªé‡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # æª¢æŸ¥æ‰€æœ‰è«–æ–‡ï¼ˆæ¨™æº–å ±å‘Šï¼‰
  python check_quality.py

  # æª¢æŸ¥ç‰¹å®šè«–æ–‡
  python check_quality.py --paper-id 1

  # ç”Ÿæˆè©³ç´°å ±å‘Š
  python check_quality.py --detail comprehensive

  # åƒ…é¡¯ç¤ºæœ‰åš´é‡å•é¡Œçš„è«–æ–‡
  python check_quality.py --critical-only

  # æª¢æŸ¥ä¸¦è‡ªå‹•ä¿®å¾©å•é¡Œ
  python check_quality.py --auto-fix

  # æª¢æ¸¬é‡è¤‡è«–æ–‡ï¼ˆç›¸ä¼¼åº¦ >= 85%ï¼‰
  python check_quality.py --detect-duplicates --threshold 0.85

  # å°‡å ±å‘Šä¿å­˜åˆ°æ–‡ä»¶
  python check_quality.py --output quality_report.txt

  # JSONæ ¼å¼è¼¸å‡º
  python check_quality.py --format json --output quality_report.json

è©³ç´°ç¨‹åº¦:
  minimal        - åƒ…ç¸½çµçµ±è¨ˆå’Œåš´é‡å•é¡Œ
  standard       - åŒ…å«è­¦å‘Šå’Œè³ªé‡è©•åˆ†ï¼ˆé è¨­ï¼‰
  comprehensive  - åŒ…å«æ‰€æœ‰è©³ç´°ä¿¡æ¯å’Œå»ºè­°
        """
    )

    # æª¢æŸ¥ç›®æ¨™
    target_group = parser.add_mutually_exclusive_group()
    target_group.add_argument(
        '--paper-id',
        type=int,
        help='æª¢æŸ¥ç‰¹å®šè«–æ–‡ID'
    )
    target_group.add_argument(
        '--all',
        action='store_true',
        default=True,
        help='æª¢æŸ¥æ‰€æœ‰è«–æ–‡ï¼ˆé è¨­ï¼‰'
    )

    # è¼¸å‡ºé¸é …
    parser.add_argument(
        '--detail',
        choices=['minimal', 'standard', 'comprehensive'],
        default='standard',
        help='å ±å‘Šè©³ç´°ç¨‹åº¦ï¼ˆé è¨­: standardï¼‰'
    )

    parser.add_argument(
        '--format',
        choices=['text', 'json'],
        default='text',
        help='è¼¸å‡ºæ ¼å¼ï¼ˆé è¨­: textï¼‰'
    )

    parser.add_argument(
        '--output',
        type=str,
        help='è¼¸å‡ºæ–‡ä»¶è·¯å¾‘ï¼ˆå¯é¸ï¼Œé»˜èªè¼¸å‡ºåˆ°çµ‚ç«¯ï¼‰'
    )

    # éæ¿¾é¸é …
    parser.add_argument(
        '--critical-only',
        action='store_true',
        help='åƒ…é¡¯ç¤ºæœ‰åš´é‡å•é¡Œçš„è«–æ–‡'
    )

    parser.add_argument(
        '--min-score',
        type=float,
        help='åƒ…é¡¯ç¤ºè©•åˆ†ä½æ–¼æ­¤å€¼çš„è«–æ–‡'
    )

    # ä¿®å¾©é¸é …
    parser.add_argument(
        '--auto-fix',
        action='store_true',
        help='è‡ªå‹•ä¿®å¾©å¯ä¿®å¾©çš„å•é¡Œ'
    )

    # é‡è¤‡æª¢æ¸¬
    parser.add_argument(
        '--detect-duplicates',
        action='store_true',
        help='æª¢æ¸¬é‡è¤‡è«–æ–‡'
    )

    parser.add_argument(
        '--threshold',
        type=float,
        default=0.85,
        help='é‡è¤‡æª¢æ¸¬ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆ0-1ï¼Œé è¨­: 0.85ï¼‰'
    )

    # APIé¸é …
    parser.add_argument(
        '--disable-api',
        action='store_true',
        help='ç¦ç”¨å¤–éƒ¨APIï¼ˆè·³éå…ƒæ•¸æ“šå¢å¼·ï¼‰'
    )

    args = parser.parse_args()

    # å‰µå»ºæª¢æŸ¥å™¨
    print("åˆå§‹åŒ–è³ªé‡æª¢æŸ¥å™¨...")
    checker = QualityChecker(enable_api=not args.disable_api)

    # æª¢æ¸¬é‡è¤‡è«–æ–‡ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
    if args.detect_duplicates:
        print(f"\næª¢æ¸¬é‡è¤‡è«–æ–‡ï¼ˆç›¸ä¼¼åº¦é–¾å€¼: {args.threshold}ï¼‰...")
        duplicates = checker.detect_duplicates(threshold=args.threshold)

        if duplicates:
            print(f"\nğŸ” ç™¼ç¾ {len(duplicates)} çµ„å¯èƒ½é‡è¤‡çš„è«–æ–‡:")
            print("=" * 70)
            for i, (id1, id2, similarity) in enumerate(duplicates, 1):
                paper1 = checker.kb.get_paper_by_id(id1)
                paper2 = checker.kb.get_paper_by_id(id2)
                print(f"\n{i}. ç›¸ä¼¼åº¦: {similarity:.2%}")
                print(f"   è«–æ–‡ {id1}: {paper1.get('title', 'Unknown')[:60]}...")
                print(f"   è«–æ–‡ {id2}: {paper2.get('title', 'Unknown')[:60]}...")
        else:
            print("âœ… æœªç™¼ç¾é‡è¤‡è«–æ–‡")

        if not args.paper_id and not args.all:
            return

    # åŸ·è¡Œæª¢æŸ¥
    if args.paper_id:
        # æª¢æŸ¥å–®ç¯‡è«–æ–‡
        print(f"\næª¢æŸ¥è«–æ–‡ ID {args.paper_id}...")
        try:
            report = checker.check_paper(args.paper_id, auto_fix=args.auto_fix)
            reports = [report]
        except ValueError as e:
            print(f"âŒ éŒ¯èª¤: {e}")
            sys.exit(1)
    else:
        # æª¢æŸ¥æ‰€æœ‰è«–æ–‡
        print("\næª¢æŸ¥çŸ¥è­˜åº«ä¸­çš„æ‰€æœ‰è«–æ–‡...")
        reports = checker.check_all_papers(auto_fix=args.auto_fix)

    # æ‡‰ç”¨éæ¿¾
    if args.critical_only:
        reports = [r for r in reports if r.has_critical_issues()]
        print(f"éæ¿¾å¾Œ: {len(reports)} ç¯‡è«–æ–‡æœ‰åš´é‡å•é¡Œ")

    if args.min_score is not None:
        reports = [r for r in reports if r.overall_score < args.min_score]
        print(f"éæ¿¾å¾Œ: {len(reports)} ç¯‡è«–æ–‡è©•åˆ†ä½æ–¼ {args.min_score}")

    if not reports:
        print("âœ… æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è«–æ–‡")
        return

    # ç”Ÿæˆè¼¸å‡º
    if args.format == 'json':
        # JSONæ ¼å¼
        output_data = {
            "summary": {
                "total_papers": len(reports),
                "average_score": sum(r.overall_score for r in reports) / len(reports),
                "critical_issues": sum(len(r.get_critical_issues()) for r in reports),
                "warnings": sum(len(r.get_warnings()) for r in reports)
            },
            "reports": [r.to_dict() for r in reports]
        }
        output_content = json.dumps(output_data, ensure_ascii=False, indent=2)
    else:
        # æ–‡æœ¬æ ¼å¼
        if len(reports) == 1:
            # å–®ç¯‡è«–æ–‡è©³ç´°å ±å‘Š
            output_content = reports[0].to_text(detail_level=args.detail)
        else:
            # å¤šç¯‡è«–æ–‡ç¸½çµå ±å‘Š
            output_content = checker.generate_summary_report(reports, detail_level=args.detail)

            # æ·»åŠ å€‹åˆ¥è«–æ–‡è©³æƒ…ï¼ˆå¦‚æœæ˜¯comprehensiveæ¨¡å¼ï¼‰
            if args.detail == "comprehensive":
                output_content += "\n\n" + "=" * 80
                output_content += "\nå€‹åˆ¥è«–æ–‡è©³ç´°å ±å‘Š:\n"
                output_content += "=" * 80 + "\n"

                for i, report in enumerate(reports, 1):
                    if i > 20:  # æœ€å¤šé¡¯ç¤º20ç¯‡è©³ç´°å ±å‘Š
                        output_content += f"\n... é‚„æœ‰ {len(reports) - 20} ç¯‡è«–æ–‡å ±å‘Šå·²çœç•¥\n"
                        break
                    output_content += "\n" + report.to_text(detail_level="standard") + "\n"

    # è¼¸å‡ºçµæœ
    if args.output:
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(output_content)

        print(f"\nâœ… å ±å‘Šå·²ä¿å­˜: {output_path}")
        print(f"   æª¢æŸ¥è«–æ–‡æ•¸: {len(reports)}")
        print(f"   å¹³å‡è©•åˆ†: {sum(r.overall_score for r in reports) / len(reports):.1f}/100")

        if args.auto_fix:
            print(f"   è‡ªå‹•ä¿®å¾©: å·²å•Ÿç”¨")
    else:
        # è¼¸å‡ºåˆ°çµ‚ç«¯
        print("\n" + output_content)

    # é€€å‡ºç¢¼
    # å¦‚æœæœ‰åš´é‡å•é¡Œï¼Œè¿”å›1ï¼›å¦å‰‡è¿”å›0
    has_critical = any(r.has_critical_issues() for r in reports)
    sys.exit(1 if has_critical else 0)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å·²ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
