#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹æ¬¡ç”Ÿæˆ Embeddings è…³æœ¬
ç‚ºçŸ¥è­˜åº«ä¸­çš„è«–æ–‡å’Œ Zettelkasten å¡ç‰‡ç”Ÿæˆå‘é‡åµŒå…¥
"""

import sys
import io
import os
import argparse
import sqlite3
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple
from tqdm import tqdm

# UTF-8 ç·¨ç¢¼ï¼ˆWindows æ”¯æ´ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# å°å…¥ embedding providers å’Œ vector database
from src.embeddings.providers import GeminiEmbedder, OllamaEmbedder
from src.embeddings.vector_db import VectorDatabase
from src.knowledge_base.kb_manager import KnowledgeBaseManager
from src.utils.content_filter import extract_ai_content


class EmbeddingGenerator:
    """åµŒå…¥å‘é‡ç”Ÿæˆå™¨"""

    def __init__(
        self,
        kb_root: str = "knowledge_base",
        provider: str = "gemini",
        chroma_path: str = "chroma_db",
        use_cloud_for_batch: bool = True,
        auto_confirm: bool = False
    ):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            kb_root: çŸ¥è­˜åº«æ ¹ç›®éŒ„
            provider: åµŒå…¥æä¾›è€… (gemini/ollama)
            chroma_path: ChromaDB æŒä¹…åŒ–è·¯å¾‘
            use_cloud_for_batch: æ‰¹æ¬¡è™•ç†ä½¿ç”¨é›²ç«¯ API
            auto_confirm: è‡ªå‹•ç¢ºèªæ‰€æœ‰æç¤º
        """
        self.kb = KnowledgeBaseManager(kb_root)
        self.provider_name = provider
        self.use_cloud_for_batch = use_cloud_for_batch
        self.auto_confirm = auto_confirm

        # åˆå§‹åŒ– embedding provider
        self._init_provider()

        # åˆå§‹åŒ– VectorDatabase
        self.vector_db = VectorDatabase(persist_directory=chroma_path)

    def _init_provider(self):
        """åˆå§‹åŒ– embedding provider"""
        if self.provider_name == "gemini":
            print("åˆå§‹åŒ– Google Gemini Embedder...")
            self.embedder = GeminiEmbedder()
            print(f"  æ¨¡å‹: {self.embedder.model}")
            print(f"  ç¶­åº¦: {self.embedder.dimension}")
            print(f"  æˆæœ¬: ${self.embedder.cost_per_1k_tokens}/1K tokens")

        elif self.provider_name == "ollama":
            print("åˆå§‹åŒ– Ollama Embedder...")
            self.embedder = OllamaEmbedder()
            print(f"  æ¨¡å‹: {self.embedder.model}")
            print(f"  ç¶­åº¦: {self.embedder.dimension}")
            print(f"  æˆæœ¬: $0 (æœ¬åœ°å…è²»)")

        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æä¾›è€…: {self.provider_name}")

    def _read_markdown_content(self, file_path: str) -> str:
        """è®€å– Markdown æ–‡ä»¶å…§å®¹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"  âš ï¸ ç„¡æ³•è®€å– {file_path}: {e}")
            return ""

    def generate_paper_embeddings(self, limit: int = None) -> Tuple[int, int]:
        """
        ç‚ºæ‰€æœ‰è«–æ–‡ç”ŸæˆåµŒå…¥

        Args:
            limit: è™•ç†æ•¸é‡é™åˆ¶ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰

        Returns:
            (æˆåŠŸæ•¸, å¤±æ•—æ•¸)
        """
        print("\n" + "=" * 70)
        print("ğŸ“„ ç”Ÿæˆè«–æ–‡åµŒå…¥")
        print("=" * 70)

        # å¾æ•¸æ“šåº«ç²å–è«–æ–‡
        conn = sqlite3.connect(self.kb.db_path)
        cursor = conn.cursor()

        query = "SELECT id, file_path, title, authors, abstract, keywords FROM papers"
        if limit:
            query += f" LIMIT {limit}"

        cursor.execute(query)
        papers = cursor.fetchall()
        conn.close()

        if not papers:
            print("âš ï¸  çŸ¥è­˜åº«ä¸­æ²’æœ‰è«–æ–‡")
            return 0, 0

        print(f"æ‰¾åˆ° {len(papers)} ç¯‡è«–æ–‡")

        # æº–å‚™æ•¸æ“š
        texts = []
        ids = []
        metadatas = []

        for paper_id, file_path, title, authors, abstract, keywords in papers:
            # çµ„åˆæ–‡æœ¬ï¼šæ¨™é¡Œ + ä½œè€… + æ‘˜è¦ + é—œéµè©
            components = []

            if title:
                components.append(f"æ¨™é¡Œ: {title}")

            if authors:
                components.append(f"ä½œè€…: {authors}")

            if abstract:
                components.append(f"æ‘˜è¦: {abstract}")

            if keywords:
                components.append(f"é—œéµè©: {keywords}")

            # å¦‚æœå…ƒæ•¸æ“šä¸è¶³ï¼Œè®€å– Markdown å…§å®¹
            if len(components) < 2:
                content = self._read_markdown_content(file_path)
                if content:
                    # å–å‰ 2000 å­—å…ƒ
                    components.append(f"å…§å®¹: {content[:2000]}")

            text = "\n".join(components)

            if not text.strip():
                print(f"  âš ï¸ è«–æ–‡ {paper_id} ç„¡å…§å®¹ï¼Œè·³é")
                continue

            texts.append(text)
            ids.append(f"paper_{paper_id}")
            metadatas.append({
                "paper_id": paper_id,
                "title": title or "Unknown",
                "authors": authors or "Unknown",
                "file_path": file_path,
                "type": "paper"
            })

        if not texts:
            print("âš ï¸  æ²’æœ‰å¯è™•ç†çš„è«–æ–‡")
            return 0, 0

        # ä¼°ç®—æˆæœ¬
        if self.provider_name == "gemini":
            cost = self.embedder.estimate_cost(texts)
            print(f"\né ä¼°æˆæœ¬: ${cost:.4f}")

            if not self.auto_confirm:
                confirm = input("æ˜¯å¦ç¹¼çºŒï¼Ÿ(y/n): ")
                if confirm.lower() != 'y':
                    print("å·²å–æ¶ˆ")
                    return 0, 0
            else:
                print("(è‡ªå‹•ç¢ºèª)")

        # ç”ŸæˆåµŒå…¥
        print(f"\nç”Ÿæˆ {len(texts)} å€‹åµŒå…¥...")
        try:
            embeddings = self.embedder.embed_batch(
                texts,
                show_progress=True
            )

            # ä¿å­˜åˆ° ChromaDB
            print("\nä¿å­˜åˆ° ChromaDB...")
            self.vector_db.upsert_papers(
                embeddings=embeddings,
                documents=texts,
                ids=ids,
                metadatas=metadatas
            )

            print(f"âœ… æˆåŠŸè™•ç† {len(texts)} ç¯‡è«–æ–‡")
            return len(texts), 0

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return 0, len(texts)

    def generate_zettel_embeddings(self, limit: int = None) -> Tuple[int, int]:
        """
        ç‚ºæ‰€æœ‰ Zettelkasten å¡ç‰‡ç”ŸæˆåµŒå…¥

        Args:
            limit: è™•ç†æ•¸é‡é™åˆ¶ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰

        Returns:
            (æˆåŠŸæ•¸, å¤±æ•—æ•¸)
        """
        print("\n" + "=" * 70)
        print("ğŸ—‚ï¸  ç”Ÿæˆ Zettelkasten å¡ç‰‡åµŒå…¥")
        print("=" * 70)

        # å¾æ•¸æ“šåº«ç²å–å¡ç‰‡
        conn = sqlite3.connect(self.kb.db_path)
        cursor = conn.cursor()

        query = """
            SELECT card_id, zettel_id, title, content, core_concept, description, ai_notes, human_notes
            FROM zettel_cards
        """
        if limit:
            query += f" LIMIT {limit}"

        cursor.execute(query)
        cards = cursor.fetchall()
        conn.close()

        if not cards:
            print("âš ï¸  çŸ¥è­˜åº«ä¸­æ²’æœ‰ Zettelkasten å¡ç‰‡")
            return 0, 0

        print(f"æ‰¾åˆ° {len(cards)} å¼µå¡ç‰‡")

        # æº–å‚™æ•¸æ“š
        texts = []
        ids = []
        metadatas = []

        for card_id, zettel_id, title, content, core_concept, description, ai_notes, human_notes in cards:
            # çµ„åˆæ–‡æœ¬ï¼šæ¨™é¡Œ + æ ¸å¿ƒæ¦‚å¿µ + æè¿° + å…§å®¹
            components = []

            if title:
                components.append(f"æ¨™é¡Œ: {title}")

            if core_concept:
                components.append(f"æ ¸å¿ƒæ¦‚å¿µ: {core_concept}")

            if description:
                components.append(f"æè¿°: {description}")

            # å„ªå…ˆä½¿ç”¨ ai_notesï¼ˆPlan Bï¼‰ï¼Œå¦‚æœç‚º NULL å‰‡ fallback åˆ°å¾ content æå–
            if ai_notes:
                # ai_notes å·²ç¶“æ˜¯ç´” AI å…§å®¹ï¼Œç›´æ¥ä½¿ç”¨
                ai_content = ai_notes
            elif content:
                # Fallback: å¾ content æå– AI å…§å®¹ï¼ˆéæ¿¾äººé¡ç­†è¨˜ï¼‰
                ai_content = extract_ai_content(content)
            else:
                ai_content = None

            if ai_content:
                # å…§å®¹å¯èƒ½å¾ˆé•·ï¼Œå–å‰ 1500 å­—å…ƒ
                components.append(f"å…§å®¹: {ai_content[:1500]}")

            text = "\n".join(components)

            if not text.strip():
                print(f"  âš ï¸ å¡ç‰‡ {zettel_id} ç„¡å…§å®¹ï¼Œè·³é")
                continue

            texts.append(text)
            # ä½¿ç”¨è³‡æ–™åº«ä¸­çš„æ¨™æº– ID æ ¼å¼ï¼ˆä¸åŠ å‰ç¶´ï¼‰
            ids.append(zettel_id)
            metadatas.append({
                "card_id": card_id,
                "zettel_id": zettel_id,
                "title": title or "Unknown",
                "type": "zettelkasten"
            })

        if not texts:
            print("âš ï¸  æ²’æœ‰å¯è™•ç†çš„å¡ç‰‡")
            return 0, 0

        # ä¼°ç®—æˆæœ¬
        if self.provider_name == "gemini":
            cost = self.embedder.estimate_cost(texts)
            print(f"\né ä¼°æˆæœ¬: ${cost:.4f}")

            if not self.auto_confirm:
                confirm = input("æ˜¯å¦ç¹¼çºŒï¼Ÿ(y/n): ")
                if confirm.lower() != 'y':
                    print("å·²å–æ¶ˆ")
                    return 0, 0
            else:
                print("(è‡ªå‹•ç¢ºèª)")

        # ç”ŸæˆåµŒå…¥
        print(f"\nç”Ÿæˆ {len(texts)} å€‹åµŒå…¥...")
        try:
            embeddings = self.embedder.embed_batch(
                texts,
                show_progress=True
            )

            # ä¿å­˜åˆ° ChromaDB
            print("\nä¿å­˜åˆ° ChromaDB...")
            self.vector_db.upsert_zettel(
                embeddings=embeddings,
                documents=texts,
                ids=ids,
                metadatas=metadatas
            )

            print(f"âœ… æˆåŠŸè™•ç† {len(texts)} å¼µå¡ç‰‡")
            return len(texts), 0

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return 0, len(texts)

    def get_stats(self):
        """ç²å– ChromaDB çµ±è¨ˆä¿¡æ¯"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ChromaDB çµ±è¨ˆ")
        print("=" * 70)

        stats = self.vector_db.get_stats()

        print(f"è«–æ–‡å‘é‡æ•¸: {stats['papers_count']}")
        print(f"Zettelkasten å‘é‡æ•¸: {stats['zettel_count']}")
        print(f"ç¸½è¨ˆ: {stats['total_count']}")


def main():
    parser = argparse.ArgumentParser(
        description="æ‰¹æ¬¡ç”ŸæˆçŸ¥è­˜åº«åµŒå…¥å‘é‡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨æ–¹å¼ï¼š
  # ä½¿ç”¨ uvï¼ˆæ¨è–¦ï¼‰
  uv run embeddings [é¸é …]

  # æˆ–ç›´æ¥ç”¨ Python
  python generate_embeddings.py [é¸é …]

ç¯„ä¾‹ï¼š
  # ç‚ºæ‰€æœ‰è«–æ–‡å’Œå¡ç‰‡ç”ŸæˆåµŒå…¥
  uv run embeddings

  # åƒ…è™•ç†è«–æ–‡
  uv run embeddings --papers-only

  # åƒ…è™•ç† Zettelkasten å¡ç‰‡
  uv run embeddings --zettel-only

  # ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹
  uv run embeddings --provider ollama

  # æ¸¬è©¦æ¨¡å¼ï¼ˆé™åˆ¶è™•ç†æ•¸é‡ï¼‰
  uv run embeddings --limit 5

  # è‡ªå‹•ç¢ºèªï¼ˆç”¨æ–¼è‡ªå‹•åŒ–è…³æœ¬ï¼‰
  uv run embeddings -y

  # åƒ…é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
  uv run embeddings --stats
        """
    )

    parser.add_argument(
        "--provider",
        choices=["gemini", "ollama"],
        default="gemini",
        help="åµŒå…¥æä¾›è€… (é»˜èª: gemini)"
    )

    parser.add_argument(
        "--kb-root",
        default="knowledge_base",
        help="çŸ¥è­˜åº«æ ¹ç›®éŒ„ (é»˜èª: knowledge_base)"
    )

    parser.add_argument(
        "--chroma-path",
        default="chroma_db",
        help="ChromaDB æŒä¹…åŒ–è·¯å¾‘ (é»˜èª: chroma_db)"
    )

    parser.add_argument(
        "--papers-only",
        action="store_true",
        help="åƒ…è™•ç†è«–æ–‡"
    )

    parser.add_argument(
        "--zettel-only",
        action="store_true",
        help="åƒ…è™•ç† Zettelkasten å¡ç‰‡"
    )

    parser.add_argument(
        "--limit",
        type=int,
        help="è™•ç†æ•¸é‡é™åˆ¶ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"
    )

    parser.add_argument(
        "--stats",
        action="store_true",
        help="åƒ…é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯"
    )

    parser.add_argument(
        "--yes", "-y",
        action="store_true",
        help="è‡ªå‹•ç¢ºèªæ‰€æœ‰æç¤ºï¼ˆç”¨æ–¼è‡ªå‹•åŒ–ï¼‰"
    )

    args = parser.parse_args()

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    print("=" * 70)
    print("çŸ¥è­˜åº«åµŒå…¥å‘é‡ç”Ÿæˆå™¨")
    print("=" * 70)

    generator = EmbeddingGenerator(
        kb_root=args.kb_root,
        provider=args.provider,
        chroma_path=args.chroma_path,
        auto_confirm=args.yes
    )

    # åƒ…é¡¯ç¤ºçµ±è¨ˆ
    if args.stats:
        generator.get_stats()
        return

    # è™•ç†è«–æ–‡
    papers_success, papers_fail = 0, 0
    if not args.zettel_only:
        papers_success, papers_fail = generator.generate_paper_embeddings(args.limit)

    # è™•ç† Zettelkasten
    zettel_success, zettel_fail = 0, 0
    if not args.papers_only:
        zettel_success, zettel_fail = generator.generate_zettel_embeddings(args.limit)

    # ç¸½çµ
    print("\n" + "=" * 70)
    print("âœ… è™•ç†å®Œæˆ")
    print("=" * 70)

    total_success = papers_success + zettel_success
    total_fail = papers_fail + zettel_fail

    print(f"è«–æ–‡: {papers_success} æˆåŠŸ, {papers_fail} å¤±æ•—")
    print(f"Zettelkasten: {zettel_success} æˆåŠŸ, {zettel_fail} å¤±æ•—")
    print(f"ç¸½è¨ˆ: {total_success} æˆåŠŸ, {total_fail} å¤±æ•—")

    # é¡¯ç¤ºçµ±è¨ˆ
    generator.get_stats()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
