#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 4: å®Œæ•´ç¶²çµ¡æ¸¬è©¦ï¼ˆ704 å¼µå¡ç‰‡ï¼‰

æ¸¬è©¦ RelationFinder Phase 2.3 æ”¹é€²åœ¨å¯¦éš›çŸ¥è­˜åº«çš„æ•ˆæœ
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# è¨­ç½®å°ˆæ¡ˆæ ¹ç›®éŒ„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

import sqlite3

from src.analyzers.relation_finder import RelationFinder


def test_full_network():
    """åŸ·è¡Œå®Œæ•´ç¶²çµ¡é—œä¿‚è­˜åˆ¥"""
    print("="*70)
    print("Phase 4: å®Œæ•´ç¶²çµ¡æ¸¬è©¦ï¼ˆ704 å¼µå¡ç‰‡ï¼‰")
    print("="*70)
    print(f"æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # åˆå§‹åŒ–
    print("\nåˆå§‹åŒ– RelationFinder...")
    finder = RelationFinder()

    # ç²å–æ‰€æœ‰å¡ç‰‡
    print("è¼‰å…¥æ‰€æœ‰ Zettelkasten å¡ç‰‡...")
    db_path = project_root / "knowledge_base" / "index.db"
    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()

    cursor.execute("""
        SELECT
            zettel_id, title, core_concept, description,
            tags, domain, ai_notes, content,
            created_at
        FROM zettel_cards
        ORDER BY zettel_id
    """)

    all_cards = []
    for row in cursor.fetchall():
        card = {
            'zettel_id': row[0],
            'title': row[1],
            'core_concept': row[2],
            'description': row[3],
            'tags': row[4],
            'domain': row[5],
            'ai_notes': row[6],
            'content': row[7],
            'created_at': row[8]
        }
        all_cards.append(card)

    print(f"è¼‰å…¥å¡ç‰‡æ•¸: {len(all_cards)}")

    # åŸ·è¡Œé—œä¿‚è­˜åˆ¥
    print("\né–‹å§‹é—œä¿‚è­˜åˆ¥...")
    print("(é€™å¯èƒ½éœ€è¦ 3-5 åˆ†é˜)")

    relations = finder.find_concept_relations(
        min_similarity=0.3,  # é™ä½é–¾å€¼ä»¥åŒ…å«æ›´å¤šé—œä¿‚
        relation_types=None  # æ‰€æœ‰é¡å‹
    )

    print(f"\nè­˜åˆ¥é—œä¿‚ç¸½æ•¸: {len(relations)}")

    # çµ±è¨ˆä¿¡åº¦åˆ†ä½ˆ
    print("\n" + "="*70)
    print("ä¿¡åº¦åˆ†ä½ˆçµ±è¨ˆ")
    print("="*70)

    confidence_bins = {
        'â‰¥ 0.8 (æ¥µé«˜)': 0,
        '0.6-0.8 (é«˜)': 0,
        '0.4-0.6 (ä¸­)': 0,
        '0.3-0.4 (ä½)': 0,
        '< 0.3 (æ¥µä½)': 0
    }

    total_confidence = 0.0
    high_confidence_relations = []  # â‰¥ 0.4

    for rel in relations:
        conf = rel.confidence_score
        total_confidence += conf

        if conf >= 0.8:
            confidence_bins['â‰¥ 0.8 (æ¥µé«˜)'] += 1
            high_confidence_relations.append(rel)
        elif conf >= 0.6:
            confidence_bins['0.6-0.8 (é«˜)'] += 1
            high_confidence_relations.append(rel)
        elif conf >= 0.4:
            confidence_bins['0.4-0.6 (ä¸­)'] += 1
            high_confidence_relations.append(rel)
        elif conf >= 0.3:
            confidence_bins['0.3-0.4 (ä½)'] += 1
        else:
            confidence_bins['< 0.3 (æ¥µä½)'] += 1

    avg_confidence = total_confidence / len(relations) if relations else 0.0

    # é¡¯ç¤ºçµ±è¨ˆçµæœ
    for bin_name, count in confidence_bins.items():
        percentage = (count / len(relations) * 100) if relations else 0
        print(f"{bin_name}: {count:,} ({percentage:.1f}%)")

    print(f"\nå¹³å‡ä¿¡åº¦: {avg_confidence:.3f}")
    print(f"é«˜ä¿¡åº¦é—œä¿‚æ•¸ (â‰¥ 0.4): {len(high_confidence_relations):,}")

    # å°æ¯”åŸºæº–æ¸¬è©¦
    print("\n" + "="*70)
    print("èˆ‡åŸºæº–æ¸¬è©¦å°æ¯”")
    print("="*70)

    baseline = {
        'total_relations': 56436,
        'avg_confidence': 0.33,
        'high_confidence': 0,
        'very_high': 0,
        'high': 0,
        'medium': 0
    }

    print(f"\nåŸºæº–æ¸¬è©¦ï¼ˆæ”¹é€²å‰ï¼‰:")
    print(f"  ç¸½é—œä¿‚æ•¸: {baseline['total_relations']:,}")
    print(f"  å¹³å‡ä¿¡åº¦: {baseline['avg_confidence']:.3f}")
    print(f"  é«˜ä¿¡åº¦é—œä¿‚ (â‰¥ 0.4): {baseline['high_confidence']}")

    print(f"\næ”¹é€²å¾Œæ¸¬è©¦:")
    print(f"  ç¸½é—œä¿‚æ•¸: {len(relations):,}")
    print(f"  å¹³å‡ä¿¡åº¦: {avg_confidence:.3f}")
    print(f"  é«˜ä¿¡åº¦é—œä¿‚ (â‰¥ 0.4): {len(high_confidence_relations):,}")

    if len(relations) > 0 and baseline['total_relations'] > 0:
        relations_change = (len(relations) - baseline['total_relations']) / baseline['total_relations'] * 100
        confidence_change = (avg_confidence - baseline['avg_confidence']) / baseline['avg_confidence'] * 100

        print(f"\næ”¹é€²å¹…åº¦:")
        print(f"  é—œä¿‚æ•¸è®ŠåŒ–: {relations_change:+.1f}%")
        print(f"  å¹³å‡ä¿¡åº¦æå‡: {confidence_change:+.1f}%")
        print(f"  é«˜ä¿¡åº¦é—œä¿‚å¢åŠ : {len(high_confidence_relations) - baseline['high_confidence']:,} (+âˆ)")

    # é¡¯ç¤ºå‰ 20 å€‹é«˜ä¿¡åº¦é—œä¿‚ç¯„ä¾‹
    if high_confidence_relations:
        print("\n" + "="*70)
        print("é«˜ä¿¡åº¦é—œä¿‚ç¯„ä¾‹ (å‰ 20 å€‹)")
        print("="*70)

        # æŒ‰ä¿¡åº¦æ’åº
        high_confidence_relations.sort(key=lambda r: r.confidence_score, reverse=True)

        for i, rel in enumerate(high_confidence_relations[:20], 1):
            print(f"\n{i}. [{rel.confidence_score:.3f}] {rel.relation_type}")
            print(f"   å¡ç‰‡1: {rel.card_id_1} - {rel.card_title_1}")
            print(f"   å¡ç‰‡2: {rel.card_id_2} - {rel.card_title_2}")

    # ä¿å­˜çµæœåˆ°æ–‡ä»¶
    output_dir = Path("output/relation_finder_test")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜çµ±è¨ˆæ•¸æ“š
    stats = {
        'test_time': datetime.now().isoformat(),
        'total_cards': len(all_cards),
        'total_relations': len(relations),
        'avg_confidence': avg_confidence,
        'confidence_distribution': confidence_bins,
        'high_confidence_count': len(high_confidence_relations),
        'baseline_comparison': {
            'baseline_total': baseline['total_relations'],
            'baseline_avg_confidence': baseline['avg_confidence'],
            'baseline_high_confidence': baseline['high_confidence'],
            'relations_change_pct': relations_change if len(relations) > 0 else 0,
            'confidence_change_pct': confidence_change if len(relations) > 0 else 0
        }
    }

    stats_file = output_dir / 'test_statistics.json'
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)

    print(f"\nçµ±è¨ˆæ•¸æ“šå·²ä¿å­˜åˆ°: {stats_file}")

    # ä¿å­˜é«˜ä¿¡åº¦é—œä¿‚åˆ—è¡¨
    if high_confidence_relations:
        high_conf_file = output_dir / 'high_confidence_relations.txt'
        with open(high_conf_file, 'w', encoding='utf-8') as f:
            f.write("é«˜ä¿¡åº¦é—œä¿‚åˆ—è¡¨ (â‰¥ 0.4)\n")
            f.write("="*70 + "\n\n")

            for rel in high_confidence_relations:
                f.write(f"ä¿¡åº¦: {rel.confidence_score:.3f} | é¡å‹: {rel.relation_type}\n")
                f.write(f"  å¡ç‰‡1: {rel.card_id_1} - {rel.card_title_1}\n")
                f.write(f"  å¡ç‰‡2: {rel.card_id_2} - {rel.card_title_2}\n")
                f.write("\n")

        print(f"é«˜ä¿¡åº¦é—œä¿‚å·²ä¿å­˜åˆ°: {high_conf_file}")

    print("\n" + "="*70)
    print("âœ… Phase 4 æ¸¬è©¦å®Œæˆ")
    print("="*70)

    # è©•ä¼°æˆåŠŸèˆ‡å¦
    if len(high_confidence_relations) > 0:
        print("\nğŸ‰ æˆåŠŸï¼šç”¢ç”Ÿäº†é«˜ä¿¡åº¦é—œä¿‚ï¼")
        print(f"   Obsidian å»ºè­°é€£çµåŠŸèƒ½ç¾åœ¨å¯ç”¨")
    else:
        print("\nâš ï¸  è­¦å‘Šï¼šä»ç„¡é«˜ä¿¡åº¦é—œä¿‚")
        print(f"   å¯èƒ½éœ€è¦é€²ä¸€æ­¥èª¿æ•´åƒæ•¸")

    return stats


if __name__ == "__main__":
    try:
        stats = test_full_network()
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
