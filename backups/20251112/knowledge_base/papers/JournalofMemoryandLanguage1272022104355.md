---
title: JournalofMemoryandLanguage127(2022)104355
authors: R. Bocanegraa, Verbal Learning, H. Poletiekb, A. Zwaana, Verbal Behavior, Erasmus University, Max Planck, Child Studies, Leiden University, Perception Understanding
year: null
keywords: Although many studies have investigated the activation of perceptual representations during language
created: 2025-10-29 16:14:45
---

# JournalofMemoryandLanguage127(2022)104355

## 基本信息

- **作者**: R. Bocanegraa, Verbal Learning, H. Poletiekb, A. Zwaana, Verbal Behavior, Erasmus University, Max Planck, Child Studies, Leiden University, Perception Understanding
- **年份**: N/A
- **關鍵詞**: Although many studies have investigated the activation of perceptual representations during language

## 摘要

None

## 研究背景

## 研究方法

## 主要結果

## 討論與結論

## 個人評論

## 相關文獻

## 完整內容

JournalofMemoryandLanguage127(2022)104355
Contents lists available at ScienceDirect
Journal of Memory and Language
journal homepage: www.elsevier.com/locate/jml
Language concatenates perceptual features into representations
during comprehension
Bruno R. Bocanegraa,b,*, Fenna H. Poletiekb,c, Rolf A. Zwaana
aDepartment of Psychology, Education and Child Studies, Erasmus University Rotterdam, the Netherlands
bInstitute of Psychology, Leiden University, the Netherlands
cMax Planck Institute for Psycholinguistics, Nijmegen, the Netherlands
A R T I C L E I N F O A B S T R A C T
Keywords: Although many studies have investigated the activation of perceptual representations during language
Language comprehension, to our knowledge only one previous study has directly tested how perceptual features are
Comprehension combined into representations during comprehension. In their classic study, Potter and Faulconer [(1979).
Perception Understanding noun phrases. Journal of Verbal Learning and Verbal Behavior, 18, 509–521.] investigated the
Conjunction
perceptual representation of adjective-noun combinations. However, their non-orthogonal design did not allow
Simulation
the differentiation between conjunctive vs. disjunctive representations. Using randomized orthogonal designs,
we observe evidence for disjunctive perceptual representations when participants represent feature combinations
simultaneously (in several experiments; N =469), and we observe evidence for conjunctive perceptual repre-
sentations when participants represent feature combinations sequentially (In several experiments; N =628). Our
findings show that the generation of conjunctive representations during comprehension depends on the
concatenation of linguistic cues, and thus suggest the construction of elaborate perceptual representations may
critically depend on language.
Introduction the house, the windows, color and texture1 (Barsalou, 1999).
In order to ensure that the simulation of perceptual representations is
A currently influential view is that conceptual processing depends on productive (i.e., that a bounded set of constituent features can generate a
the reactivation of perceptual representations (e.g. Damasio, 1994; potentially unbounded set of composite representations), current
Edelman, 1992; Feldman, 2010; Gallese & Lakoff, 2005; Barsalou, 1999; models assume that people are able to simulate specific conjunctions of
Goldstone & Barsalou, 1998; Prinz, 2002; Pulvermüller, 2005). For perceptual features during comprehension (see Barsalou, 1999; Gold-
example, Prinz claims that “all (human) concepts are copies or combi- stone & Barsalou, 1998). For instance, a perceptual simulation of a BLUE
nations of copies of perceptual representations” (Prinz, 2002, p. 108). HOUSE should represent a house (excluding other objects), that is blue
The idea is that our perceptual system analyzes objects in terms of (excluding other colors).
different features, each of which can be attended to individually through We define a conjunctive representation as the selective representa-
the allocation of selective attention. By allocating attention to different tion of an intersection of two sets of features, and a disjunctive repre-
objects, people can, over time, store individual perceptual features in sentation as a general representation of the union of two sets of features.
memory. Once established, these features can be reactivated episodi- In operational terms, we claim that participants are using a conjunctive
cally in different combinations (see Goldstone & Barsalou, 1998). In this representation, if, during the process of perceptual decision-making (e.
manner, we can represent known objects in their absence, and simulate g., the process of target identification by matching the shape and color
novel objects that we have never seen before. When thinking of a house, dimensions of a target to those encoded in the representation), they have
for example, people can simulate a representation of the overall shape of access to information pertaining to feature presence vs. absence for both
* Corresponding author at: Department of Psychology, Education and Child Studies, Erasmus University Rotterdam, Burg. Oudlaan 50, 3062 PA Rotterdam, the
Netherlands.
E-mail address: bocanegra@essb.eur.nl (B.R. Bocanegra).
1 Please note that throughout this paper we use the term visualization to describe the activation of visual features through language, not the direct activation of
visual features through perception.
https://doi.org/10.1016/j.jml.2022.104355
Received 17 May 2021; Received in revised form 7 July 2022; Accepted 15 July 2022
Availableonline25July2022
0749-596X/©2022TheAuthors.PublishedbyElsevierInc.ThisisanopenaccessarticleundertheCCBYlicense(http://creativecommons.org/licenses/by/4.0/).

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
features simultaneously. If, on the other hand, features can only be participants were never presented an instance of BURNING AIRPLANE
interrogated independently from each other during perceptual decision- or a UPSIDE-DOWN HOUSE. Because of this, the adjective and noun
making, this would constitute a disjunctive representation2. features were perfectly correlated and could not be evaluated indepen-
According to standard arguments, being able to generate a dently of each other. If, within an experimental context, every house is a
conjunctive representation is necessary for meanings of concepts to have burning one and every burning thing is a house, there is no way of telling
combinatorial productivity, which is one of the presumed hallmarks of whether being fast at identifying a picture of a burning house is due to
human cognition (e.g., Rips, 1995). The assumption here is that the the expectation that it will be a house that is burning, or due to the
conjunction operates as an independent unit which inherits its meaning expectation that it will be an object that is burning or a house or both.
from its constituent features, and that it provides the internal structure In the present study, we investigated the combinatorial properties of
which is necessary for (novel) combinations to be composed. This perceptual representations generated during language comprehension,
composition function serves to specify the constituency relations that similar to the way this has previously been investigated in the visual
mental representations can enter into (e.g. Barsalou, 1999; Fodor & perception literature (e.g. Kahneman, Treisman, & Gibbs, 1992; Gordon
Lepore, 1996). Importantly, this wide-held claim is made independently & Irwin, 1996; Saiki, 2003; Hommel, 2005; Bocanegra & Hommel,
of separate claims regarding the (perceptual) nature of the features 2014). We used an orthogonal set of 4 stimuli consisting of two colors (i.
involved in conceptual representation. e., red or green) and two shapes (i.e., a diamond or square)3. In our
Although previous studies have convincingly established that people tasks, participants were presented a verbal cue and instructed to visu-
activate perceptual features during language comprehension (e.g., alize the object described by the cue in terms of its color and shape.
Lupyan & Ward, 2013; Ostarek & Huettig, 2017; Zwaan, Stanfield, & Subsequently, they were presented with a visual target, and they had to
Yaxley, 2002), the critical (and often implicit) assumption that people indicate as fast as possible whether the target matched or mismatched
can generate conjunctive representations has not often been their visualization. For example, participants would be cued with the
investigated. phrase “red square” and then would have to identify a RED SQUARE as a
To date, surprisingly few studies have investigated how people match or a GREEN DIAMOND as a mismatch, within an experimental
combine features when they generate perceptual representations (i.e., context where they also had to identify a RED DIAMOND and a GREEN
Potter & Faulconer, 1979; Wu & Barsalou, 2009). To our knowledge, SQUARE (see right-most panel in Fig. 2b).
Potter and Faulconer (1979) were the first to investigate how combi- Because color and shape features were uncorrelated within our
nations of words in a sentence can cue the generation of a perceptual design this allowed us to test whether people were generating
representation during comprehension. In their classic study, participants conjunctive or disjunctive representations. Our critical comparison is
listened to sentences containing either an adjective-noun or simple noun between single-feature trials where participants were asked to visualize a
phrase, for example, “it was already late when the man saw the {burning one visual feature (i.e., “red”, “square”, “green” or “diamond”) and dual-
house vs. house} ahead of him”, and were asked to discriminate a picture feature trials where participants were asked to visualize two visual fea-
of a burning house from an unrelated picture presented immediately tures simultaneously (i.e., “red square”, “green diamond”, “red dia-
after the noun phrase (see Fig. 1). They argued that if participants are mond” or “green square”). If participants take less time to identify the
cued by the adjective-noun phrase “burning house”, then they should be target when they visualized two features vs. one feature we take this as
faster to respond to a picture of a burning house than when they are cued evidence for the representation of a feature conjunction (e.g., both RED
by the simple noun phrase “house”. The rationale for this benefit in and SQUARE). On the other hand, if perceptual identification times are
performance is that in the adjective-noun condition all features in the similar in dual-feature and single-feature trials we interpret this as evi-
picture can potentially be matched to the generated representation, dence for the representation of a feature disjunction (e.g., either RED or
whereas in the noun-only condition only the features relating to the SQUARE).
building can be matched to the representation but the features relating To clarify these predictions, let’s first assume that the participant
to the flames cannot (see Fig. 2a). activated a conjunctive representation of both RED and SQUARE during
Potter and Faulconer (1979) indeed confirmed that participants a dual-feature trial. This conjunctive representation is illustrated sche-
responded faster in the adjective-noun condition (e.g. “burning house”), matically by the single box located in the R-S (top-left) quadrant in the
compared to the noun-only condition (e.g. “house”). Although this space of possible stimuli (see the left column in Fig. 3). A feature
finding shows that participants were generating a representation using conjunction is therefore a selective representation of only one of the four
both the adjective and the noun, their experimental design did not allow possible target stimuli in the experiment (i.e., the red square), excluding
one to differentiate between a conjunctive representation of the inter- all other possible targets (i.e., the green square, the red diamond, and
section of two sets of features and a disjunctive representation of the the green diamond). At the end of the trial, the color or the shape of the
union of two sets of features (see the two left-most panels in Fig. 2b). The target may be checked against this representation (both color and shape
reason for this is that, within their design, each target was either a were cued features). Given that both the target color and shape will
positive or a negative instance of a unique combination of features: in match the representation, and given our assumption of a conjunctive
other words, participants were presented a BURNING HOUSE, or an representation, only a single comparison is needed in order to uniquely
UPSIDE-DOWN AIRPLANE (see the middle panel in Fig. 2b), but match the target to the represented quadrant (i.e., R-S).
In contrast, the situation is different if we assume that the participant
activated a disjunctive representation of either RED or SQUARE during a
2 This implies that our general notion of conjunctive and disjunctive repre- dual-feature trial. This disjunctive representation is illustrated sche-
sentation could be implemented in various process models using different de- matically by the three boxes located in the R-S (top-left), G-S (top-right),
cision rules / thresholds, as well different types of information representation. It and R-D (bottom-left) quadrants in the space of possible stimuli (see the
is also worth pointing out that there are various ways one might represent middle column in Fig. 3). A feature disjunction is therefore a more
multiple objects as distinct entities (e.g., a white cloud above a blue house)
within frameworks that use both conjunctive and disjunctive representations.
For instance, this could be achieved using conjunctive normal form (CNF)
where a set of objects is represented as an overall disjunction of conjunctive 3 One may argue that a diamond and a square are identical shapes which
literals. For example, one could use a representation like ((A and B) or (¬A and differ only in their orientation. Importantly however, participants in our ex-
¬B)). Alternatively, one could use an equivalent disjunctive normal form (DNF) periments experienced no difficulty interpreting the rotated square as a ‘dia-
where a set of objects is represented as an overall conjunction of disjunctive mond’. It is also worth noting that in the visual search literature color and
literals. Here, the previous example would be represented as ((¬A or B) and (A orientation are standard features for investigating conjunctions (e.g., Spivey,
or ¬B)) (see; Mooney, 1995). Tyler, Eberhard, & Tanenhaus, 2001).
2

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
Fig. 1. Schematic examples of trials in the experiment reported in Potter and Faulconer (1979). In this experiment participants identified a visual picture after
hearing a sentence describing the object presented in the picture. They had to indicate whether the object matched or mismatched the sentence. The left panel
displays a trial where the object was described using an adjective and noun, the right panel displays a trial where the object was described using a noun only. On
mismatching trials participants responded to an unrelated picture.
Critically, we can compare the conjunctive and disjunctive repre-
sentations to a situation when a participant activated a simple repre-
sentation of only SQUARE during a single-feature trial. This
representation is illustrated schematically by the two boxes located in
the R-S (top-left) and G-S (top-right) quadrants in the space of possible
stimuli (see the right column in Fig. 3). At the end of the trial, the color
of the target may be checked against this representation (shape was the
only cued feature). In this case, two comparisons are also needed in
order to uniquely match the target to one of the represented quadrants.
For instance, after initially checking shape, two of the represented
quadrants will coincide with the target (R-S and G-S), and color will
additionally need to be checked in order to determine that the target
uniquely matches the R-S quadrant.
Following this logic, we interpret a performance benefit for dual-
feature vs. single-feature trials as suggesting that participants acti-
vated a conjunctive representation, whereas a null-effect is interpreted
as suggesting that participants activated disjunctive representation.
Please note that this logic applies symmetrically to match trials where
both target features match the representation (see top panel of Fig. 3),
and to mismatch trials where both target features mismatch the repre-
sentation (see bottom panel of Fig. 3). In the latter case, the same
number of comparisons are needed for each type of representation in
order to determine that the target uniquely mismatches one of the rep-
Fig. 2a. A theoretical interpretation of the activation and identification process resented quadrants.
underlying the speed-up for adjective + noun compared to noun-only trials It is important to note that we posit that the perceptual identification
observed in Potter and Faulconer (1979). The left column displays the inter- process is agnostic to meta-cognitive knowledge the participant might
pretation that the representation of HOUSE is selectively constrained by the have of task constraints. For instance, within our experimental context
adjective BURNING. The right column displays the activation of the represen- both target features always either match or mismatch the verbal cue.
tation of HOUSE in the absence of the adjective BURNING.
Therefore, one might argue that there is no need for participants to
evaluate both features: they could employ a task strategy where they
general representation of three of the four possible target stimuli in the only focus on a single feature (e.g., color) in order to determine the
experiment (i.e., the red square, the green square, and the red diamond), correct response. However, given that the task-relevant features in the
excluding only one possible target (i.e., the green diamond). At the end cues varied randomly at the trial-level, participants would not be able to
of the trial, the color or the shape of the target may be checked against consistently apply this strategy throughout the course of the experiment
this representation (both color and shape were cued features). Given (see Bocanegra & Hommel, 2014, for examples of similar tasks that
that both the target color and shape will match the representation, and either enable or prevent participants from applying this type of strat-
given our assumption of a disjunctive representation, in this case two egy). Given the orthogonal design and the variability in task-relevant
comparisons are needed in order to uniquely match the target to one of features, we posit that participants will focus their attention on both
the represented quadrants. For instance, if color is checked first, two of color and shape features and engage in an exhaustive perceptual iden-
the represented quadrants will coincide with the target (R-S and R-D), tification of the target. From this it follows that in match trials a target
and shape will additionally need to be checked in order to determine will have been positively identified once it is determined that it uniquely
that the target uniquely matches the R-S quadrant. matches one of the potential targets in the representation, whereas in
3

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
Fig. 2b. The two left-most panels illustrate the difference between a conjunctive representation of the intersection between two sets of features (top) and a
disjunctive representation of the union of two sets of features (bottom). The middle panel illustrates the non-orthogonal manipulation of feature combinations used in
Potter and Faulconer (1979). The right panel illustrates the orthogonal manipulation of feature combinations used in the present study.
mismatch trials a target will have been negatively identified if it we used 4 auditory word combinations: “red square”, “red diamond”,
uniquely mismatches one of the potential targets in the representation “green square” and “green diamond”. In the single-feature trials, we
(see Fig. 3). used 4 auditory words: “red”, “green”, “square” and “diamond”. The
cues were spoken by a digitally generated female speaker with a neutral
Experiments 1a-d prosody. We used 8 different visual target stimuli. In the visualization
task, we used 4 colored geometric shapes: a red square, red diamond,
In Experiments 1a and 1b we instructed participants to visualize green square and a green diamond. In the verbal task, we used 4 visual
features using an auditory verbal cue, whereas in Experiments 1c and 1d word combinations: “red square”, “red diamond”, “green square” and
we used a visual verbal cue. According to our predictions (see Fig. 3), if “green diamond”.
participants activate a conjunctive representation of color and shape,
then we should observe faster reaction-times for dual-feature vs. single- Procedure
feature trials; on the other hand, if participants activate a disjunctive Experiment 1a had a 2 (visualization task vs. verbal control task) ×2
representation of color and shape then we should observe similar (dual-feature trial vs. single-feature trial) design. In the first half of the
reaction-times for dual-feature and single-feature trials. experiment participants performed the visualization task and in the
Alongside the experimental tasks (i.e., the visualization tasks in Ex- second half they performed the verbal task, or vice versa. Within each
periments 1a-d; see Fig. 4), participants also performed various types of task, single-feature and dual-feature trials were blocked and alternated
control tasks (i.e., a purely verbal task in Experiments 1a-b, a purely (4 blocks per task, with 32 trials per block). The order of the tasks and
visual task in Experiment 1c, and a verbalization task in Experiment 1d) blocks were counterbalanced over participants. All other variables var-
investigating several interpretations of potential effects observed in the ied randomly from trial to trial within each block. The experiment
visualizations tasks (see Fig. 5). These controls had task structures that consisted of 128 trials.
were identical to the experimental visualization tasks, but systematically Each trial started with a fixation cross (500 ms), followed by an
varied characteristics of the cues and targets, where we instructed par- auditory verbal cue stimulus (between 700 ms and 1200 ms), a blank
ticipants either to verbalize (Experiment 1a, 1b, and 1d) or to visualize screen (2000 ms), and finally a visual perceptual target stimulus (until
(Experiment 1c). response). After responding, performance feedback was given (500 ms).
By systematically comparing our original visualization task (where In conditions with visual perceptual targets, participants were
participants were required to actively generate a visual representation instructed to visualize the cued object (in terms of its color and / or
based on a verbal description) to identical tasks that either (a) could be shape), whereas in conditions with visual word targets participants were
performed using only visual maintenance (where participants were instructed to verbalize the cued words (in terms of its color and / or
presented an actual picture as a cue; Experiment 1c), (b) could be per- shape). After a 2 s interval, they were presented with a target stimulus,
formed using only verbal maintenance (where participants were pre- and had to indicate as fast as possible whether the target matched or
sented verbal stimuli as targets; Experiments 1a and 1b), and (c) could mismatched their visualization or verbalization (see Figs. 4 and 5). They
only be performed using verbalization (where participants were were instructed to press the right response if the target matched the cue
required to actively generate a verbal representation based on a visual they were presented at the start of the trial (the “m” key on the
stimulus; Experiment 1d), we aimed to show that any effects observed in keyboard), and to press the left response if the target mismatched the
the experimental conditions could only be attributed to visualization, cue (the “z” key on the keyboard). Participants were instructed that
rather than other task parameters. Their outcomes are discussed in the there would never be ambiguity as to which response had to be given: for
results and discussion section below. dual-feature trials, the target would always either match or mismatch on
both color and shape dimensions (see Figs. 4 and 5).
Experiment 1b was identical to Experiment 1a except for the visual
Method
targets used in the visualization task: We spatially separated out the two
perceptual features in order to match the target presentation in the
Participants
verbal control task.
Forty-eight participants with normal or corrected-to-normal vision
Experiment 1c was identical to Experiment 1a, except for in the
participated in Experiments 1a-d (twelve in each experiment). All par-
following ways. Instead of using a purely verbal task as a control task,
ticipants were undergraduate students at Leiden University, the
we used a purely visual task alongside the visualization task. The cue
Netherlands, participating for course credit or a small monetary reward.
and target stimuli were therefore always presented in the visual mo-
All experiments were conducted in accordance with relevant regulations
dality. In the visual control task, cue stimuli consisted of colored patches
and institutional guidelines and was approved by the local ethics com-
and geometric shapes. In the visualization task, cue stimuli consisted of
mittees from the Faculty of Social and Behavioural Sciences.
visually presented words. Cue stimuli were presented for 1000 ms.
Experiment 1d was identical to Experiment 1c, except for in the
Materials
following ways. Here, we used a verbalization task as the control task.
We used 8 different auditory cue stimuli. In the dual-feature trials,
4

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
Fig. 3. Schematic representation of the process of perceptual representation and identification underlying the theoretical predictions for the visualization tasks in
Experiments 1a-d. We represent the situation where participants activate a feature conjunction (e.g., RED and SQUARE; see left column), a feature disjunction (e.g.
RED or SQUARE; see middle column), or a single feature (e.g., SQUARE; see right column). The top panel displays match trials that required “yes” responses, whereas
bottom panel displays mismatch trials that required “no” responses.
5

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
Fig. 4. Examples of trials in the visualization tasks of Experiments 1a-d. In these visualization tasks participants identified a visual perceptual target using a verbal
linguistic cue (i.e., in order to identify the perceptual target they had to visualize the linguistic cue). The left panels display dual-feature trials, the right panels display
single-feature trials. In Experiment 1a and 1b, the sequence consisted of an auditory cue (700–1200 ms), followed by a blank screen (2000 ms), and finally a visual
target (until response). In Experiments 1c and 1d, the sequence consisted of a visual cue (1000 ms), followed by a blank screen (2000 ms), and finally a visual target
(until response).
The features in both the cue and target stimuli were always presented in the experiments reported in this study are available from https://osf.
a spatially separated manner. In the verbalization control task, cue io/gbuqm/.
stimuli consisted of colored patches and geometric shapes and target
stimuli consisted of visually presented words. In the visualization task, Results
this was the reverse: cue stimuli consisted of visually presented words
and target stimuli consisted of colored patches and geometric shapes. RTs and accuracies for each experiment were analyzed using a 2 ×2
(Task [visualization vs. control] × Trial-type [dual-feature vs. single-
Data analysis feature]) analysis of variance (ANOVA). In Experiment 1a, we found
Reaction times faster than 100 ms and slower than 2000 ms were significant main effects in RT for task, F(1,11) = 19.23, p <.01, η p 2 =
discarded (<4% in Experiment 1a, < 2% in Experiments 1b-d). The 0.64, trial-type, F(1,11) =17.27, p <.01, η p 2 =0.61, and a significant
mean RTs for correct trials, as well as the proportion of accurate re- interaction between task and trial-type, F(1,11) =10.24, p <.01, η p 2 =
sponses were included in the statistical analyses. All raw data files for 0.48. Dual-feature trials (M =637, SD =256) did not differ from single-
6

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
Fig. 5. Examples of trials in the control tasks of Experiments 1a-d. In Experiments 1a and 1b, the control task was a purely verbal task where both cues and target
were verbal linguistic stimuli. In Experiment 1c the control task was a purely visual task where both cues and targets were visual perceptual stimuli. In Experiment 1d
the control task was a verbalization task where participants identified a verbal linguistic target using a visual perceptual cue (i.e., in order to identify the verbal target
they had to verbalize the perceptual cue). The left panels display dual-feature trials, the right panels display single-feature trials. In Experiment 1a and 1b, the
sequence consisted of an auditory cue (700–1200 ms), followed by a blank screen (2000 ms), and finally a visual target (until response). In Experiments 1c and 1d,
the sequence consisted of a visual cue (1000 ms), followed by a blank screen (2000 ms), and finally a visual target (until response).
7

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
single-feature trials (M =766, SD =151) in the verbal control task, t(11)
=7.18, p <.001 (see Fig. 7). In the accuracies, we only observed a sig-
nificant main effect for trial-type F(1,11) = 7.09, p <.05, η p 2 = 0.39.
Participants were more accurate for dual-feature trials (verbal control
task: M =.96, SD =.03; visualization task: M =.96, SD =.03) compared to
single-feature trials (verbal control task: M =.94, SD =.05; visualization
task: M =.93, SD =.05).
In Experiment 1c, we found significant main effects in RT for task, F
(1,11) =9.84, p <.01, η p 2 =0.47, trial-type, F(1,11) =18.69, p <.01, η p 2
=0.63, and and a significant interaction between task and trial-type, F
(1,11) =5.47, p <.05, η p 2 =0.33. Dual-feature trials (M =548, SD =111)
did not differ from single-feature trials (M = 556, SD = 108) in the
visualization task, |t| < 1, p >.50 (see Fig. 6). However, participants
were faster for dual-feature trials (M = 460, SD = 62) compared to
Fig. 6. RTs for the dual and single feature conditions in the visualization tasks
single-feature trials (M =517, SD =77) in the visual control task, t(11)
of Experiments 1a-d. In these visualization tasks participants identified a
perceptual target using a linguistic cue. Error bars represent within-subjects =4.90, p <.001 (see Fig. 7). In the accuracies, we only observed a sig-
standard errors (Loftus & Masson, 1994). nificant main effect for trial-type F(1,11) = 6.42, p <.05, η p 2 = 0.37.
Participants were more accurate for dual-feature trials (visual control
task: M =.96, SD =.03; visualization task: M =.95, SD =.05) compared to
single feature trials (visual control task: M =.95, SD =.05; visualization
task: M =.92, SD =.06).
In Experiment 1d, we found significant main effects in RT for task, F
(1,11) =5.55, p <.05, η p 2 =0.34, trial-type, F(1,11) =4.96, p <.05, η p 2 =
0.31, and a significant interaction between task and trial-type, F(1,11)
=10.40, p <.01, η p 2 =0.49. Dual-feature trials (M =652, SD =139) did
not differ from single-feature trials (M =651, SD =134) in the visual-
ization task, |t| < 1, p >.90 (see Fig. 6). However, participants were
faster for dual-feature trials (M =668, SD =105) compared to single-
feature trials (M =746, SD =127) in the verbalization control task, t
(11) =3.40, p <.01 (see Fig. 7). In the accuracies, we only observed a
significant main effect for trial-type F(1,11) =5.12, p <.05, η p 2 =0.31.
Participants were more accurate for dual-feature trials (verbalization
control task: M =.96, SD =.03; visualization task: M =.96, SD =.03)
compared to single-feature trials (verbalization control task: M =.94, SD
Fig. 7. RTs for the dual and single feature conditions in the control tasks in
Experiments 1a-d. In Experiments 1a and 1b, the control task was a purely =.03; visualization task: M =.95, SD =.03).
verbal task (both cues and target were linguistic stimuli). In Experiment 1c the
control task was a purely visual task (both cues and targets were perceptual Discussion
stimuli). In Experiment 1d the control task was a verbalization task (partici-
pants identified a linguistic target using a perceptual cue). Error bars represent In Experiment 1a, we did not observe a dual-feature benefit in the
within-subjects standard errors (Loftus & Masson, 1994). visualization task, which is consistent with the idea that participants
were representing a disjunctive combination of shape and color. How-
feature trials (M =646, SD =264) in the visualization task, |t| <1, p ever, there are various potential alternative explanations for this null-
>.50 (see Fig. 6). However, participants were faster for dual-feature effect. We will go through each of these in turn.
trials (M = 693, SD = 275) compared to single-feature trials (M = Although we instructed participants to visualize two features during
779, SD =297) in the verbal control task, t(11) =4.90, p <.001 (see dual-feature trials, there were no task requirements that forced partici-
Fig. 7). In the accuracies, we did not observe significant main effects or pants to do so. In other words, participants could have potentially dis-
interaction, F <3.7, p >.08. Participants were equally accurate for dual- regarded the instructions and attended to only one of the two features
feature trials (verbal control task: M =.98, SD =.03; visualization task: presented in the auditory cue (for example, the first word). The selective
M =.96, SD =.03) and single-feature trials (verbal control task: M =.96, representation of only a single feature in during dual-feature trials
SD =.02; visualization task: M =.96, SD =.03)4. would make them informationally equivalent to the single-feature trials
In Experiment 1b, we found significant main effects in RT for task, F and therefore explain the observed null-effect. Given that participants
(1,11) =15.82, p <.01, η p 2 =0.59, trial-type, F(1,11) =11.21, p <.01, η p 2 could potentially perform the task by processing only one of the words
= 0.50, and a significant interaction between task and trial-type, F presented in the auditory cue, we therefore included a verbal control
(1,11) =14.04, p <.01, η p 2 =0.56. Dual-feature trials (M =650, SD = task in order to assess whether participants were processing both cue
129) did not differ from single-feature trials (M =653, SD =169) in the words. If participants were only processing one of the two cue words,
visualization task, |t| < 1, p >.80 (see Fig. 6). However, participants then we should also observe similar reaction-times for dual-feature trials
were faster for dual-feature trials (M = 684, SD = 144) compared to and single-feature trials in the verbal control task that we tested
alongside the visualization task in Experiment 1a. This was not the case:
we observed a clear dual-feature benefit in the verbal control task,
suggesting that the null-effect observed in the visualization task cannot
4 In order to get an indication of whether the type of feature had an overall
be explained by a failure of participants to process both cue words.
effect on RT in our experiments, we analyzed potential differences between
A salient procedural difference between the visualization task and
color vs shape in the single feature trials for Experiments 1a-d. We failed to find
significant differences in the visualization tasks (ps >.12), and in the control verbal control task in Experiment 1a is that target features in the verbal
tasks (ps >.62), indicating that judging the color and shape features during control task were spatially segregated (see Figs. 4 and 5), whereas target
visualization and verbalization was approximately comparable in terms of features in the visualization task were spatially integrated. This may
difficulty. have created a difference in the way that participants performed the two
8

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
tasks, which could potentially offer an explanation for the differential feature conjunctions during language comprehension?
effect of cueing two features vs. one feature in the visualization vs. Some researchers have proposed that language may play an impor-
verbal control task. In order to assess the impact of this difference, we tant role in the generation of complex perceptual representations (e.g.
replicated these two tasks in Experiment 1b, while segregating the target Borghi & Binkofski, 2014; Carruthers, 1996; Gomila, Travieso, & Lobo,
features in the visualization task (see Figs. 4 and 5). As in Experiment 1a, 2012; Lupyan & Bergen, 2016; Paivio, 1986; 2007; Spelke, 2003; Zwaan
we did not observe a dual-feature benefit in the visualization task, & Madden, 2005). For example, Zwaan and Madden (2005) view lin-
whereas we replicated the dual-feature benefit that we previously guistic sequences as a series of cues that can activate and combine
observed in the verbal control task. This suggests that the spatial posi- previously stored perceptual features. If this is the case, then the tem-
tioning of the target features cannot account for the null-effect observed poral concatenation of a sequence of cues may play an important role in
in the visualization task. the activation of feature combinations. The rationale behind this idea is
Our failure to observe a dual-feature benefit in Experiments 1a and that an ordered sequence of words may, over time, incrementally acti-
1b may also be explained by the nature of the identification task per- vate (sub-) sets of perceptual features that provide the referential
formed on the target. Perhaps identifying the target in a visualization domain for a phrase. Through this process, sets of perceptual features
task is very easy and does not allow us to observe any additional benefit may become increasingly specified in terms of its perceptual content.
of visualizing two features vs. one feature. In Experiment 1c, we there- This prediction is illustrated schematically in Fig. 8. Based on our
fore compared the visualization task to a purely visual control task (see results in Experiments 1a-d, we hypothesized a sequential process where
Figs. 4 and 5). If some aspect of the target identification task is pre- a set of features is initially activated, leading to a disjunctive represen-
venting us from observing a dual-feature benefit in the visualization tation of features, and subsequently a subset of features is selected,
task, then we should also fail to observe this benefit in a purely visual leading to a conjunctive representation of features (see left column in
control task. As in Experiments 1a and 1b, we again observed a null- Fig. 8). For example, initially, a participant may activate a representa-
effect in the visualization task. However, we did observe a clear dual- tion of RED, illustrated schematically by the two boxes located in the R-S
feature benefit in the purely visual control task. Given that the targets (top-left) and R-D (bottom-left) quadrants. Subsequently, the participant
were identical in the visualization and purely visual control tasks, this may select the subset SQUARE within the previously activated repre-
suggests that the ease of target identification cannot account for our sentation, illustrated by the single box located in the R-S (top-left)
failure to observe a dual-feature benefit in the visualization task (i.e. due quadrant. Finally, at the end of the trial, either the color or the shape of
to floor effects in RT masking a difference). This interpretation is the target may be checked against this representation in order to identify
bolstered by the fact that participants showed the dual-feature benefit in the target (as explained in our introduction, see Fig. 8).
the visual control task despite being overall faster (see Figs. 6 and 7). In Experiments 2a-b, we tested the prediction that participants
A critical feature of the visualization tasks in Experiments 1a-c is that generate a conjunctive representation of shape and color after being
they always required participants to translate information from the presented a sequence of verbal cues (see Fig. 9). Therefore, we predicted
verbal to the visual domain. In contrast, while performing the control a dual-feature benefit in a sequential version of the visualization task
tasks in Experiments 1a-c participants always processed information (Experiment 2b), whereas we predicted similar reaction times for dual-
within a domain (i.e., within the verbal domain in Experiment 1a and 1b, feature and single-feature trials in a simultaneous version of the visu-
and the visual domain in Experiment 1c). Due to this difference, one alization task (Experiment 2a).
might ask whether cross-domain translation may be masking a potential
dual-feature benefit in the visualization tasks. To test this, we compared Method
the visualization task to a verbalization control task in Experiment 1d
(see Fig. 5), where participants translated information from the visual to Participants
the verbal domain. If cross-domain translation is responsible for mask- Twenty-four participants with normal or corrected-to-normal vision
ing a dual-feature benefit in the visualization task, then we should also participated, twelve in each experiment. All participants were under-
observe a null-effect in the verbalization control task. Our results indi- graduate students at Leiden University, the Netherlands, participating
cate that this was not the case. In addition to again observing the null- for course credit or a small monetary reward.
effect in the visualization task, we observed a clear dual-feature
benefit in the verbalization task, suggesting that cross-domain trans- Materials
lation cannot account for our failure to observe a dual-feature benefit in Stimuli in Experiments 2a and 2b were identical to the visualization
the visualization tasks. task introduced in Experiment 1c, except in the following. In both ex-
In sum, in all four experiments we observed consistent null-effects in periments, the cue words were separated vertically (see Fig. 9). Single-
the visualization tasks where reaction-times for dual-feature trials and feature trials presented the same (color or shape) feature twice,
single-feature trials were similar, and we observed consistent dual- whereas dual-feature trials presented a color and a shape feature.
feature benefits in the various control tasks. Please note that the dual-
features benefits occurred while we systematically varied various Procedure
properties of the cues and targets in the control tasks, which allows us to Procedures in Experiments 2a and 2b were identical to the visuali-
exclude many alternative explanations of the null-effects observed in the zation task introduced in Experiment 1c, except for in the following
visualizations tasks. The consistent pattern across Experiments 1a-d is ways. In Experiment 2a, both cue features were presented simulta-
that null-effects are observed whenever participants are visualizing a neously (for 1000 ms, followed by a 2000 ms blank screen), so that they
verbal cue. Therefore, in light of our predictions, this pattern of results would be visualized simultaneously (i.e., a simultaneous visualization
suggests that participants were activating a general disjunctive repre- task). In Experiment 2b, cue features were presented consecutively
sentation instead of a specific conjunctive representation of the shape (each for 1000 ms, followed by a 2000 ms blank screen), so that they
and color features in the visualization tasks. would be visualized one-at-a-time (i.e., a sequential visualization task;
see Fig. 9). Task was therefore manipulated as a between-subjects factor,
Experiments 2a-b and trial-type as a within-subjects factor. Within each experiment, two
feature orderings (color-shape vs shape-color) were blocked (2 blocks
Given that we did not observe dual-feature benefits when partici- per experiment) and counterbalanced over participants.
pants were visualizing combinations of color and shape features in the
visualization tasks in Experiments 1a-d, this leaves us with the following Data analysis
question: under what conditions do participants represent specific Reaction times faster than 100 ms and slower than 2000 ms were
9

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
Fig. 8. Schematic representation of the perceptual simulation and identification process underlying the theoretical predictions for the visualization tasks in Ex-
periments 2a-b. We represent the situation where participants activate (a) a feature conjunction (e.g., RED and SQUARE) by first activating a feature and then
selecting a subset representation within the feature (see left column), (b) a feature disjunction (e.g. RED or SQUARE; see middle column), or a single feature (e.g.,
SQUARE; see right column).
discarded (<3%). The mean RTs for correct trials, as well as the pro- simultaneously. Importantly, however, we observed a clear dual-feature
portion of accurate responses were included in the statistical analyses. benefit in a sequential version of the visualization task. This finding is
Given that we did not observe any significant main-effects or interaction consistent with idea that participants initially activate a set of features,
effects due to feature ordering, we collapsed the data over this factor. and subsequently select a subset of features, leading to a conjunctive
representation.
Results and discussion Experiments 3a-b
RTs and accuracies for each experiment were analyzed using a 2 ×2 In Experiments 1a-d and Experiment 2a, we failed to observe dual-
(Task [simultaneous vs. sequential] ×Trial-type [dual-feature vs. single- feature benefits when participants were instructed to visualize two
feature]) analysis of variance (ANOVA). In the RTs, we found a signifi- features simultaneously. However, one might wonder whether these
cant main effect for trial-type, F(1,22) =12.77, p <.01, η p 2 =0.37, and a null-effects may be explained by the fact that, in each experiment,
significant interaction between task and trial-type, F(1,22) = 4.49, p single-feature and dual-feature conditions were presented in a blocked
<.05, η p 2 =0.17. Dual-feature trials (M =581, SD =207) did not differ fashion where each block contained a number of trial repetitions. In
from single-feature trials (M = 605, SD = 160) in the simultaneous addition, although well-controlled, it is conceivable that our previous
visualization task, |t| <1, p >.30 (see Fig. 10). However, participants experiments were sampling from a homogenous population of university
were faster for dual-feature trials (M = 587, SD = 160) compared to students which may limit the generality of our results.
single-feature trials (M =682, SD =210) in the sequential visualization In light of these issues, we tested whether we could observe the
task, t(11) =3.54, p <.01. In the accuracies, we only observed a sig- pattern of results of Experiments 2a-b, testing a larger, more heteroge-
nificant main effect for trial-type F(1,22) = 5.95, p <.05, η p 2 = 0.21. neous sample of participants and using a simpler experimental paradigm
Participants were more accurate for dual-feature trials (sequential within a design where single-feature and dual-feature conditions were
visualization task: M =.93, SD =.05; simultaneous visualization task: M not blocked (i.e. the cueing conditions were randomized at the trial-level
=.93, SD =.13) compared to single-feature trials (sequential visualiza- and each trial was presented once). In Experiment 3a, the cue was
tion task: M =.92, SD =.07; simultaneous visualization task: M =.91, SD presented for a short temporal interval of 1000 ms, and was followed by
=.14).
a blank screen for 2000 ms until the onset of the target. In Experiment
Consistent with Experiments 1a-d, we again observed a null-effect in 3b, the cue was presented continuously for a long temporal interval of
a visualization task where both cue words were presented
10

B.R. Bocanegra et al. J o u r n a l o f M e m o r y a n d L a n g u a g e 127(2022)104355
Fig. 9. Illustrations of the trials in Experiment 2a-b. The top panels display the simultaneous visualization task, the bottom panels display the sequential visualization
task. The left panels display dual-feature trials, the right panels display single-feature trials. Each cue (1000 ms), was followed by a blank screen (2000 ms), and the
sequence ended with a target (until response).
Method
Participants
The participants were recruited using the Amazon Mechanical Turk
(https://www.mturk.com)5. Four-hundred and ten participants partici-
pated6, 203 in Experiment 3a and 207 in Experiment 3b. All participants
completed an informed consent form prior to the start of the experiment,
were from the United States and were paid $1.00 for approximately
5–10 min of their time (see Buhrmester, Kwang, & Gosling, 2011).
Materials
Stimuli in Experiments 3a and 3b were identical to Experiments 2a
and 2b, except for the vertical vs. horizontal positioning of the two
words in the verbal cues.
Procedure
Both Experiments 3a and 3b were similar to Experiments 2a and 2b,
except for the following aspects. In Experiment 3a, the cue features were
presented for 1000 ms, followed by a 2000 ms blank screen (short cue
Fig. 10. RTs for each of the conditions in Experiments 2a-b. Error bars repre- task). In Experiment 3b, cue features were presented continuously for
sent within-subjects standard errors (Loftus & Masson, 1994).
3000 ms until target onset (long cue task; see Fig. 11). Task was there-
fore manipulated as a between-subjects factor, and trial-type as a within-
3000 ms until the onset of the target (see Fig. 11). subjects factor constituting a 2 (task: short cue vs. long cue) ×2 (

## 引用

```

```
