#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹æ¬¡è™•ç†å·¥å…·
ç©©å®šåœ°æ‰¹æ¬¡è™•ç†å¤§é‡PDFæ–‡ä»¶

ä½¿ç”¨ç¯„ä¾‹:
    # æ‰¹æ¬¡è™•ç†è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰PDF
    python batch_process.py --folder "D:\\pdfs\\mental_simulation"

    # æ‰¹æ¬¡è™•ç†ä¸¦åŠ å…¥çŸ¥è­˜åº«
    python batch_process.py --folder "D:\\pdfs" --domain CogSci --add-to-kb

    # æ‰¹æ¬¡è™•ç†ä¸¦ç”Ÿæˆ Zettelkasten
    python batch_process.py --folder "D:\\pdfs" --domain CogSci --generate-zettel

    # å®Œæ•´è™•ç†ï¼ˆçŸ¥è­˜åº« + Zettelkastenï¼‰
    python batch_process.py --folder "D:\\pdfs" --domain CogSci --add-to-kb --generate-zettel

    # æŒ‡å®šç‰¹å®šæ–‡ä»¶
    python batch_process.py --files paper1.pdf paper2.pdf paper3.pdf
"""

import sys
import argparse
from pathlib import Path

# æ·»åŠ  src åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from src.processors import BatchProcessor


def main():
    parser = argparse.ArgumentParser(
        description="æ‰¹æ¬¡è™•ç†å·¥å…· - ç©©å®šè™•ç†å¤§é‡PDFæ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # æ‰¹æ¬¡è™•ç†è³‡æ–™å¤¾
  python batch_process.py --folder "D:\\pdfs\\mental_simulation" --domain CogSci

  # åŠ å…¥çŸ¥è­˜åº«
  python batch_process.py --folder "D:\\pdfs" --add-to-kb

  # ç”Ÿæˆ Zettelkasten ç­†è¨˜
  python batch_process.py --folder "D:\\pdfs" --domain CogSci --generate-zettel

  # å®Œæ•´è™•ç†
  python batch_process.py --folder "D:\\pdfs" --domain CogSci --add-to-kb --generate-zettel --workers 4

  # æŒ‡å®šç‰¹å®šæ–‡ä»¶
  python batch_process.py --files paper1.pdf paper2.pdf --add-to-kb

  # ç”Ÿæˆå ±å‘Š
  python batch_process.py --folder "D:\\pdfs" --add-to-kb --report batch_report.json

é ˜åŸŸä»£ç¢¼:
  CogSci       - èªçŸ¥ç§‘å­¸
  Linguistics  - èªè¨€å­¸
  AI           - äººå·¥æ™ºæ…§
  Research     - ä¸€èˆ¬ç ”ç©¶ï¼ˆé è¨­ï¼‰
        """
    )

    # è¼¸å…¥ä¾†æºï¼ˆä¸‰é¸ä¸€ï¼‰
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument(
        '--folder',
        type=str,
        help='åŒ…å«PDFæ–‡ä»¶çš„è³‡æ–™å¤¾è·¯å¾‘'
    )
    input_group.add_argument(
        '--files',
        type=str,
        nargs='+',
        help='æŒ‡å®šçš„PDFæ–‡ä»¶åˆ—è¡¨'
    )
    input_group.add_argument(
        '--from-bibtex',
        type=str,
        help='å¾ BibTeX æ–‡ä»¶è®€å–ï¼ˆPhase 3ï¼šZotero + Obsidian æ•´åˆï¼‰'
    )

    # Phase 3 é¸é …
    parser.add_argument(
        '--pdf-index',
        type=str,
        help='PDF ç´¢å¼•æ–‡ä»¶ï¼ˆPhase 3ï¼šç”¨æ–¼å¾ BibTeX cite key è§£æ PDF è·¯å¾‘ï¼‰'
    )

    parser.add_argument(
        '--pdf-base-dir',
        type=str,
        help='PDF åŸºç¤ç›®éŒ„ï¼ˆPhase 3ï¼šè¦†è“‹ç´¢å¼•ä¸­çš„è·¯å¾‘ï¼‰'
    )

    # è™•ç†é¸é …
    parser.add_argument(
        '--domain',
        type=str,
        default='Research',
        help='é ˜åŸŸä»£ç¢¼ï¼ˆé è¨­: Researchï¼‰'
    )

    parser.add_argument(
        '--add-to-kb',
        action='store_true',
        help='åŠ å…¥çŸ¥è­˜åº«'
    )

    parser.add_argument(
        '--generate-zettel',
        action='store_true',
        help='ç”Ÿæˆ Zettelkasten ç­†è¨˜'
    )

    # Zettelkasten é…ç½®
    parser.add_argument(
        '--detail',
        choices=['standard', 'detailed', 'comprehensive'],
        default='detailed',
        help='Zettelkasten è©³ç´°ç¨‹åº¦ï¼ˆé è¨­: detailedï¼‰'
    )

    parser.add_argument(
        '--cards',
        type=int,
        default=20,
        help='Zettelkasten å¡ç‰‡æ•¸é‡ï¼ˆé è¨­: 20ï¼‰'
    )

    parser.add_argument(
        '--llm-provider',
        choices=['auto', 'google', 'ollama', 'openai', 'anthropic'],
        default='google',
        help='LLM æä¾›è€…ï¼ˆé è¨­: googleï¼‰'
    )

    parser.add_argument(
        '--model',
        type=str,
        default=None,
        help='LLM æ¨¡å‹åç¨±ï¼ˆå¯é¸ï¼Œä¾‹å¦‚ï¼šgpt-oss:20b-cloud, gemma2:latestï¼‰'
    )

    # åŸ·è¡Œé¸é …
    parser.add_argument(
        '--workers',
        type=int,
        default=3,
        help='å¹³è¡Œè™•ç†çš„å·¥ä½œåŸ·è¡Œç·’æ•¸ï¼ˆé è¨­: 3ï¼‰'
    )

    parser.add_argument(
        '--error-handling',
        choices=['skip', 'retry', 'stop'],
        default='skip',
        help='éŒ¯èª¤è™•ç†ç­–ç•¥ï¼ˆé è¨­: skipï¼‰'
    )

    # è¼¸å‡ºé¸é …
    parser.add_argument(
        '--report',
        type=str,
        help='å ±å‘Šè¼¸å‡ºè·¯å¾‘ï¼ˆJSON æˆ–æ–‡æœ¬ï¼‰'
    )

    args = parser.parse_args()

    # Phase 3: é©—è­‰åƒæ•¸çµ„åˆ
    if args.from_bibtex and not args.pdf_index:
        parser.error("--from-bibtex éœ€è¦ --pdf-index åƒæ•¸")

    # æº–å‚™ PDF è·¯å¾‘
    if args.from_bibtex:
        # Phase 3: å¾ BibTeX + PDF index è™•ç†
        import json
        import re

        print(f"\nğŸ“š Phase 3: å¾ BibTeX è®€å–")
        print(f"   BibTeX: {args.from_bibtex}")
        print(f"   PDF Index: {args.pdf_index}")

        # è¼‰å…¥ PDF index
        try:
            with open(args.pdf_index, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
                pdf_index = index_data['index']
            print(f"   âœ… è¼‰å…¥ PDF ç´¢å¼•: {len(pdf_index)} å€‹ cite keys")
        except Exception as e:
            print(f"\nâŒ éŒ¯èª¤: ç„¡æ³•è¼‰å…¥ PDF ç´¢å¼•: {e}")
            sys.exit(1)

        # è§£æ BibTeX ç²å– cite keys
        try:
            with open(args.from_bibtex, 'r', encoding='utf-8') as f:
                bibtex_content = f.read()

            # æå– cite keys: @article{CiteKey,
            cite_keys = re.findall(r'@\w+\{([^,]+),', bibtex_content)
            cite_keys = [ck.strip() for ck in cite_keys if not ck.startswith('%')]
            print(f"   âœ… å¾ BibTeX æå–: {len(cite_keys)} å€‹ cite keys")
        except Exception as e:
            print(f"\nâŒ éŒ¯èª¤: ç„¡æ³•è®€å– BibTeX: {e}")
            sys.exit(1)

        # å¾ PDF index è§£æ PDF è·¯å¾‘
        pdf_paths = []
        missing_pdfs = []

        for cite_key in cite_keys:
            if cite_key in pdf_index:
                entry = pdf_index[cite_key]
                pdf_path = entry['full_path']

                # å¦‚æœæŒ‡å®šäº† pdf_base_dirï¼Œè¦†è“‹è·¯å¾‘
                if args.pdf_base_dir:
                    from pathlib import Path
                    pdf_path = str(Path(args.pdf_base_dir) / entry['filename'])

                pdf_paths.append(pdf_path)
            else:
                missing_pdfs.append(cite_key)

        if missing_pdfs:
            print(f"\nâš ï¸  è­¦å‘Š: {len(missing_pdfs)} å€‹ cite keys ç„¡æ³•è§£æ:")
            for ck in missing_pdfs[:5]:
                print(f"      - {ck}")
            if len(missing_pdfs) > 5:
                print(f"      ... å’Œ {len(missing_pdfs) - 5} å€‹å…¶ä»–")
            print()

        if not pdf_paths:
            print("\nâŒ éŒ¯èª¤: æ²’æœ‰å¯è™•ç†çš„ PDF æ–‡ä»¶")
            sys.exit(1)

        print(f"   âœ… è§£ææˆåŠŸ: {len(pdf_paths)}/{len(cite_keys)} PDFs")
        print()

    elif args.folder:
        pdf_paths = args.folder
        print(f"\nğŸ“ æƒæè³‡æ–™å¤¾: {args.folder}")
    else:
        pdf_paths = args.files
        print(f"\nğŸ“„ è™•ç†æ–‡ä»¶: {len(args.files)} å€‹")

    # Ensure Path is imported for report saving
    from pathlib import Path

    # æº–å‚™ Zettelkasten é…ç½®
    zettel_config = None
    if args.generate_zettel:
        zettel_config = {
            'detail_level': args.detail,
            'card_count': args.cards,
            'llm_provider': args.llm_provider,
            'model': args.model  # æ”¯æ´è‡ªè¨‚æ¨¡å‹åç¨±
        }

    # å‰µå»ºè™•ç†å™¨
    try:
        processor = BatchProcessor(
            max_workers=args.workers,
            error_handling=args.error_handling
        )
    except FileNotFoundError as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        print("   è«‹ç¢ºä¿åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œæ­¤è…³æœ¬")
        sys.exit(1)

    # åŸ·è¡Œæ‰¹æ¬¡è™•ç†
    try:
        result = processor.process_batch(
            pdf_paths=pdf_paths,
            domain=args.domain,
            add_to_kb=args.add_to_kb,
            generate_zettel=args.generate_zettel,
            zettel_config=zettel_config,
            progress_callback=None  # å¯é¸ï¼šæ·»åŠ é€²åº¦æ¢
        )

        # é¡¯ç¤ºå ±å‘Š
        print("\n")
        print(result.to_report())

        # ä¿å­˜å ±å‘Šï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.report:
            report_path = Path(args.report)

            # æ ¹æ“šå‰¯æª”åæ±ºå®šæ ¼å¼
            if report_path.suffix == '.json':
                content = result.to_json()
            else:
                content = result.to_report()

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)

            print(f"\nğŸ“„ å ±å‘Šå·²ä¿å­˜: {report_path}")

        # è©¢å•æ˜¯å¦æ•´ç†æ–‡ä»¶ï¼ˆåªåœ¨äº’å‹•å¼çµ‚ç«¯ï¼‰
        if result.success > 0 and sys.stdin.isatty():
            print("\n" + "="*60)
            try:
                cleanup_response = input("ğŸ“ æ˜¯å¦åŸ·è¡Œæª”æ¡ˆæ•´ç†ï¼Ÿ[Y/n] ")
                if cleanup_response.lower() != 'n':
                    print("\næ­£åœ¨æ•´ç†æ–‡ä»¶...")
                    from src.utils import SessionOrganizer
                    organizer = SessionOrganizer(dry_run=False, auto_backup=True)
                    cleanup_report = organizer.organize_session(session_type='batch')
                    report_path = organizer.save_report()
                    print(f"âœ… æ•´ç†å®Œæˆï¼å ±å‘Š: {report_path}")
            except KeyboardInterrupt:
                print("\n\nâš ï¸  å·²è·³éæª”æ¡ˆæ•´ç†")
        elif result.success > 0:
            print("\nğŸ’¡ æç¤º: è™•ç†å®Œæˆå¾Œå¯æ‰‹å‹•åŸ·è¡Œæª”æ¡ˆæ•´ç†ï¼š")
            print("   python cleanup_session.py --session batch --auto")

        # è¿”å›ç¢¼
        sys.exit(0 if result.failed == 0 else 1)

    except KeyboardInterrupt:
        print("\n\nâš ï¸  è™•ç†å·²ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
