# Task 1.3 å¯¦æ–½è¨ˆç•«ï¼šæ•´åˆ Zettelkasten åˆ°çŸ¥è­˜åº«

**æ–‡æª”ç‰ˆæœ¬**: v1.0
**å‰µå»ºæ—¥æœŸ**: 2025-10-30
**é è¨ˆå®Œæˆæ™‚é–“**: 2å¤©ï¼ˆ16å°æ™‚ï¼‰
**ç‹€æ…‹**: è¦åŠƒéšæ®µ â†’ å¯¦æ–½ä¸­
**è² è²¬æ¨¡çµ„**: `src/knowledge_base/kb_manager.py`

---

## ğŸ“‹ ç›®éŒ„

1. [ä»»å‹™æ¦‚è¿°](#ä»»å‹™æ¦‚è¿°)
2. [å·²å®ŒæˆåŸºç¤è¨­æ–½](#å·²å®ŒæˆåŸºç¤è¨­æ–½)
3. [è©³ç´°å¯¦æ–½æ­¥é©Ÿ](#è©³ç´°å¯¦æ–½æ­¥é©Ÿ)
4. [æ•¸æ“šçµæ§‹è¨­è¨ˆ](#æ•¸æ“šçµæ§‹è¨­è¨ˆ)
5. [å–®å…ƒæ¸¬è©¦æ¸…å–®](#å–®å…ƒæ¸¬è©¦æ¸…å–®)
6. [æ•´åˆæ¸¬è©¦è¨ˆç•«](#æ•´åˆæ¸¬è©¦è¨ˆç•«)
7. [é¢¨éšªç®¡ç†](#é¢¨éšªç®¡ç†)
8. [æ™‚é–“é ä¼°](#æ™‚é–“é ä¼°)

---

## ä»»å‹™æ¦‚è¿°

### ç›®æ¨™
å°‡ç¾æœ‰çš„ 660 å¼µ Zettelkasten åŸå­å¡ç‰‡ï¼ˆ33å€‹è³‡æ–™å¤¾ï¼‰ç´¢å¼•åˆ°çŸ¥è­˜åº«ï¼Œå¯¦ç¾è·¨è«–æ–‡æ¦‚å¿µæœç´¢å’ŒçŸ¥è­˜åœ–è­œæ§‹å»ºã€‚

### æˆåŠŸæŒ‡æ¨™
- âœ… 644 å¼µå¡ç‰‡æˆåŠŸç´¢å¼•åˆ°æ•¸æ“šåº«ï¼ˆ>95% æˆåŠŸç‡ï¼‰
- âœ… å¡ç‰‡èˆ‡è«–æ–‡æ­£ç¢ºé—œè¯ï¼ˆ>80% é—œè¯æˆåŠŸç‡ï¼‰
- âœ… è·¨è«–æ–‡æ¦‚å¿µæœç´¢å¯ç”¨ï¼ˆå¦‚ `kb.search_zettel("mental simulation")`ï¼‰
- âœ… FTS5 å…¨æ–‡æœç´¢æ•ˆèƒ½è‰¯å¥½ï¼ˆ<500ms éŸ¿æ‡‰æ™‚é–“ï¼‰
- âœ… CLI å‘½ä»¤å®Œæ•´å¯ç”¨

### ç•¶å‰ç‹€æ…‹ç¸½è¦½

| çµ„ä»¶ | ç‹€æ…‹ | å®Œæˆåº¦ |
|------|------|--------|
| æ•¸æ“šè¡¨çµæ§‹ | âœ… å®Œæˆ | 100% |
| BibTeX è§£æå™¨ | âœ… å®Œæˆ | 100% |
| Zotero æƒæå™¨ | âœ… å®Œæˆ | 100% |
| Papers è¡¨æ“´å±• | âœ… å®Œæˆ | 100% |
| Zettel æ•¸æ“šè¡¨ | âœ… å®Œæˆ | 100% |
| å¡ç‰‡è§£æå™¨ | âŒ å¾…å¯¦ä½œ | 0% |
| é€£çµè§£æå™¨ | âŒ å¾…å¯¦ä½œ | 0% |
| æ‰¹æ¬¡ç´¢å¼•å™¨ | âŒ å¾…å¯¦ä½œ | 0% |
| è«–æ–‡é—œè¯é‚è¼¯ | âŒ å¾…å¯¦ä½œ | 0% |
| FTS5 æœç´¢ | âŒ å¾…å¯¦ä½œ | 0% |
| CLI å‘½ä»¤ | âŒ å¾…å¯¦ä½œ | 0% |

---

## å·²å®ŒæˆåŸºç¤è¨­æ–½

### 1. æ•¸æ“šè¡¨çµæ§‹ âœ…

**`zettel_cards` è¡¨**ï¼ˆ17 æ¬„ä½ï¼‰ï¼š
```sql
CREATE TABLE zettel_cards (
    card_id INTEGER PRIMARY KEY AUTOINCREMENT,
    zettel_id TEXT NOT NULL UNIQUE,           -- å¦‚ "Linguistics-20251029-001"
    title TEXT NOT NULL,
    content TEXT NOT NULL,                     -- å®Œæ•´ Markdown å…§å®¹
    core_concept TEXT,                         -- æ ¸å¿ƒæ¦‚å¿µï¼ˆåŸæ–‡å¼•ç”¨ï¼‰
    description TEXT,                          -- èªªæ˜æ–‡å­—
    card_type TEXT DEFAULT 'concept',          -- concept/method/finding/question
    domain TEXT NOT NULL,                      -- CogSci/Linguistics/AI
    tags TEXT,                                 -- JSON é™£åˆ—å­—ä¸²
    paper_id INTEGER,                          -- é—œè¯è«–æ–‡ ID
    zettel_folder TEXT NOT NULL,               -- è³‡æ–™å¤¾è·¯å¾‘
    source_info TEXT,                          -- ä¾†æºè«–æ–‡ä¿¡æ¯
    file_path TEXT NOT NULL,                   -- å¡ç‰‡æ–‡ä»¶è·¯å¾‘
    ai_notes TEXT,                             -- AI Agent ç­†è¨˜
    human_notes TEXT,                          -- äººé¡ç­†è¨˜
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (paper_id) REFERENCES papers(id)
);
```

**`zettel_links` è¡¨**ï¼ˆ7 æ¬„ä½ï¼‰ï¼š
```sql
CREATE TABLE zettel_links (
    link_id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_card_id INTEGER NOT NULL,           -- ä¾†æºå¡ç‰‡ ID
    target_zettel_id TEXT NOT NULL,            -- ç›®æ¨™å¡ç‰‡ zettel_id
    relation_type TEXT NOT NULL,               -- åŸºæ–¼/å°å‘/ç›¸é—œ/å°æ¯”/ä¸Šä½/ä¸‹ä½
    context TEXT,                              -- é€£çµä¸Šä¸‹æ–‡
    is_cross_paper BOOLEAN DEFAULT FALSE,      -- æ˜¯å¦è·¨è«–æ–‡é€£çµ
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (source_card_id) REFERENCES zettel_cards(card_id)
);
```

**`zettel_cards_fts` å…¨æ–‡æœç´¢è¡¨**ï¼š
```sql
CREATE VIRTUAL TABLE zettel_cards_fts USING fts5(
    zettel_id, title, content, core_concept, description, tags, ai_notes,
    content=zettel_cards, content_rowid=card_id
);
```

### 2. æ•´åˆæ¨¡çµ„ âœ…

- **BibTeX è§£æå™¨**: `src/integrations/bibtex_parser.py`
  - å·²è§£æ 7245 å€‹ BibTeX æ¢ç›®
  - å…ƒæ•¸æ“šå®Œæ•´æ€§ï¼šå¹´ä»½ 97%ï¼ŒDOI 43.5%ï¼Œæ‘˜è¦ 44.2%

- **Zotero æƒæå™¨**: `src/integrations/zotero_scanner.py`
  - æƒæ 583 å€‹ PDF æ–‡ä»¶
  - åŒ¹é…ç‡ 78.2%ï¼ˆ456/583ï¼‰
  - ä¸»è¦é€é cite_key åŒ¹é…ï¼ˆ453 å€‹ï¼‰

### 3. æ•¸æ“šè³‡æº âœ…

- **Zettelkasten å¡ç‰‡**: 33 å€‹è³‡æ–™å¤¾ï¼Œ~660 å¼µå¡ç‰‡
- **BibTeX æ–‡ä»¶**: `D:\core\research\Program_verse\+\My Library.bib`
- **PDF æ–‡ä»¶**: 583 å€‹ PDFï¼ˆ`D:\core\research\Program_verse\+\pdf`ï¼‰

---

## è©³ç´°å¯¦æ–½æ­¥é©Ÿ

### **éšæ®µ 1ï¼šå¡ç‰‡è§£ææ ¸å¿ƒ** (4-5 å°æ™‚)

#### Task 1.1: å¯¦ä½œ `parse_zettel_card()` æ–¹æ³•

**åŠŸèƒ½æè¿°**ï¼šè§£æå–®å¼µ Zettelkasten Markdown å¡ç‰‡ï¼Œæå–æ‰€æœ‰çµæ§‹åŒ–ä¿¡æ¯ã€‚

**è¼¸å…¥**ï¼š
```python
file_path: str  # å¦‚ "output/.../zettel_cards/Linguistics-20251029-001.md"
```

**è¼¸å‡º**ï¼š
```python
ZettelCard = {
    'zettel_id': 'Linguistics-20251029-001',
    'title': 'Mass Noun (Mass Noun)',
    'content': '<å®Œæ•´ Markdown å…§å®¹>',
    'core_concept': '"I use mass noun interchangeably with..."',
    'description': 'Mass Nounï¼ˆä¸å¯æ•¸åè©ï¼‰èˆ‡ Non-Count Noun...',
    'card_type': 'concept',
    'domain': 'Linguistics',
    'tags': ['Mass Noun', 'Non-Count Noun', 'Common Noun'],
    'source_info': '"Chinese Classifiers and Count Nouns" (2025)',
    'file_path': '<çµ•å°è·¯å¾‘>',
    'ai_notes': '[AI Agent] é€™æ˜¯ä¸€å€‹é‡è¦çš„å®šç¾©...',
    'human_notes': '(TODO) <!-- è«‹åœ¨æ­¤è™•æ·»åŠ ... -->',
    'links': [  # é€£çµä¿¡æ¯ï¼ˆä¾›å¾ŒçºŒè™•ç†ï¼‰
        {
            'relation_type': 'å°å‘',
            'target_ids': ['Linguistics-20251029-002', 'Linguistics-20251029-003']
        }
    ]
}
```

**å¯¦ä½œç´°ç¯€**ï¼š

```python
import re
import yaml
from pathlib import Path
from typing import Dict, List, Optional

def parse_zettel_card(file_path: str) -> Optional[Dict]:
    """
    è§£æå–®å¼µ Zettelkasten å¡ç‰‡

    Returns:
        ZettelCard å­—å…¸ï¼Œè§£æå¤±æ•—è¿”å› None
    """
    try:
        # 1. è®€å–æ–‡ä»¶ï¼ˆUTF-8ï¼‰
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # 2. æå– YAML frontmatter
        yaml_match = re.match(r'^---\n(.*?)\n---\n(.*)$', content, re.DOTALL)
        if not yaml_match:
            raise ValueError(f"ç„¡æ•ˆçš„ Zettelkasten æ ¼å¼ï¼š{file_path}")

        yaml_content = yaml_match.group(1)
        markdown_content = yaml_match.group(2)

        # 3. è§£æ YAML
        metadata = yaml.safe_load(yaml_content)

        # 4. æå– Markdown å„å€å¡Š
        result = {
            'zettel_id': self._normalize_id(metadata.get('id', '')),
            'title': metadata.get('title', '').strip(),
            'content': content,  # å®Œæ•´å…§å®¹
            'card_type': metadata.get('type', 'concept'),
            'domain': self._extract_domain_from_id(metadata.get('id', '')),
            'tags': metadata.get('tags', []),
            'source_info': metadata.get('source', ''),
            'file_path': str(Path(file_path).resolve()),
            'created_at': metadata.get('created', None),
        }

        # 5. æå–æ ¸å¿ƒæ¦‚å¿µï¼ˆå¾ Markdown å…§å®¹ï¼‰
        core_match = re.search(r'> \*\*æ ¸å¿ƒ\*\*:\s*"(.+?)"', markdown_content, re.DOTALL)
        result['core_concept'] = core_match.group(1).strip() if core_match else None

        # 6. æå–èªªæ˜æ–‡å­—
        desc_match = re.search(r'## èªªæ˜\n(.+?)(?=\n##|\Z)', markdown_content, re.DOTALL)
        result['description'] = desc_match.group(1).strip() if desc_match else None

        # 7. æå– AI ç­†è¨˜
        ai_match = re.search(r'\*\*\[AI Agent\]\*\*:\s*(.+?)(?=\n\*\*\[Human\]|\n---|===|\Z)', markdown_content, re.DOTALL)
        result['ai_notes'] = ai_match.group(1).strip() if ai_match else None

        # 8. æå–äººé¡ç­†è¨˜
        human_match = re.search(r'\*\*\[Human\]\*\*:\s*(.+?)(?=\n---|===|\Z)', markdown_content, re.DOTALL)
        result['human_notes'] = human_match.group(1).strip() if human_match else None

        # 9. æå–é€£çµä¿¡æ¯ï¼ˆä¾›å¾ŒçºŒ parse_zettel_links ä½¿ç”¨ï¼‰
        result['links'] = self._extract_links_from_content(markdown_content)

        return result

    except Exception as e:
        self.logger.error(f"è§£æå¡ç‰‡å¤±æ•—ï¼š{file_path}, éŒ¯èª¤ï¼š{e}")
        return None

def _normalize_id(self, zettel_id: str) -> str:
    """
    æ­£è¦åŒ– Zettel ID æ ¼å¼

    ä¿®å¾©éŒ¯èª¤æ ¼å¼ï¼š
    - CogSci20251028001 â†’ CogSci-20251028-001
    - AI_20251029_005 â†’ AI-20251029-005
    """
    # ç§»é™¤åº•ç·šå’Œå¤šé¤˜ç©ºç™½
    zettel_id = zettel_id.replace('_', '-').strip()

    # æ­£å‰‡è¡¨é”å¼åŒ¹é…ä¸¦é‡çµ„
    match = re.match(r'^([A-Za-z]+)[-]?(\d{8})[-]?(\d{3})$', zettel_id)
    if match:
        domain, date, num = match.groups()
        return f"{domain}-{date}-{num}"
    else:
        # ç„¡æ³•ä¿®å¾©ï¼Œè¨˜éŒ„è­¦å‘Š
        self.logger.warning(f"ç„¡æ³•æ­£è¦åŒ– IDï¼š{zettel_id}")
        return zettel_id

def _extract_domain_from_id(self, zettel_id: str) -> str:
    """å¾ ID æå–é ˜åŸŸä»£ç¢¼"""
    match = re.match(r'^([A-Za-z]+)-', zettel_id)
    return match.group(1) if match else 'Unknown'

def _extract_links_from_content(self, markdown: str) -> List[Dict]:
    """
    æå–é€£çµç¶²çµ¡å€å¡Šçš„æ‰€æœ‰é€£çµ

    ç¯„ä¾‹è¼¸å…¥ï¼š
    ## é€£çµç¶²çµ¡
    **å°å‘** â†’ [[Linguistics-20251029-002]], [[Linguistics-20251029-003]]
    **åŸºæ–¼** â†’ [[Linguistics-20251029-001]]

    è¿”å›ï¼š
    [
        {'relation_type': 'å°å‘', 'target_ids': ['Linguistics-20251029-002', ...]},
        {'relation_type': 'åŸºæ–¼', 'target_ids': ['Linguistics-20251029-001']}
    ]
    """
    links = []

    # æå–ã€Œé€£çµç¶²çµ¡ã€å€å¡Š
    network_match = re.search(r'## é€£çµç¶²çµ¡\n(.+?)(?=\n##|\Z)', markdown, re.DOTALL)
    if not network_match:
        return links

    network_text = network_match.group(1)

    # åŒ¹é…æ¯ä¸€è¡Œé€£çµ
    # æ ¼å¼ï¼š**é—œä¿‚é¡å‹** â†’ [[ID1]], [[ID2]]
    link_pattern = r'\*\*(åŸºæ–¼|å°å‘|ç›¸é—œ|å°æ¯”|ä¸Šä½|ä¸‹ä½)\*\*\s*â†’\s*(.+?)(?=\n|$)'

    for match in re.finditer(link_pattern, network_text):
        relation_type = match.group(1)
        target_text = match.group(2)

        # æå–æ‰€æœ‰ç›®æ¨™ ID
        target_ids = re.findall(r'\[\[([A-Za-z]+-\d{8}-\d{3})\]\]', target_text)

        if target_ids:
            links.append({
                'relation_type': relation_type,
                'target_ids': target_ids
            })

    return links
```

**å–®å…ƒæ¸¬è©¦**ï¼šè¦‹ [å–®å…ƒæ¸¬è©¦æ¸…å–®](#å–®å…ƒæ¸¬è©¦æ¸…å–®) - Test Suite 1

---

#### Task 1.2: å¯¦ä½œ `parse_zettel_links()` æ–¹æ³•

**åŠŸèƒ½æè¿°**ï¼šå°‡å¡ç‰‡è§£æçµæœä¸­çš„é€£çµä¿¡æ¯æ’å…¥ `zettel_links` è¡¨ã€‚

**è¼¸å…¥**ï¼š
```python
card_data: Dict        # parse_zettel_card() çš„è¼¸å‡º
source_card_id: int    # å·²æ’å…¥ zettel_cards çš„ card_id
```

**è¼¸å‡º**ï¼š
```python
List[int]  # æ’å…¥çš„ link_id åˆ—è¡¨
```

**å¯¦ä½œç´°ç¯€**ï¼š

```python
def parse_zettel_links(
    self,
    card_data: Dict,
    source_card_id: int
) -> List[int]:
    """
    è§£æä¸¦æ’å…¥å¡ç‰‡é€£çµåˆ°æ•¸æ“šåº«

    Args:
        card_data: å¡ç‰‡è§£æçµæœï¼ˆåŒ…å« 'links' æ¬„ä½ï¼‰
        source_card_id: ä¾†æºå¡ç‰‡çš„ card_id

    Returns:
        æ’å…¥çš„ link_id åˆ—è¡¨
    """
    inserted_ids = []

    if 'links' not in card_data or not card_data['links']:
        return inserted_ids

    cursor = self.conn.cursor()

    for link_group in card_data['links']:
        relation_type = link_group['relation_type']
        target_ids = link_group['target_ids']

        for target_id in target_ids:
            try:
                # æª¢æŸ¥ç›®æ¨™å¡ç‰‡æ˜¯å¦å­˜åœ¨
                cursor.execute(
                    'SELECT card_id, domain FROM zettel_cards WHERE zettel_id = ?',
                    (target_id,)
                )
                target_row = cursor.fetchone()

                # åˆ¤æ–·æ˜¯å¦è·¨è«–æ–‡é€£çµ
                is_cross_paper = False
                if target_row:
                    target_domain = target_row[1]
                    source_domain = card_data.get('domain', '')
                    # ç°¡åŒ–åˆ¤æ–·ï¼šdomain ä¸åŒè¦–ç‚ºè·¨è«–æ–‡ï¼ˆå¯¦éš›å¯èƒ½éœ€è¦æ›´ç²¾ç¢ºé‚è¼¯ï¼‰
                    is_cross_paper = (target_domain != source_domain)

                # æ’å…¥é€£çµ
                cursor.execute('''
                    INSERT INTO zettel_links
                    (source_card_id, target_zettel_id, relation_type, is_cross_paper)
                    VALUES (?, ?, ?, ?)
                ''', (source_card_id, target_id, relation_type, is_cross_paper))

                inserted_ids.append(cursor.lastrowid)

            except sqlite3.Error as e:
                self.logger.warning(f"æ’å…¥é€£çµå¤±æ•—ï¼š{source_card_id} â†’ {target_id}, éŒ¯èª¤ï¼š{e}")
                continue

    self.conn.commit()
    return inserted_ids
```

**å–®å…ƒæ¸¬è©¦**ï¼šè¦‹ [å–®å…ƒæ¸¬è©¦æ¸…å–®](#å–®å…ƒæ¸¬è©¦æ¸…å–®) - Test Suite 2

---

### **éšæ®µ 2ï¼šæ‰¹æ¬¡ç´¢å¼•å™¨** (3-4 å°æ™‚)

#### Task 2.1: å¯¦ä½œ `index_zettelkasten()` æ–¹æ³•

**åŠŸèƒ½æè¿°**ï¼šæƒæ Zettelkasten è³‡æ–™å¤¾ï¼Œæ‰¹æ¬¡ç´¢å¼•æ‰€æœ‰å¡ç‰‡åˆ°æ•¸æ“šåº«ã€‚

**è¼¸å…¥**ï¼š
```python
zettel_dirs: List[str]  # è³‡æ–™å¤¾è·¯å¾‘åˆ—è¡¨ï¼Œæˆ–å–®å€‹æ ¹ç›®éŒ„
update_existing: bool = False  # æ˜¯å¦æ›´æ–°å·²å­˜åœ¨çš„å¡ç‰‡
link_to_papers: bool = True    # æ˜¯å¦å»ºç«‹è«–æ–‡é—œè¯
progress_callback: callable = None  # é€²åº¦å›èª¿
```

**è¼¸å‡º**ï¼š
```python
IndexResult = {
    'total_folders': int,
    'total_cards': int,
    'success': int,
    'failed': int,
    'skipped': int,  # å·²å­˜åœ¨ä¸”æœªæ›´æ–°
    'links_created': int,
    'papers_linked': int,
    'errors': List[Dict],
    'processing_time': str
}
```

**å¯¦ä½œç´°ç¯€**ï¼š

```python
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Callable, Optional
import time

def index_zettelkasten(
    self,
    zettel_dirs: List[str] | str,
    update_existing: bool = False,
    link_to_papers: bool = True,
    progress_callback: Optional[Callable] = None
) -> Dict:
    """
    æ‰¹æ¬¡ç´¢å¼• Zettelkasten å¡ç‰‡

    å·¥ä½œæµç¨‹ï¼š
    1. æƒææ‰€æœ‰ zettel_cards/*.md æ–‡ä»¶
    2. è§£ææ¯å¼µå¡ç‰‡ï¼ˆparse_zettel_cardï¼‰
    3. æ’å…¥æˆ–æ›´æ–° zettel_cards è¡¨
    4. å»ºç«‹å¡ç‰‡é€£çµï¼ˆparse_zettel_linksï¼‰
    5. ï¼ˆå¯é¸ï¼‰é—œè¯è«–æ–‡ï¼ˆlink_card_to_paperï¼‰
    6. æ›´æ–° FTS5 å…¨æ–‡æœç´¢ç´¢å¼•
    """
    start_time = time.time()

    # 1. æ­£è¦åŒ–è¼¸å…¥è·¯å¾‘
    if isinstance(zettel_dirs, str):
        zettel_dirs = [zettel_dirs]

    # 2. æƒææ‰€æœ‰å¡ç‰‡æ–‡ä»¶
    all_card_files = []
    for dir_path in zettel_dirs:
        folder = Path(dir_path)
        if not folder.exists():
            self.logger.warning(f"è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{dir_path}")
            continue

        # æƒæ zettel_cards/*.md
        card_files = list(folder.glob('zettel_cards/*.md'))
        all_card_files.extend(card_files)

    total_cards = len(all_card_files)
    self.logger.info(f"ç™¼ç¾ {total_cards} å¼µå¡ç‰‡ï¼Œé–‹å§‹ç´¢å¼•...")

    # 3. åˆå§‹åŒ–çµ±è¨ˆ
    result = {
        'total_folders': len(zettel_dirs),
        'total_cards': total_cards,
        'success': 0,
        'failed': 0,
        'skipped': 0,
        'links_created': 0,
        'papers_linked': 0,
        'errors': [],
        'processing_time': ''
    }

    # 4. é€å€‹è™•ç†å¡ç‰‡
    cursor = self.conn.cursor()

    for idx, card_file in enumerate(all_card_files, 1):
        try:
            # é€²åº¦å›èª¿
            if progress_callback:
                progress_callback(idx, total_cards, str(card_file.name))

            # 4.1 è§£æå¡ç‰‡
            card_data = self.parse_zettel_card(str(card_file))
            if not card_data:
                result['failed'] += 1
                result['errors'].append({
                    'file': str(card_file),
                    'error': 'è§£æå¤±æ•—'
                })
                continue

            zettel_id = card_data['zettel_id']

            # 4.2 æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            cursor.execute('SELECT card_id FROM zettel_cards WHERE zettel_id = ?', (zettel_id,))
            existing = cursor.fetchone()

            if existing and not update_existing:
                result['skipped'] += 1
                continue

            # 4.3 æ’å…¥æˆ–æ›´æ–°å¡ç‰‡
            if existing:
                card_id = existing[0]
                self._update_zettel_card(card_id, card_data)
            else:
                card_id = self._insert_zettel_card(card_data)

            # 4.4 å»ºç«‹é€£çµ
            link_ids = self.parse_zettel_links(card_data, card_id)
            result['links_created'] += len(link_ids)

            # 4.5ï¼ˆå¯é¸ï¼‰é—œè¯è«–æ–‡
            if link_to_papers:
                paper_id = self._link_card_to_paper(card_data, card_id)
                if paper_id:
                    result['papers_linked'] += 1

            result['success'] += 1

        except Exception as e:
            result['failed'] += 1
            result['errors'].append({
                'file': str(card_file),
                'error': str(e)
            })
            self.logger.error(f"è™•ç†å¡ç‰‡å¤±æ•—ï¼š{card_file}, éŒ¯èª¤ï¼š{e}")
            continue

    # 5. æ›´æ–° FTS5 ç´¢å¼•
    try:
        self._rebuild_zettel_fts_index()
    except Exception as e:
        self.logger.warning(f"FTS5 ç´¢å¼•æ›´æ–°å¤±æ•—ï¼š{e}")

    # 6. ç”Ÿæˆå ±å‘Š
    elapsed = time.time() - start_time
    result['processing_time'] = f"{elapsed:.2f}s"

    self.logger.info(
        f"ç´¢å¼•å®Œæˆï¼šæˆåŠŸ {result['success']}/{total_cards}, "
        f"å¤±æ•— {result['failed']}, è·³é {result['skipped']}, "
        f"è€—æ™‚ {result['processing_time']}"
    )

    return result

def _insert_zettel_card(self, card_data: Dict) -> int:
    """æ’å…¥æ–°å¡ç‰‡"""
    cursor = self.conn.cursor()

    cursor.execute('''
        INSERT INTO zettel_cards (
            zettel_id, title, content, core_concept, description,
            card_type, domain, tags, zettel_folder, source_info,
            file_path, ai_notes, human_notes
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        card_data['zettel_id'],
        card_data['title'],
        card_data['content'],
        card_data.get('core_concept'),
        card_data.get('description'),
        card_data.get('card_type', 'concept'),
        card_data['domain'],
        json.dumps(card_data.get('tags', []), ensure_ascii=False),
        str(Path(card_data['file_path']).parent.parent),  # zettel_folder
        card_data.get('source_info'),
        card_data['file_path'],
        card_data.get('ai_notes'),
        card_data.get('human_notes')
    ))

    self.conn.commit()
    return cursor.lastrowid

def _update_zettel_card(self, card_id: int, card_data: Dict):
    """æ›´æ–°å·²å­˜åœ¨çš„å¡ç‰‡"""
    cursor = self.conn.cursor()

    cursor.execute('''
        UPDATE zettel_cards SET
            title = ?, content = ?, core_concept = ?, description = ?,
            card_type = ?, tags = ?, source_info = ?, file_path = ?,
            ai_notes = ?, human_notes = ?, updated_at = CURRENT_TIMESTAMP
        WHERE card_id = ?
    ''', (
        card_data['title'],
        card_data['content'],
        card_data.get('core_concept'),
        card_data.get('description'),
        card_data.get('card_type', 'concept'),
        json.dumps(card_data.get('tags', []), ensure_ascii=False),
        card_data.get('source_info'),
        card_data['file_path'],
        card_data.get('ai_notes'),
        card_data.get('human_notes'),
        card_id
    ))

    self.conn.commit()

def _rebuild_zettel_fts_index(self):
    """é‡å»º FTS5 å…¨æ–‡æœç´¢ç´¢å¼•"""
    cursor = self.conn.cursor()

    # æ¸…ç©º FTS5 è¡¨
    cursor.execute('DELETE FROM zettel_cards_fts')

    # å¾ zettel_cards é‡æ–°æ’å…¥
    cursor.execute('''
        INSERT INTO zettel_cards_fts (
            rowid, zettel_id, title, content, core_concept, description, tags, ai_notes
        )
        SELECT card_id, zettel_id, title, content, core_concept, description, tags, ai_notes
        FROM zettel_cards
    ''')

    self.conn.commit()
    self.logger.info("FTS5 ç´¢å¼•é‡å»ºå®Œæˆ")
```

**å–®å…ƒæ¸¬è©¦**ï¼šè¦‹ [å–®å…ƒæ¸¬è©¦æ¸…å–®](#å–®å…ƒæ¸¬è©¦æ¸…å–®) - Test Suite 3

---

### **éšæ®µ 3ï¼šè«–æ–‡é—œè¯** (2-3 å°æ™‚)

#### Task 3.1: å¯¦ä½œ `_link_card_to_paper()` æ–¹æ³•

**åŠŸèƒ½æè¿°**ï¼šæ ¹æ“šå¡ç‰‡çš„ `source_info` åŒ¹é…çŸ¥è­˜åº«è«–æ–‡ï¼Œå»ºç«‹é—œè¯ã€‚

**å¯¦ä½œç´°ç¯€**ï¼š

```python
def _link_card_to_paper(self, card_data: Dict, card_id: int) -> Optional[int]:
    """
    å°‡å¡ç‰‡é—œè¯åˆ°è«–æ–‡

    åŒ¹é…ç­–ç•¥ï¼š
    1. å„ªå…ˆä½¿ç”¨ Zotero cite_keyï¼ˆå¾ source_info æå–ï¼‰
    2. æ¨¡ç³ŠåŒ¹é…è«–æ–‡æ¨™é¡Œ
    3. åŒ¹é…ä½œè€… + å¹´ä»½çµ„åˆ

    Returns:
        paper_idï¼ˆæˆåŠŸï¼‰æˆ– Noneï¼ˆå¤±æ•—ï¼‰
    """
    source_info = card_data.get('source_info', '')
    if not source_info:
        return None

    cursor = self.conn.cursor()

    # ç­–ç•¥ 1ï¼šå¾ source_info æå–å¯èƒ½çš„ cite_key
    # æ ¼å¼ç¯„ä¾‹ï¼š"Chinese Classifiers and Count Nouns" (2025)
    #            â†’ æŸ¥æ‰¾ zotero_key æˆ– title åŒ¹é…

    # æå–æ¨™é¡Œå’Œå¹´ä»½
    title_match = re.match(r'"(.+?)"\s*\((\d{4})\)', source_info)
    if title_match:
        title = title_match.group(1)
        year = int(title_match.group(2))

        # å˜—è©¦æ¨™é¡Œæ¨¡ç³ŠåŒ¹é…ï¼ˆä½¿ç”¨ LIKEï¼‰
        cursor.execute('''
            SELECT id FROM papers
            WHERE title LIKE ? AND (year = ? OR year IS NULL)
            LIMIT 1
        ''', (f'%{title}%', year))

        result = cursor.fetchone()
        if result:
            paper_id = result[0]

            # æ›´æ–° zettel_cards çš„ paper_id
            cursor.execute(
                'UPDATE zettel_cards SET paper_id = ? WHERE card_id = ?',
                (paper_id, card_id)
            )
            self.conn.commit()

            return paper_id

    # ç­–ç•¥ 2ï¼šä½¿ç”¨ zettel_folder åç¨±åŒ¹é…
    # æ ¼å¼ï¼šzettel_Her2012a_20251029 â†’ cite_key: Her2012a
    folder_name = Path(card_data['file_path']).parent.parent.name
    cite_key_match = re.search(r'zettel_([A-Za-z]+\d{4}[a-z]?)_', folder_name)

    if cite_key_match:
        cite_key = cite_key_match.group(1)

        cursor.execute(
            'SELECT id FROM papers WHERE zotero_key = ? LIMIT 1',
            (cite_key,)
        )
        result = cursor.fetchone()
        if result:
            paper_id = result[0]
            cursor.execute(
                'UPDATE zettel_cards SET paper_id = ? WHERE card_id = ?',
                (paper_id, card_id)
            )
            self.conn.commit()
            return paper_id

    # ç„¡æ³•åŒ¹é…
    self.logger.debug(f"ç„¡æ³•åŒ¹é…è«–æ–‡ï¼š{source_info}")
    return None
```

#### Task 3.2: å¯¦ä½œè«–æ–‡å…ƒæ•¸æ“šå¢å¼·

**åŠŸèƒ½æè¿°**ï¼šå¾ BibTeX è£œå……ç¼ºå¤±çš„è«–æ–‡å…ƒæ•¸æ“šï¼ˆå¹´ä»½ã€DOIã€æ‘˜è¦ï¼‰ã€‚

```python
def enrich_paper_metadata_from_bibtex(
    self,
    bib_file: str = None
) -> Dict:
    """
    å¾ BibTeX å¢å¼·è«–æ–‡å…ƒæ•¸æ“š

    Args:
        bib_file: BibTeX æ–‡ä»¶è·¯å¾‘ï¼ˆé»˜èªä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾‘ï¼‰

    Returns:
        {
            'total_papers': int,
            'enriched': int,
            'fields_updated': {'year': int, 'doi': int, 'abstract': int}
        }
    """
    if bib_file is None:
        bib_file = "D:\\core\\research\\Program_verse\\+\\My Library.bib"

    # ä½¿ç”¨å·²æœ‰çš„ BibTeXParser
    from integrations.bibtex_parser import BibTeXParser
    parser = BibTeXParser(bib_file)
    entries = parser.parse()  # 7245 å€‹æ¢ç›®

    cursor = self.conn.cursor()
    cursor.execute('SELECT id, title, zotero_key, year, doi FROM papers')
    papers = cursor.fetchall()

    result = {
        'total_papers': len(papers),
        'enriched': 0,
        'fields_updated': {'year': 0, 'doi': 0, 'abstract': 0, 'url': 0}
    }

    for paper in papers:
        paper_id, title, zotero_key, current_year, current_doi = paper
        updated = False

        # æŸ¥æ‰¾å°æ‡‰çš„ BibTeX æ¢ç›®
        bib_entry = None
        if zotero_key:
            bib_entry = next((e for e in entries if e.get('ID') == zotero_key), None)

        if not bib_entry and title:
            # æ¨¡ç³ŠåŒ¹é…æ¨™é¡Œ
            bib_entry = next((e for e in entries if title.lower() in e.get('title', '').lower()), None)

        if bib_entry:
            # æ›´æ–°ç¼ºå¤±æ¬„ä½
            updates = []
            values = []

            if not current_year and bib_entry.get('year'):
                updates.append('year = ?')
                values.append(int(bib_entry['year']))
                result['fields_updated']['year'] += 1
                updated = True

            if not current_doi and bib_entry.get('doi'):
                updates.append('doi = ?')
                values.append(bib_entry['doi'])
                result['fields_updated']['doi'] += 1
                updated = True

            if bib_entry.get('abstract'):
                updates.append('abstract = ?')  # å‡è¨­ papers è¡¨æœ‰ abstract æ¬„ä½
                values.append(bib_entry['abstract'])
                result['fields_updated']['abstract'] += 1
                updated = True

            if bib_entry.get('url'):
                updates.append('url = ?')
                values.append(bib_entry['url'])
                result['fields_updated']['url'] += 1
                updated = True

            if updated:
                values.append(paper_id)
                cursor.execute(
                    f"UPDATE papers SET {', '.join(updates)} WHERE id = ?",
                    values
                )
                result['enriched'] += 1

    self.conn.commit()
    self.logger.info(
        f"å…ƒæ•¸æ“šå¢å¼·å®Œæˆï¼š{result['enriched']}/{result['total_papers']} ç¯‡è«–æ–‡æ›´æ–°"
    )

    return result
```

**å–®å…ƒæ¸¬è©¦**ï¼šè¦‹ [å–®å…ƒæ¸¬è©¦æ¸…å–®](#å–®å…ƒæ¸¬è©¦æ¸…å–®) - Test Suite 4

---

### **éšæ®µ 4ï¼šæœç´¢èˆ‡æŸ¥è©¢** (2-3 å°æ™‚)

#### Task 4.1: å¯¦ä½œ `search_zettel()` æ–¹æ³•

**åŠŸèƒ½æè¿°**ï¼šä½¿ç”¨ FTS5 å…¨æ–‡æœç´¢æŸ¥è©¢ Zettelkasten å¡ç‰‡ã€‚

**è¼¸å…¥**ï¼š
```python
query: str                # æœç´¢é—œéµè©ï¼ˆæ”¯æ´ FTS5 èªæ³•ï¼‰
filters: Dict = None      # éæ¿¾æ¢ä»¶
limit: int = 20           # çµæœæ•¸é‡
include_content: bool = False  # æ˜¯å¦è¿”å›å®Œæ•´å…§å®¹
```

**è¼¸å‡º**ï¼š
```python
List[ZettelSearchResult] = [
    {
        'card_id': int,
        'zettel_id': str,
        'title': str,
        'core_concept': str,
        'snippet': str,        # æœç´¢æ‘˜è¦ï¼ˆé«˜äº®ï¼‰
        'domain': str,
        'tags': List[str],
        'paper_id': int,
        'paper_title': str,    # é—œè¯è«–æ–‡æ¨™é¡Œ
        'rank': float,         # ç›¸é—œæ€§åˆ†æ•¸
        'content': str         # å®Œæ•´å…§å®¹ï¼ˆå¯é¸ï¼‰
    }
]
```

**å¯¦ä½œç´°ç¯€**ï¼š

```python
def search_zettel(
    self,
    query: str,
    filters: Dict = None,
    limit: int = 20,
    include_content: bool = False
) -> List[Dict]:
    """
    å…¨æ–‡æœç´¢ Zettelkasten å¡ç‰‡

    Args:
        query: æœç´¢è©ï¼ˆFTS5 èªæ³•ï¼Œå¦‚ "mental simulation" æˆ– "mental AND simulation"ï¼‰
        filters: éæ¿¾æ¢ä»¶ï¼Œå¯é¸ï¼š
            - domain: str (CogSci/Linguistics)
            - tags: List[str]
            - paper_id: int
            - card_type: str
        limit: æœ€å¤šè¿”å›çµæœæ•¸
        include_content: æ˜¯å¦åŒ…å«å®Œæ•´ Markdown å…§å®¹

    Returns:
        æœç´¢çµæœåˆ—è¡¨ï¼ˆæŒ‰ç›¸é—œæ€§æ’åºï¼‰

    ç¯„ä¾‹ï¼š
        results = kb.search_zettel("mental simulation", filters={'domain': 'CogSci'})
    """
    filters = filters or {}

    # 1. æ§‹å»º FTS5 æŸ¥è©¢
    cursor = self.conn.cursor()

    # åŸºç¤ FTS5 æŸ¥è©¢
    base_query = '''
        SELECT
            zc.card_id,
            zc.zettel_id,
            zc.title,
            zc.core_concept,
            snippet(zettel_cards_fts, 2, '<mark>', '</mark>', '...', 30) as snippet,
            zc.domain,
            zc.tags,
            zc.paper_id,
            p.title as paper_title,
            zf.rank
    '''

    if include_content:
        base_query += ', zc.content'

    base_query += '''
        FROM zettel_cards_fts zf
        JOIN zettel_cards zc ON zf.rowid = zc.card_id
        LEFT JOIN papers p ON zc.paper_id = p.id
        WHERE zettel_cards_fts MATCH ?
    '''

    # 2. æ·»åŠ éæ¿¾æ¢ä»¶
    conditions = []
    params = [query]

    if filters.get('domain'):
        conditions.append('zc.domain = ?')
        params.append(filters['domain'])

    if filters.get('card_type'):
        conditions.append('zc.card_type = ?')
        params.append(filters['card_type'])

    if filters.get('paper_id'):
        conditions.append('zc.paper_id = ?')
        params.append(filters['paper_id'])

    if filters.get('tags'):
        # JSON é™£åˆ—æŸ¥è©¢ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        tag_conditions = ' OR '.join(['zc.tags LIKE ?' for _ in filters['tags']])
        conditions.append(f'({tag_conditions})')
        params.extend([f'%{tag}%' for tag in filters['tags']])

    if conditions:
        base_query += ' AND ' + ' AND '.join(conditions)

    # 3. æ’åºå’Œé™åˆ¶
    base_query += ' ORDER BY zf.rank LIMIT ?'
    params.append(limit)

    # 4. åŸ·è¡ŒæŸ¥è©¢
    cursor.execute(base_query, params)
    rows = cursor.fetchall()

    # 5. æ ¼å¼åŒ–çµæœ
    results = []
    for row in rows:
        result = {
            'card_id': row[0],
            'zettel_id': row[1],
            'title': row[2],
            'core_concept': row[3],
            'snippet': row[4],
            'domain': row[5],
            'tags': json.loads(row[6]) if row[6] else [],
            'paper_id': row[7],
            'paper_title': row[8],
            'rank': row[9]
        }

        if include_content:
            result['content'] = row[10]

        results.append(result)

    self.logger.info(f"æœç´¢ '{query}' æ‰¾åˆ° {len(results)} å€‹çµæœ")
    return results

def get_related_zettel(
    self,
    zettel_id: str,
    max_depth: int = 2,
    relation_types: List[str] = None
) -> Dict:
    """
    ç²å–ç›¸é—œå¡ç‰‡ç¶²çµ¡ï¼ˆåŸºæ–¼é€£çµï¼‰

    Args:
        zettel_id: èµ·å§‹å¡ç‰‡ ID
        max_depth: æœ€å¤§é€£çµæ·±åº¦ï¼ˆ1=ç›´æ¥é€£çµ, 2=äºŒéšé€£çµï¼‰
        relation_types: é™å®šé€£çµé¡å‹ï¼ˆé»˜èªå…¨éƒ¨ï¼‰

    Returns:
        {
            'center': ZettelCard,
            'related': List[ZettelCard],
            'links': List[ZettelLink],
            'graph': NetworkX Graphï¼ˆå¯é¸ï¼‰
        }
    """
    # TODO: å¯¦ä½œåœ–è«–éæ­·æ¼”ç®—æ³•ï¼ˆBFS/DFSï¼‰
    pass
```

**å–®å…ƒæ¸¬è©¦**ï¼šè¦‹ [å–®å…ƒæ¸¬è©¦æ¸…å–®](#å–®å…ƒæ¸¬è©¦æ¸…å–®) - Test Suite 5

---

### **éšæ®µ 5ï¼šCLI å·¥å…·** (1-2 å°æ™‚)

#### Task 5.1: æ“´å±• `kb_manage.py`

æ–°å¢ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# 1. ç´¢å¼• Zettelkasten
python kb_manage.py index-zettel \
  --zettel-dir "output/zettelkasten_notes" \
  --update-existing \
  --link-papers \
  --report index_report.json

# 2. åŒæ­¥ Zotero å…ƒæ•¸æ“š
python kb_manage.py sync-zotero \
  --bib-file "D:\core\research\Program_verse\+\My Library.bib" \
  --pdf-dir "D:\core\research\Program_verse\+\pdf" \
  --enrich-metadata

# 3. æœç´¢ Zettelkasten
python kb_manage.py search-zettel \
  --query "mental simulation" \
  --domain CogSci \
  --limit 10 \
  --format table

# 4. ç”Ÿæˆæ¦‚å¿µç¶²çµ¡åœ–
python kb_manage.py concept-network \
  --zettel-id "CogSci-20251029-001" \
  --depth 2 \
  --output concept_network.html
```

**å¯¦ä½œç¯„ä¾‹**ï¼ˆkb_manage.py ç‰‡æ®µï¼‰ï¼š

```python
import argparse
from src.knowledge_base import KnowledgeBaseManager

def cmd_index_zettel(args):
    """ç´¢å¼• Zettelkasten å‘½ä»¤"""
    kb = KnowledgeBaseManager()

    # é€²åº¦å›èª¿
    def progress(current, total, filename):
        print(f"\r[{current}/{total}] è™•ç†ä¸­: {filename}", end='', flush=True)

    result = kb.index_zettelkasten(
        zettel_dirs=args.zettel_dir,
        update_existing=args.update_existing,
        link_to_papers=args.link_papers,
        progress_callback=progress if not args.quiet else None
    )

    print(f"\n\nâœ… ç´¢å¼•å®Œæˆ!")
    print(f"   æˆåŠŸ: {result['success']}/{result['total_cards']}")
    print(f"   å¤±æ•—: {result['failed']}")
    print(f"   è·³é: {result['skipped']}")
    print(f"   é€£çµ: {result['links_created']}")
    print(f"   è«–æ–‡é—œè¯: {result['papers_linked']}")
    print(f"   è€—æ™‚: {result['processing_time']}")

    if args.report:
        import json
        with open(args.report, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"   å ±å‘Š: {args.report}")

def cmd_search_zettel(args):
    """æœç´¢ Zettelkasten å‘½ä»¤"""
    kb = KnowledgeBaseManager()

    filters = {}
    if args.domain:
        filters['domain'] = args.domain
    if args.tags:
        filters['tags'] = args.tags.split(',')

    results = kb.search_zettel(
        query=args.query,
        filters=filters,
        limit=args.limit
    )

    if args.format == 'json':
        import json
        print(json.dumps(results, ensure_ascii=False, indent=2))
    else:
        # è¡¨æ ¼è¼¸å‡º
        from tabulate import tabulate
        table = [
            [r['zettel_id'], r['title'][:50], r['domain'], r['paper_title'][:30] if r['paper_title'] else '-']
            for r in results
        ]
        print(tabulate(table, headers=['ID', 'æ¨™é¡Œ', 'é ˜åŸŸ', 'è«–æ–‡'], tablefmt='grid'))

# ä¸»ç¨‹å¼
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='çŸ¥è­˜åº«ç®¡ç†å·¥å…·')
    subparsers = parser.add_subparsers(dest='command', help='å‘½ä»¤')

    # index-zettel å­å‘½ä»¤
    parser_index = subparsers.add_parser('index-zettel', help='ç´¢å¼• Zettelkasten å¡ç‰‡')
    parser_index.add_argument('--zettel-dir', required=True, help='Zettelkasten æ ¹ç›®éŒ„')
    parser_index.add_argument('--update-existing', action='store_true', help='æ›´æ–°å·²å­˜åœ¨çš„å¡ç‰‡')
    parser_index.add_argument('--link-papers', action='store_true', default=True, help='å»ºç«‹è«–æ–‡é—œè¯')
    parser_index.add_argument('--report', help='è¼¸å‡ºå ±å‘Šè·¯å¾‘ (JSON)')
    parser_index.add_argument('--quiet', action='store_true', help='éœé»˜æ¨¡å¼')
    parser_index.set_defaults(func=cmd_index_zettel)

    # search-zettel å­å‘½ä»¤
    parser_search = subparsers.add_parser('search-zettel', help='æœç´¢ Zettelkasten')
    parser_search.add_argument('--query', required=True, help='æœç´¢é—œéµè©')
    parser_search.add_argument('--domain', help='é™å®šé ˜åŸŸ (CogSci/Linguistics)')
    parser_search.add_argument('--tags', help='æ¨™ç±¤éæ¿¾ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    parser_search.add_argument('--limit', type=int, default=20, help='çµæœæ•¸é‡')
    parser_search.add_argument('--format', choices=['table', 'json'], default='table', help='è¼¸å‡ºæ ¼å¼')
    parser_search.set_defaults(func=cmd_search_zettel)

    # ... å…¶ä»–å­å‘½ä»¤

    args = parser.parse_args()
    if hasattr(args, 'func'):
        args.func(args)
    else:
        parser.print_help()
```

---

## æ•¸æ“šçµæ§‹è¨­è¨ˆ

### æ ¸å¿ƒé¡åˆ¥å®šç¾©

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime

@dataclass
class ZettelCard:
    """Zettelkasten å¡ç‰‡æ•¸æ“šé¡"""
    card_id: Optional[int] = None
    zettel_id: str = ''
    title: str = ''
    content: str = ''
    core_concept: Optional[str] = None
    description: Optional[str] = None
    card_type: str = 'concept'
    domain: str = 'Unknown'
    tags: List[str] = None
    paper_id: Optional[int] = None
    zettel_folder: str = ''
    source_info: str = ''
    file_path: str = ''
    ai_notes: Optional[str] = None
    human_notes: Optional[str] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

    def __post_init__(self):
        if self.tags is None:
            self.tags = []

    def to_dict(self) -> Dict:
        """è½‰ç‚ºå­—å…¸ï¼ˆç”¨æ–¼ JSON åºåˆ—åŒ–ï¼‰"""
        return {k: v for k, v in self.__dict__.items() if v is not None}

@dataclass
class ZettelLink:
    """Zettelkasten é€£çµæ•¸æ“šé¡"""
    link_id: Optional[int] = None
    source_card_id: int = 0
    target_zettel_id: str = ''
    relation_type: str = ''  # åŸºæ–¼/å°å‘/ç›¸é—œ/å°æ¯”/ä¸Šä½/ä¸‹ä½
    context: Optional[str] = None
    is_cross_paper: bool = False
    created_at: Optional[datetime] = None

@dataclass
class IndexResult:
    """ç´¢å¼•çµæœæ•¸æ“šé¡"""
    total_folders: int = 0
    total_cards: int = 0
    success: int = 0
    failed: int = 0
    skipped: int = 0
    links_created: int = 0
    papers_linked: int = 0
    errors: List[Dict] = None
    processing_time: str = ''

    def __post_init__(self):
        if self.errors is None:
            self.errors = []

    def to_report(self) -> str:
        """ç”Ÿæˆå¯è®€å ±å‘Š"""
        report = f"""
ğŸ“Š Zettelkasten ç´¢å¼•å ±å‘Š
========================

çµ±è¨ˆ:
  - è³‡æ–™å¤¾æ•¸: {self.total_folders}
  - ç¸½å¡ç‰‡æ•¸: {self.total_cards}
  - æˆåŠŸ: {self.success}
  - å¤±æ•—: {self.failed}
  - è·³é: {self.skipped}
  - é€£çµå»ºç«‹: {self.links_created}
  - è«–æ–‡é—œè¯: {self.papers_linked}
  - è™•ç†æ™‚é–“: {self.processing_time}

æˆåŠŸç‡: {self.success / self.total_cards * 100:.1f}%
"""

        if self.errors:
            report += f"\néŒ¯èª¤åˆ—è¡¨ ({len(self.errors)}):\n"
            for err in self.errors[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                report += f"  - {err['file']}: {err['error']}\n"

        return report
```

---

## å–®å…ƒæ¸¬è©¦æ¸…å–®

### Test Suite 1: `parse_zettel_card()` æ¸¬è©¦

**æ¸¬è©¦æ–‡ä»¶**: `tests/test_zettel_parser.py`

```python
import unittest
from pathlib import Path
from src.knowledge_base import KnowledgeBaseManager

class TestZettelCardParser(unittest.TestCase):
    """æ¸¬è©¦ Zettelkasten å¡ç‰‡è§£æ"""

    @classmethod
    def setUpClass(cls):
        cls.kb = KnowledgeBaseManager()
        cls.test_card_path = "output/zettelkasten_notes/zettel_Linguistics_20251029/zettel_cards/Linguistics-20251029-001.md"

    def test_parse_valid_card(self):
        """æ¸¬è©¦è§£ææœ‰æ•ˆå¡ç‰‡"""
        result = self.kb.parse_zettel_card(self.test_card_path)

        self.assertIsNotNone(result)
        self.assertEqual(result['zettel_id'], 'Linguistics-20251029-001')
        self.assertEqual(result['title'], 'Mass Noun (Mass Noun)')
        self.assertEqual(result['domain'], 'Linguistics')
        self.assertEqual(result['card_type'], 'concept')
        self.assertIn('Mass Noun', result['tags'])
        self.assertIsNotNone(result['core_concept'])
        self.assertIn('mass noun interchangeably', result['core_concept'])

    def test_parse_invalid_path(self):
        """æ¸¬è©¦è§£æä¸å­˜åœ¨çš„æ–‡ä»¶"""
        result = self.kb.parse_zettel_card("nonexistent.md")
        self.assertIsNone(result)

    def test_normalize_id(self):
        """æ¸¬è©¦ ID æ­£è¦åŒ–"""
        # æ­£ç¢ºæ ¼å¼
        self.assertEqual(
            self.kb._normalize_id('Linguistics-20251029-001'),
            'Linguistics-20251029-001'
        )

        # éŒ¯èª¤æ ¼å¼ï¼ˆéœ€ä¿®å¾©ï¼‰
        self.assertEqual(
            self.kb._normalize_id('CogSci20251028001'),
            'CogSci-20251028-001'
        )

        self.assertEqual(
            self.kb._normalize_id('AI_20251030_005'),
            'AI-20251030-005'
        )

    def test_extract_links(self):
        """æ¸¬è©¦é€£çµæå–"""
        markdown = """
## é€£çµç¶²çµ¡

**å°å‘** â†’ [[Linguistics-20251029-002]], [[Linguistics-20251029-003]]

**åŸºæ–¼** â†’ [[Linguistics-20251029-001]]
"""
        links = self.kb._extract_links_from_content(markdown)

        self.assertEqual(len(links), 2)
        self.assertEqual(links[0]['relation_type'], 'å°å‘')
        self.assertEqual(len(links[0]['target_ids']), 2)
        self.assertEqual(links[1]['relation_type'], 'åŸºæ–¼')

    def test_extract_core_concept(self):
        """æ¸¬è©¦æ ¸å¿ƒæ¦‚å¿µæå–"""
        markdown = '''
> **æ ¸å¿ƒ**: "I use mass noun interchangeably with non-count noun."

## èªªæ˜
é€™æ˜¯èªªæ˜æ–‡å­—ã€‚
'''
        # æ¸¬è©¦æ­£å‰‡è¡¨é”å¼
        import re
        match = re.search(r'> \*\*æ ¸å¿ƒ\*\*:\s*"(.+?)"', markdown)
        self.assertIsNotNone(match)
        self.assertIn('mass noun', match.group(1))

    def test_extract_ai_notes(self):
        """æ¸¬è©¦ AI ç­†è¨˜æå–"""
        markdown = '''
**[AI Agent]**: é€™æ˜¯ AI çš„æ‰¹åˆ¤æ€§æ€è€ƒã€‚

**[Human]**: (TODO) å¾…è£œå……
'''
        import re
        ai_match = re.search(r'\*\*\[AI Agent\]\*\*:\s*(.+?)(?=\n\*\*\[Human\]|\Z)', markdown, re.DOTALL)
        self.assertIsNotNone(ai_match)
        self.assertIn('æ‰¹åˆ¤æ€§æ€è€ƒ', ai_match.group(1))
```

### Test Suite 2: `parse_zettel_links()` æ¸¬è©¦

```python
class TestZettelLinksParser(unittest.TestCase):
    """æ¸¬è©¦ Zettelkasten é€£çµè§£æ"""

    def setUp(self):
        self.kb = KnowledgeBaseManager()
        # å‰µå»ºæ¸¬è©¦æ•¸æ“šï¼ˆæ’å…¥å…©å¼µæ¸¬è©¦å¡ç‰‡ï¼‰
        self.test_card_1_id = self._insert_test_card('Test-001', 'Test Card 1')
        self.test_card_2_id = self._insert_test_card('Test-002', 'Test Card 2')

    def tearDown(self):
        # æ¸…ç†æ¸¬è©¦æ•¸æ“š
        self.kb.conn.execute('DELETE FROM zettel_cards WHERE zettel_id LIKE "Test-%"')
        self.kb.conn.execute('DELETE FROM zettel_links WHERE target_zettel_id LIKE "Test-%"')
        self.kb.conn.commit()

    def test_parse_links_basic(self):
        """æ¸¬è©¦åŸºæœ¬é€£çµæ’å…¥"""
        card_data = {
            'links': [
                {'relation_type': 'å°å‘', 'target_ids': ['Test-002']}
            ],
            'domain': 'Test'
        }

        link_ids = self.kb.parse_zettel_links(card_data, self.test_card_1_id)

        self.assertEqual(len(link_ids), 1)

        # é©—è­‰æ•¸æ“šåº«è¨˜éŒ„
        cursor = self.kb.conn.cursor()
        cursor.execute('SELECT * FROM zettel_links WHERE link_id = ?', (link_ids[0],))
        row = cursor.fetchone()

        self.assertEqual(row[1], self.test_card_1_id)  # source_card_id
        self.assertEqual(row[2], 'Test-002')            # target_zettel_id
        self.assertEqual(row[3], 'å°å‘')                 # relation_type

    def test_parse_links_multiple_targets(self):
        """æ¸¬è©¦å¤šå€‹ç›®æ¨™é€£çµ"""
        card_data = {
            'links': [
                {'relation_type': 'ç›¸é—œ', 'target_ids': ['Test-002', 'Test-003', 'Test-004']}
            ],
            'domain': 'Test'
        }

        link_ids = self.kb.parse_zettel_links(card_data, self.test_card_1_id)
        self.assertEqual(len(link_ids), 3)

    def test_parse_links_cross_paper(self):
        """æ¸¬è©¦è·¨è«–æ–‡é€£çµåµæ¸¬"""
        # æ’å…¥ä¸åŒ domain çš„å¡ç‰‡
        other_domain_id = self._insert_test_card('CogSci-001', 'Other Domain', domain='CogSci')

        card_data = {
            'links': [
                {'relation_type': 'å°æ¯”', 'target_ids': ['CogSci-001']}
            ],
            'domain': 'Linguistics'
        }

        link_ids = self.kb.parse_zettel_links(card_data, self.test_card_1_id)

        # æª¢æŸ¥ is_cross_paper æ¨™è¨˜
        cursor = self.kb.conn.cursor()
        cursor.execute('SELECT is_cross_paper FROM zettel_links WHERE link_id = ?', (link_ids[0],))
        is_cross = cursor.fetchone()[0]

        self.assertTrue(is_cross)

    def _insert_test_card(self, zettel_id, title, domain='Test'):
        """è¼”åŠ©æ–¹æ³•ï¼šæ’å…¥æ¸¬è©¦å¡ç‰‡"""
        cursor = self.kb.conn.cursor()
        cursor.execute('''
            INSERT INTO zettel_cards (zettel_id, title, content, domain, file_path, zettel_folder)
            VALUES (?, ?, '', ?, '', '')
        ''', (zettel_id, title, domain))
        self.kb.conn.commit()
        return cursor.lastrowid
```

### Test Suite 3: `index_zettelkasten()` æ¸¬è©¦

```python
class TestZettelIndexer(unittest.TestCase):
    """æ¸¬è©¦æ‰¹æ¬¡ç´¢å¼•åŠŸèƒ½"""

    def setUp(self):
        self.kb = KnowledgeBaseManager()
        # ä½¿ç”¨çœŸå¯¦çš„æ¸¬è©¦è³‡æ–™å¤¾ï¼ˆå–®å€‹è³‡æ–™å¤¾ï¼‰
        self.test_folder = "output/zettelkasten_notes/zettel_Linguistics_20251029"

    def test_index_single_folder(self):
        """æ¸¬è©¦ç´¢å¼•å–®å€‹è³‡æ–™å¤¾"""
        result = self.kb.index_zettelkasten(
            zettel_dirs=self.test_folder,
            update_existing=False,
            link_to_papers=False  # æš«æ™‚è·³éè«–æ–‡é—œè¯
        )

        self.assertGreater(result['total_cards'], 0)
        self.assertGreater(result['success'], 0)
        self.assertLessEqual(result['failed'], 2)  # å®¹è¨±å°‘é‡å¤±æ•—

        # é©—è­‰æ•¸æ“šåº«
        cursor = self.kb.conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM zettel_cards WHERE domain = "Linguistics"')
        count = cursor.fetchone()[0]
        self.assertEqual(count, result['success'])

    def test_index_with_progress_callback(self):
        """æ¸¬è©¦é€²åº¦å›èª¿"""
        progress_calls = []

        def progress(current, total, filename):
            progress_calls.append((current, total))

        result = self.kb.index_zettelkasten(
            zettel_dirs=self.test_folder,
            progress_callback=progress
        )

        self.assertEqual(len(progress_calls), result['total_cards'])
        self.assertEqual(progress_calls[-1][0], result['total_cards'])  # æœ€å¾Œä¸€æ¬¡æ˜¯ total

    def test_index_skip_existing(self):
        """æ¸¬è©¦è·³éå·²å­˜åœ¨å¡ç‰‡"""
        # ç¬¬ä¸€æ¬¡ç´¢å¼•
        result1 = self.kb.index_zettelkasten(self.test_folder, update_existing=False)

        # ç¬¬äºŒæ¬¡ç´¢å¼•ï¼ˆæ‡‰è©²å…¨éƒ¨è·³éï¼‰
        result2 = self.kb.index_zettelkasten(self.test_folder, update_existing=False)

        self.assertEqual(result2['skipped'], result1['success'])
        self.assertEqual(result2['success'], 0)

    def test_index_update_existing(self):
        """æ¸¬è©¦æ›´æ–°å·²å­˜åœ¨å¡ç‰‡"""
        # ç¬¬ä¸€æ¬¡ç´¢å¼•
        result1 = self.kb.index_zettelkasten(self.test_folder, update_existing=False)

        # ç¬¬äºŒæ¬¡ç´¢å¼•ï¼ˆæ›´æ–°æ¨¡å¼ï¼‰
        result2 = self.kb.index_zettelkasten(self.test_folder, update_existing=True)

        self.assertEqual(result2['success'], result1['success'])
        self.assertEqual(result2['skipped'], 0)

    def test_fts_index_rebuild(self):
        """æ¸¬è©¦ FTS5 ç´¢å¼•é‡å»º"""
        # ç´¢å¼•å¡ç‰‡
        self.kb.index_zettelkasten(self.test_folder)

        # æª¢æŸ¥ FTS5 è¡¨
        cursor = self.kb.conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM zettel_cards_fts')
        fts_count = cursor.fetchone()[0]

        cursor.execute('SELECT COUNT(*) FROM zettel_cards')
        cards_count = cursor.fetchone()[0]

        self.assertEqual(fts_count, cards_count)
```

### Test Suite 4: è«–æ–‡é—œè¯æ¸¬è©¦

```python
class TestPaperLinking(unittest.TestCase):
    """æ¸¬è©¦å¡ç‰‡-è«–æ–‡é—œè¯"""

    def setUp(self):
        self.kb = KnowledgeBaseManager()
        # æ’å…¥æ¸¬è©¦è«–æ–‡
        self.test_paper_id = self._insert_test_paper(
            title="Chinese Classifiers and Count Nouns",
            year=2021,
            zotero_key="Her2012a"
        )

    def tearDown(self):
        self.kb.conn.execute('DELETE FROM papers WHERE id = ?', (self.test_paper_id,))
        self.kb.conn.commit()

    def test_link_by_title(self):
        """æ¸¬è©¦é€šéæ¨™é¡ŒåŒ¹é…è«–æ–‡"""
        card_data = {
            'source_info': '"Chinese Classifiers and Count Nouns" (2021)',
            'domain': 'Linguistics'
        }

        # æ’å…¥æ¸¬è©¦å¡ç‰‡
        cursor = self.kb.conn.cursor()
        cursor.execute('''
            INSERT INTO zettel_cards (zettel_id, title, content, domain, file_path, zettel_folder)
            VALUES ('Test-001', 'Test', '', 'Linguistics', '', '')
        ''')
        card_id = cursor.lastrowid
        self.kb.conn.commit()

        # åŸ·è¡Œé—œè¯
        paper_id = self.kb._link_card_to_paper(card_data, card_id)

        self.assertEqual(paper_id, self.test_paper_id)

        # é©—è­‰æ•¸æ“šåº«æ›´æ–°
        cursor.execute('SELECT paper_id FROM zettel_cards WHERE card_id = ?', (card_id,))
        linked_paper = cursor.fetchone()[0]
        self.assertEqual(linked_paper, self.test_paper_id)

        # æ¸…ç†
        cursor.execute('DELETE FROM zettel_cards WHERE card_id = ?', (card_id,))
        self.kb.conn.commit()

    def test_link_by_cite_key(self):
        """æ¸¬è©¦é€šé cite_key åŒ¹é…è«–æ–‡"""
        card_data = {
            'source_info': '"Some Paper" (2020)',
            'file_path': 'output/.../zettel_Her2012a_20251029/zettel_cards/Test-001.md',
            'domain': 'Linguistics'
        }

        # æ’å…¥æ¸¬è©¦å¡ç‰‡
        cursor = self.kb.conn.cursor()
        cursor.execute('''
            INSERT INTO zettel_cards (zettel_id, title, content, domain, file_path, zettel_folder)
            VALUES ('Test-002', 'Test', '', 'Linguistics', ?, '')
        ''', (card_data['file_path'],))
        card_id = cursor.lastrowid
        self.kb.conn.commit()

        # åŸ·è¡Œé—œè¯
        paper_id = self.kb._link_card_to_paper(card_data, card_id)

        self.assertEqual(paper_id, self.test_paper_id)

        # æ¸…ç†
        cursor.execute('DELETE FROM zettel_cards WHERE card_id = ?', (card_id,))
        self.kb.conn.commit()

    def test_metadata_enrichment(self):
        """æ¸¬è©¦å…ƒæ•¸æ“šå¢å¼·"""
        # å‰µå»ºç¼ºå°‘å¹´ä»½çš„è«–æ–‡
        cursor = self.kb.conn.cursor()
        cursor.execute('''
            INSERT INTO papers (title, year, zotero_key)
            VALUES ('Test Paper', NULL, 'TestKey2020')
        ''')
        test_id = cursor.lastrowid
        self.kb.conn.commit()

        # æ¨¡æ“¬ BibTeX æ•¸æ“š
        # ï¼ˆå¯¦éš›æ¸¬è©¦éœ€è¦çœŸå¯¦çš„ BibTeX æ–‡ä»¶æˆ– mockï¼‰

        # æ¸…ç†
        cursor.execute('DELETE FROM papers WHERE id = ?', (test_id,))
        self.kb.conn.commit()

    def _insert_test_paper(self, title, year, zotero_key):
        """è¼”åŠ©æ–¹æ³•ï¼šæ’å…¥æ¸¬è©¦è«–æ–‡"""
        cursor = self.kb.conn.cursor()
        cursor.execute('''
            INSERT INTO papers (title, year, zotero_key)
            VALUES (?, ?, ?)
        ''', (title, year, zotero_key))
        self.kb.conn.commit()
        return cursor.lastrowid
```

### Test Suite 5: æœç´¢åŠŸèƒ½æ¸¬è©¦

```python
class TestZettelSearch(unittest.TestCase):
    """æ¸¬è©¦ Zettelkasten æœç´¢"""

    @classmethod
    def setUpClass(cls):
        cls.kb = KnowledgeBaseManager()
        # ç´¢å¼•æ¸¬è©¦æ•¸æ“š
        cls.kb.index_zettelkasten("output/zettelkasten_notes/zettel_Linguistics_20251029")

    def test_search_basic(self):
        """æ¸¬è©¦åŸºæœ¬æœç´¢"""
        results = self.kb.search_zettel("mass noun", limit=10)

        self.assertGreater(len(results), 0)
        self.assertIn('zettel_id', results[0])
        self.assertIn('title', results[0])
        self.assertIn('snippet', results[0])

    def test_search_with_domain_filter(self):
        """æ¸¬è©¦é ˜åŸŸéæ¿¾"""
        results = self.kb.search_zettel(
            "noun",
            filters={'domain': 'Linguistics'},
            limit=10
        )

        for result in results:
            self.assertEqual(result['domain'], 'Linguistics')

    def test_search_with_tags_filter(self):
        """æ¸¬è©¦æ¨™ç±¤éæ¿¾"""
        results = self.kb.search_zettel(
            "noun",
            filters={'tags': ['Mass Noun']},
            limit=10
        )

        for result in results:
            self.assertIn('Mass Noun', result['tags'])

    def test_search_fts_syntax(self):
        """æ¸¬è©¦ FTS5 èªæ³•"""
        # AND æŸ¥è©¢
        results = self.kb.search_zettel("mass AND noun")
        self.assertGreater(len(results), 0)

        # OR æŸ¥è©¢
        results = self.kb.search_zettel("mass OR count")
        self.assertGreater(len(results), 0)

        # çŸ­èªæŸ¥è©¢
        results = self.kb.search_zettel('"mass noun"')
        self.assertGreater(len(results), 0)

    def test_search_performance(self):
        """æ¸¬è©¦æœç´¢æ•ˆèƒ½"""
        import time

        start = time.time()
        results = self.kb.search_zettel("noun", limit=100)
        elapsed = time.time() - start

        self.assertLess(elapsed, 0.5)  # æ‡‰åœ¨ 500ms å…§å®Œæˆ

    def test_search_ranking(self):
        """æ¸¬è©¦ç›¸é—œæ€§æ’åº"""
        results = self.kb.search_zettel("mass noun", limit=5)

        # é©—è­‰ rank éæ¸›ï¼ˆFTS5 çš„ rank æ˜¯è² æ•¸ï¼Œè¶Šå¤§è¶Šç›¸é—œï¼‰
        for i in range(len(results) - 1):
            self.assertGreaterEqual(results[i]['rank'], results[i+1]['rank'])
```

### æ¸¬è©¦åŸ·è¡ŒæŒ‡ä»¤

```bash
# åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
pytest tests/test_zettel_*.py -v

# åŸ·è¡Œç‰¹å®šæ¸¬è©¦å¥—ä»¶
pytest tests/test_zettel_parser.py::TestZettelCardParser -v

# ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š
pytest tests/ --cov=src.knowledge_base --cov-report=html --cov-report=term

# ä¸¦è¡Œæ¸¬è©¦ï¼ˆåŠ é€Ÿï¼‰
pytest tests/ -n auto
```

---

## æ•´åˆæ¸¬è©¦è¨ˆç•«

### æ•´åˆæ¸¬è©¦ 1ï¼šå°è¦æ¨¡ç«¯åˆ°ç«¯æ¸¬è©¦

**ç›®æ¨™**: é©—è­‰å®Œæ•´æµç¨‹ï¼ˆ1å€‹è³‡æ–™å¤¾ï¼Œ~20å¼µå¡ç‰‡ï¼‰

**æ­¥é©Ÿ**:
1. æ¸…ç©ºæ¸¬è©¦æ•¸æ“šåº«
2. ç´¢å¼•å–®å€‹ Zettelkasten è³‡æ–™å¤¾
3. é©—è­‰æ‰€æœ‰å¡ç‰‡æˆåŠŸç´¢å¼•
4. é©—è­‰é€£çµæ­£ç¢ºå»ºç«‹
5. æ¸¬è©¦æœç´¢åŠŸèƒ½
6. ç”Ÿæˆæ¸¬è©¦å ±å‘Š

```python
def integration_test_small_scale():
    """å°è¦æ¨¡æ•´åˆæ¸¬è©¦"""
    kb = KnowledgeBaseManager()

    # 1. æ¸…ç©ºæ¸¬è©¦æ•¸æ“š
    kb.conn.execute('DELETE FROM zettel_cards')
    kb.conn.execute('DELETE FROM zettel_links')
    kb.conn.commit()

    # 2. ç´¢å¼•å–®å€‹è³‡æ–™å¤¾
    result = kb.index_zettelkasten(
        "output/zettelkasten_notes/zettel_Linguistics_20251029",
        link_to_papers=True
    )

    # 3. é©—è­‰çµ±è¨ˆ
    assert result['success'] >= 10, "è‡³å°‘10å¼µå¡ç‰‡æˆåŠŸ"
    assert result['failed'] <= 2, "å¤±æ•—æ•¸ä¸è¶…é2"
    assert result['links_created'] > 0, "è‡³å°‘å»ºç«‹ä¸€äº›é€£çµ"

    # 4. é©—è­‰æ•¸æ“šåº«
    cursor = kb.conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM zettel_cards')
    cards_count = cursor.fetchone()[0]
    assert cards_count == result['success']

    # 5. æ¸¬è©¦æœç´¢
    results = kb.search_zettel("mass noun")
    assert len(results) > 0, "æ‡‰è©²æ‰¾åˆ°çµæœ"

    print("âœ… å°è¦æ¨¡æ•´åˆæ¸¬è©¦é€šé!")
```

### æ•´åˆæ¸¬è©¦ 2ï¼šå…¨é‡ç´¢å¼•æ¸¬è©¦

**ç›®æ¨™**: ç´¢å¼•æ‰€æœ‰33å€‹è³‡æ–™å¤¾ï¼Œ~660å¼µå¡ç‰‡

**æ­¥é©Ÿ**:
1. å‚™ä»½ç¾æœ‰æ•¸æ“šåº«
2. åŸ·è¡Œå…¨é‡ç´¢å¼•
3. é©—è­‰æˆåŠŸç‡ >95%
4. é©—è­‰ FTS5 ç´¢å¼•å®Œæ•´æ€§
5. æ•ˆèƒ½æ¸¬è©¦ï¼ˆæœç´¢éŸ¿æ‡‰æ™‚é–“ï¼‰
6. ç”Ÿæˆå®Œæ•´å ±å‘Š

```python
def integration_test_full_scale():
    """å…¨é‡æ•´åˆæ¸¬è©¦"""
    import shutil
    from datetime import datetime

    kb = KnowledgeBaseManager()

    # 1. å‚™ä»½æ•¸æ“šåº«
    backup_path = f"knowledge_base/index_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
    shutil.copy('knowledge_base/index.db', backup_path)
    print(f"æ•¸æ“šåº«å·²å‚™ä»½: {backup_path}")

    # 2. åŸ·è¡Œå…¨é‡ç´¢å¼•
    result = kb.index_zettelkasten(
        "output/zettelkasten_notes",
        update_existing=True,
        link_to_papers=True
    )

    # 3. é©—è­‰æˆåŠŸç‡
    success_rate = result['success'] / result['total_cards'] * 100
    assert success_rate >= 95, f"æˆåŠŸç‡éä½: {success_rate:.1f}%"

    # 4. é©—è­‰ FTS5
    cursor = kb.conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM zettel_cards_fts')
    fts_count = cursor.fetchone()[0]
    assert fts_count == result['success'], "FTS5 ç´¢å¼•ä¸å®Œæ•´"

    # 5. æ•ˆèƒ½æ¸¬è©¦
    import time
    queries = ["mental simulation", "noun", "concept", "embodied cognition"]
    total_time = 0

    for query in queries:
        start = time.time()
        results = kb.search_zettel(query, limit=20)
        elapsed = time.time() - start
        total_time += elapsed
        assert elapsed < 0.5, f"æŸ¥è©¢ '{query}' éæ…¢: {elapsed:.3f}s"

    avg_time = total_time / len(queries)
    print(f"å¹³å‡æœç´¢æ™‚é–“: {avg_time*1000:.1f}ms")

    # 6. ç”Ÿæˆå ±å‘Š
    report = f"""
ğŸ‰ å…¨é‡æ•´åˆæ¸¬è©¦å®Œæˆ

ğŸ“Š ç´¢å¼•çµ±è¨ˆ:
  - ç¸½å¡ç‰‡æ•¸: {result['total_cards']}
  - æˆåŠŸ: {result['success']} ({success_rate:.1f}%)
  - å¤±æ•—: {result['failed']}
  - é€£çµ: {result['links_created']}
  - è«–æ–‡é—œè¯: {result['papers_linked']}
  - è™•ç†æ™‚é–“: {result['processing_time']}

ğŸ” æœç´¢æ•ˆèƒ½:
  - å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time*1000:.1f}ms
  - FTS5 ç´¢å¼•: {fts_count} æ¢è¨˜éŒ„

âœ… æ‰€æœ‰æ¸¬è©¦é€šé!
"""

    print(report)

    # ä¿å­˜å ±å‘Š
    with open('integration_test_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
```

### æ•´åˆæ¸¬è©¦ 3ï¼šZotero åŒæ­¥æ¸¬è©¦

**ç›®æ¨™**: æ¸¬è©¦ BibTeX è§£æå’Œå…ƒæ•¸æ“šå¢å¼·

```python
def integration_test_zotero_sync():
    """Zotero åŒæ­¥æ•´åˆæ¸¬è©¦"""
    kb = KnowledgeBaseManager()

    # 1. å…ƒæ•¸æ“šå¢å¼·
    result = kb.enrich_paper_metadata_from_bibtex(
        "D:\\core\\research\\Program_verse\\+\\My Library.bib"
    )

    # 2. é©—è­‰å¢å¼·æ•ˆæœ
    assert result['enriched'] > 0, "æ‡‰è©²è‡³å°‘å¢å¼·ä¸€äº›è«–æ–‡"

    print(f"""
ğŸ“š Zotero åŒæ­¥æ¸¬è©¦å®Œæˆ

  - ç¸½è«–æ–‡æ•¸: {result['total_papers']}
  - å¢å¼·æ•¸: {result['enriched']}
  - å¹´ä»½è£œå……: {result['fields_updated']['year']}
  - DOI è£œå……: {result['fields_updated']['doi']}
  - æ‘˜è¦è£œå……: {result['fields_updated']['abstract']}

âœ… æ¸¬è©¦é€šé!
""")
```

---

## é¢¨éšªç®¡ç†

### å·²è­˜åˆ¥é¢¨éšª

| é¢¨éšª | å½±éŸ¿ | å¯èƒ½æ€§ | ç·©è§£ç­–ç•¥ |
|------|------|--------|----------|
| **ID æ ¼å¼ä¸ä¸€è‡´** | ä¸­ | é«˜ | å¯¦ä½œ `_normalize_id()` è‡ªå‹•ä¿®å¾© |
| **è«–æ–‡åŒ¹é…å¤±æ•—** | ä½ | ä¸­ | å…è¨±æ‰‹å‹•æŒ‡å®š paper_idï¼Œè¨˜éŒ„æœªåŒ¹é…æ¸…å–® |
| **è¨˜æ†¶é«”ä¸è¶³** | é«˜ | ä½ | ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼ï¼Œåˆ†æ‰¹è™•ç† |
| **ç·¨ç¢¼å•é¡Œ** | ä¸­ | ä¸­ | çµ±ä¸€ UTF-8 ç·¨ç¢¼ï¼Œå¼·åˆ¶æŒ‡å®š `encoding='utf-8'` |
| **FTS5 æ•ˆèƒ½å•é¡Œ** | ä¸­ | ä½ | å»ºç«‹é©ç•¶ç´¢å¼•ï¼Œå®šæœŸ VACUUM |
| **é€£çµç›®æ¨™ä¸å­˜åœ¨** | ä½ | ä¸­ | å®¹éŒ¯è™•ç†ï¼Œè¨˜éŒ„è­¦å‘Šä½†ä¸ä¸­æ–· |
| **YAML è§£æéŒ¯èª¤** | ä¸­ | ä½ | Try-catchï¼Œè·³ééŒ¯èª¤å¡ç‰‡ä¸¦è¨˜éŒ„ |

### å›æ»¾è¨ˆç•«

å¦‚æœå‡ºç¾åš´é‡å•é¡Œï¼ŒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š

```python
def rollback_zettel_index():
    """å›æ»¾ Zettelkasten ç´¢å¼•"""
    kb = KnowledgeBaseManager()
    cursor = kb.conn.cursor()

    # 1. åˆªé™¤æ‰€æœ‰ Zettelkasten æ•¸æ“š
    cursor.execute('DELETE FROM zettel_links')
    cursor.execute('DELETE FROM zettel_cards')
    cursor.execute('DELETE FROM zettel_cards_fts')

    # 2. é‡ç½® paper_idï¼ˆå¦‚æœéœ€è¦ï¼‰
    # cursor.execute('UPDATE papers SET paper_id = NULL')

    kb.conn.commit()
    print("âœ… Zettelkasten æ•¸æ“šå·²æ¸…é™¤")
```

---

## æ™‚é–“é ä¼°

### è©³ç´°æ™‚é–“åˆ†é…

| éšæ®µ | ä»»å‹™ | é ä¼°æ™‚é–“ | å„ªå…ˆç´š |
|------|------|----------|--------|
| **éšæ®µ 1** | å¯¦ä½œ `parse_zettel_card()` | 2å°æ™‚ | P0 |
|  | å¯¦ä½œ `parse_zettel_links()` | 1.5å°æ™‚ | P0 |
|  | æ’°å¯« Test Suite 1-2 | 1å°æ™‚ | P0 |
| **éšæ®µ 2** | å¯¦ä½œ `index_zettelkasten()` | 2.5å°æ™‚ | P0 |
|  | å¯¦ä½œè¼”åŠ©æ–¹æ³•ï¼ˆinsert/update/rebuild_ftsï¼‰ | 1å°æ™‚ | P0 |
|  | æ’°å¯« Test Suite 3 | 1å°æ™‚ | P0 |
| **éšæ®µ 3** | å¯¦ä½œ `_link_card_to_paper()` | 1.5å°æ™‚ | P1 |
|  | å¯¦ä½œ `enrich_paper_metadata()` | 1å°æ™‚ | P1 |
|  | æ’°å¯« Test Suite 4 | 0.5å°æ™‚ | P1 |
| **éšæ®µ 4** | å¯¦ä½œ `search_zettel()` | 2å°æ™‚ | P0 |
|  | å¯¦ä½œ `get_related_zettel()` (å¯é¸) | 1.5å°æ™‚ | P2 |
|  | æ’°å¯« Test Suite 5 | 1å°æ™‚ | P0 |
| **éšæ®µ 5** | æ“´å±• `kb_manage.py` CLI | 1.5å°æ™‚ | P1 |
|  | æ’°å¯«æ–‡æª”å’Œä½¿ç”¨ç¯„ä¾‹ | 0.5å°æ™‚ | P1 |
| **æ¸¬è©¦** | åŸ·è¡Œæ•´åˆæ¸¬è©¦ | 1å°æ™‚ | P0 |
|  | ä¿®å¾©ç™¼ç¾çš„å•é¡Œ | 1å°æ™‚ | P0 |
| **ç¸½è¨ˆ** | | **19-20å°æ™‚** | |

### åˆ†éšæ®µäº¤ä»˜

**Day 1** (8å°æ™‚):
- âœ… å®Œæˆéšæ®µ 1ï¼ˆå¡ç‰‡è§£ææ ¸å¿ƒï¼‰
- âœ… å®Œæˆéšæ®µ 2ï¼ˆæ‰¹æ¬¡ç´¢å¼•å™¨ï¼‰
- âœ… åŸ·è¡Œå°è¦æ¨¡æ¸¬è©¦

**Day 2** (8å°æ™‚):
- âœ… å®Œæˆéšæ®µ 3ï¼ˆè«–æ–‡é—œè¯ï¼‰
- âœ… å®Œæˆéšæ®µ 4ï¼ˆæœç´¢åŠŸèƒ½ï¼‰
- âœ… å®Œæˆéšæ®µ 5ï¼ˆCLI å·¥å…·ï¼‰
- âœ… åŸ·è¡Œå…¨é‡æ•´åˆæ¸¬è©¦

**Day 3** (é ç•™ç·©è¡æ™‚é–“):
- ä¿®å¾©ç™¼ç¾çš„å•é¡Œ
- å„ªåŒ–æ•ˆèƒ½
- å®Œå–„æ–‡æª”

---

## æˆåŠŸé©—æ”¶æ¨™æº–

### å¿…è¦æ¢ä»¶ï¼ˆMust Haveï¼‰

- âœ… è‡³å°‘ 95% çš„å¡ç‰‡æˆåŠŸç´¢å¼•åˆ°æ•¸æ“šåº«
- âœ… FTS5 æœç´¢å¯ç”¨ä¸”éŸ¿æ‡‰æ™‚é–“ <500ms
- âœ… è«–æ–‡é—œè¯æˆåŠŸç‡ >70%
- âœ… å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ >80%
- âœ… æ‰€æœ‰ CLI å‘½ä»¤å¯æ­£å¸¸åŸ·è¡Œ
- âœ… é€£çµç¶²çµ¡æ­£ç¢ºå»ºç«‹ï¼ˆå¯è¦–è¦ºåŒ–é©—è­‰ï¼‰

### æœŸæœ›æ¢ä»¶ï¼ˆShould Haveï¼‰

- âœ… è«–æ–‡é—œè¯æˆåŠŸç‡ >80%
- âœ… æœç´¢éŸ¿æ‡‰æ™‚é–“ <300ms
- âœ… å…ƒæ•¸æ“šå¢å¼·åŠŸèƒ½æ­£å¸¸é‹ä½œ
- âœ… å®Œæ•´çš„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„

### å¯é¸æ¢ä»¶ï¼ˆNice to Haveï¼‰

- â­ æ¦‚å¿µç¶²çµ¡åœ–è¦–è¦ºåŒ–ï¼ˆ`get_related_zettel()`ï¼‰
- â­ è·¨è«–æ–‡æ¦‚å¿µé—œè¯åˆ†æ
- â­ çŸ¥è­˜åœ–è­œå°å‡ºï¼ˆGraphML/Mermaidï¼‰

---

## ä¸‹ä¸€æ­¥è¡Œå‹•

**ç«‹å³é–‹å§‹å¯¦ä½œ** - ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# 1. é–‹å§‹å¯¦ä½œ parse_zettel_card()
ç”¨æˆ¶: "é–‹å§‹å¯¦ä½œ parse_zettel_card() æ–¹æ³•ï¼ŒæŒ‰ç…§å¯¦æ–½è¨ˆç•«åŸ·è¡Œ"

# 2. æˆ–å…ˆåŸ·è¡Œå°è¦æ¨¡æ¸¬è©¦é©—è­‰å¯è¡Œæ€§
ç”¨æˆ¶: "å…ˆæ¸¬è©¦è§£æå–®å¼µ Zettelkasten å¡ç‰‡ï¼Œé©—è­‰ YAML å’Œ Markdown æå–é‚è¼¯"

# 3. æˆ–ç›´æ¥åŸ·è¡Œå®Œæ•´å¯¦ä½œ
ç”¨æˆ¶: "æŒ‰ç…§å¯¦æ–½è¨ˆç•«ï¼Œå®Œæ•´å¯¦ä½œ Task 1.3 æ‰€æœ‰åŠŸèƒ½"
```

---

**æ–‡æª”ç‹€æ…‹**: ğŸ“ è¦åŠƒå®Œæˆï¼Œç­‰å¾…å¯¦æ–½
**ç¶­è­·è€…**: Claude Code Agent
**æœ€å¾Œæ›´æ–°**: 2025-10-30
