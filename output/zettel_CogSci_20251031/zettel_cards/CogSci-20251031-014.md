---
id: CogSci-20251031-014
title: "Prompting and Probing"
tags: [[Prompting], [Probing], [HumanSimulation]]
source: "Günther-2025a" (2025)
paper_id: 
created: 2025-10-31
type: method
---

# Prompting and Probing

> **核心**: "prompting/probing these models to produce an output, treating them similarly to human participants."

## 說明
在實驗設計中，研究者給 LLM 提供特定提示或檢測問題，視其回應為「實驗結果」，類似於對人類參與者的測試。這方法可評估模型在語境、推理或語法上的「理解」程度。

## 連結網絡


**基於** → [[CogSci-20251031-001]]


**導向** → [[CogSci-20251031-015]]




## 來源脈絡
- 📄 **文獻**: Günther-2025a



## 個人筆記


**[AI Agent]**: [AI Agent]：雖然簡單有效，但 prompt 的設計極易影響模型回應，需考量提示偏差與人類實驗中的引導效應。


**[Human]**: (TODO) <!-- 請在此處添加您的個人思考、批判性評論或延伸想法 -->


## 待解問題
如何量化 prompt 偏差對模型回答的影響？是否有標準化提示框架可供心理學研究採用？


---
*卡片類型*: method
