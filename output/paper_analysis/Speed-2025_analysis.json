{
  "file_path": "D:\\core\\Research\\Program_verse\\+\\pdf\\Speed-2025.pdf",
  "file_name": "Speed-2025.pdf",
  "full_text": "Memory & Cognition\nhttps://doi.org/10.3758/s13421-025-01731-y\nDissociating voluntary mental imagery and mental simulation:\nEvidence from aphantasia\nLaura J. Speed1,3 · Emma M. E. Geraerds1 · Ken McRae2\nAccepted: 5 May 2025\n© The Author(s) 2025\nAbstract\nIntentional visual imagery is a component of numerous aspects of cognition. Related to visual imagery, mental simulation\nplays a role in language comprehension: modality-specific regions of the brain are activated as an implicit part of people\nunderstanding language. The degree of overlap between the processes underlying conscious, voluntary visual imagery versus\nless conscious, more automatic mental simulation is unclear. We investigated this issue by having aphantasics (people who\nare unable to experience conscious voluntary visual imagery) and control participants perform a property verification task\nin which they were asked whether a property is a physical part of an object (e.g., is mane a physical part of a lion?). We\nmanipulated the false trials so that the two words either were associated (semantically related) but did not form an object–\npart combination (monkey–banana), or were not associated (apple–cloud). Solomon and Barsalou (Memory & Cognition,\n32, 244–259, 2004) demonstrated that word association influenced responses when the words in the false trials were not\nassociated, whereas when they were associated, perceptual measures most strongly influenced the results, indicating mental\nsimulation. In the present study, control participants and aphantasics demonstrated similar evidence of the use of both mental\nsimulation and word association when verifying whether the words formed an object–part combination. These results suggest\nthat visual imagery and mental simulation are at least somewhat separable cognitive processes.\nKeywords Aphantasia · Mental simulation · Mental imagery · Embodiment\nHumans can voluntarily and purposefully create internal a separate, less conscious, more automatic process, known\nvisual images in their mind, known as visual imagery. Vis- as mental simulation, is used (Mak & Faber, 2024; Muraki\nual imagery is critically involved in many cognitive tasks. et al., 2023b).\nFor example, it has a role in working memory (Keogh & Evidence from neuroimaging shows that voluntary visual\nPearson, 2011), autobiographical memory (Anderson et al., imagery recruits regions of the brain involved in veridical\n2017; Greenberg & Knowlton, 2014; Sheldon, 2022), and visual perception, including early visual areas (Albers, et al.,\nevent future thinking (D’Argembeau & Van Der Linden, 2013; Slotnick et al., 2005; Stokes et al., 2009). For example,\n2004, 2012). Visual imagery is also thought to be recruited retinotopic maps constructed via fMRI were similar when\nwhen comprehending language. However, there is an ongo- participants viewed a flickering checkerboard and when\ning debate as to whether language comprehension uses the they imagined one (Slotnick et al., 2005). Mental images\nsame voluntary, conscious imagery processes as those used of works of art can even be decoded from low-level visual\nwhen one is explicitly asked to “Imagine a . . . ,” or whether activation in the brain (Naselaris et al., 2015). Visual brain\nregions are also activated when comprehending language\n* (Mak et al., 2023; Pulvermüller & Hauk, 2006; Saygin\nLaura J. Speed\nlaura.speed@ru.nl et al., 2010; Simmons et al., 2007; van Dam et al., 2012).\nFor example, performing property judgments about color\n1 Centre for Language Studies, Radboud University, on word pairs (e.g., TAXI > yellow) activates brain regions\nNijmegen, Netherlands\nrecruited during color perception (Simmons et al., 2007).\n2 Department of Psychology, University of Western Ontario, In addition, reading sentences about motion (e.g., The wild\nLondon, Canada\nhorse crossed the barren field) activates motion-sensitive\n3 Donders Institute for Brain, Cognition, and Behaviour, visual areas of the brain (Saygin et al., 2010). This evidence\nRadboud University, Nijmegen, Netherlands\nVol.:(0123456789)\n\nMemory & Cognition\nis consistent with embodied theories of language compre- 2012). It is possible, however, that the range of imagery\nhension that propose that activation of modality-specific abilities in these samples was not sufficiently large to detect\nregions of the brain takes place during language comprehen- effects of individual differences in imagery on mental simu-\nsion (Barsalou, 2008; Meteyard et al., 2012). This perceptual lation processes. In addition, it is likely that most partici-\nactivation is known as mental simulation. It is important to pants were able to visualize to some extent.\nnote that there exist inconsistencies and overlap regarding\nterminology within and across fields. Researchers such as\nAphantasia\nSchacter and Addis (2007) use the term “simulation” when\ndescribing how people voluntarily and explicitly generate\nimagery in autobiographical memory and event future think- A more direct way to establish the extent to which men-\ning tasks. In this article, to remain consistent with the lan- tal simulation and conscious, voluntary visual imagery are\nguage comprehension literature, we use “mental simulation” related is to investigate individuals with no conscious expe-\nto denote the more implicit automatic process that is part of rience of visual imagery—that is, with aphantasia (Muraki\nunderstanding language. et al., 2023a, b). Aphantasia is a condition in which people\nAlthough there are similarities between visual imagery are unable to experience conscious voluntary visual imagery\nand the visual simulation that occurs during language com- (Zeman, 2024; Zeman et al., 2015), and often imagery\nprehension, it remains unclear to what extent the two pro- in other sensory modalities as well (Dawes et al., 2024).\ncesses overlap (Mak & Faber, 2024; Muraki et al., 2023b). Aphantasia occurs in approximately 4% of the population\nMental simulation has been described as less conscious (Dance et al., 2022), and has been shown to affect other\n(Connell & Lynott, 2016; Muraki et al., 2023b; Zwaan & cognitive processes, such as autobiographical memory and\nPecher, 2012) and more schematic than visual imagery event future thinking (Dawes et al., 2020, 2022; Milton et al.,\n(Barsalou, 1999). While Barsalou (1999) acknowledges 2021). If visual imagery underlies language comprehension,\nthat mental simulation can sometimes produce “conscious it is puzzling why people with aphantasia do not report dif-\ncounterparts” (p. 583), the basic definition is that uncon- ficulties with understanding spoken and written language.\nscious mental images underlie mental simulation. Support- Initial evidence suggests that aphantasics may have\ning this proposal, Connell and Lynott (2016) showed that reduced mental simulation during reading compared with\ninformation is lost when the contents of mental simulations controls. Aphantasics have a reduced emotional response\nare transferred to conscious imagery. Mental simulation is to frightening stories, but not frightening images (Monzel\nalso considered to be automatic and involuntary. For exam- et al., 2023; Wicken et al., 2021), which could be due to a\nple, activation of visual representations during language lack of mental simulation. Aphantasics also failed to show\ncomprehension has been found to occur as early as 200 ms motor simulation, measured with motor-evoked potentials\nafter word onset (Ostarek & Huettig, 2017). Although it has (MEPs) when reading manual action sentences (e.g., “I have\nbeen proposed that mental simulation uses a subset of the a hair on my arm, I pull it out”; original stimuli presented\nmechanisms involved in mental imagery (Schendan & Ganis, in French: “J’ai un cheveu sur mon bras, je le retire” ).With\n2012), the evidence concerning the degree to which mental longer texts, aphantasics appear to be impaired in deep\nimagery and mental simulation are related is mixed. On the reading—operationalized as the ability to select the best-\none hand, individual differences in specific forms of motor fitting words for a sentence context (Dupont et al., 2023).\nimagery correlate with effects of sensorimotor simulation Aphantasics also report being less absorbed in a short story\nin some language tasks (Cayol et al., 2020; Muraki et al., and less transported to the story world compared with con-\n2023a; Muraki & Pexman, 2021). Furthermore, strong visual trols (Speed et al., 2024). However, this type of becoming\nimagers have been found to have better long-term memory immersed in a story may involve conscious visual imagery\nfor words with more sensorimotor associations (McKelvie rather than mental simulation. It therefore remains unclear\n& Demers, 1979). whether aphantasics mentally simulate during language\nOn the other hand, there is evidence to suggest that men- comprehension.\ntal simulation and mental imagery are distinct processes. The current evidence for whether people with aphantasia\nWillems et al. (2010) found that areas of the brain activated can engage in involuntary unconscious imagery, which may\nduring a mental simulation task were distinct from regions be more related to mental simulation, is mixed. Evidence\nactivated by an explicit mental imagery task. However, from the binocular rivalry paradigm suggests that people\nWillems et al. (2010) specifically addressed motor imagery, with aphantasia are impaired in both voluntary, conscious,\nwhich may differ from sensory imagery. In other studies, and involuntary, unconscious imagery (Keogh & Pearson,\nindividual scores on visual and auditory imagery question- 2021; Purkart et al., 2025), and it has been argued that\nnaires do not predict performance in mental simulation tasks aphantasia should not be characterized as solely a specific\n(Pecher et al., 2009; Speed & Majid, 2018; Zwaan & Pecher, deficit in voluntary imagery (Krempel & Monzel, 2024).\n\nMemory & Cognition\nKeogh and Pearson (2021) found that aphantasic partici- typical imagers and vivid imagers to imagine pairs of\npants’ attention to visual features (green vertical or red hori- objects, faces, and spatial layouts and make judgments about\nzontal lines of a plaid stimulus) was affected by an atten- them (e.g., “beaver,” “fox,” “which is longer?”). Surpris-\ntional cue (being cued to attend to green or red lines of a ingly, aphantasics showed no impairment in their accuracy\nprime image), but the same attentional cue did not activate performing the task, but their response time was slower\nvisual representations in the form of attentional templates— for all domains except space. The authors suggest that the\nthought to unconsciously activate visual representations— aphantasics were able to generate mental imagery sufficient\nlike it did in control participants. Similarly, Purkart et al. to perform the task, but may have a deficit in phenomenal\n(2025) found no evidence of binocular rivalry when par- consciousness, which affects speed of information process-\nticipants were implicitly primed to imagine a Gabor patch ing. Similarly, Jacobs et al. (2018) found that an aphantasic\nvia associations between colors and Gabors learned in an individual did not differ from controls on a working mem-\nassociation phase. There is also evidence that aphantasics ory task putatively requiring visual imagery, but they did\ndo not activate motor simulation, measured via MEPs, dur- lack insight into their performance, in line with a deficit in\ning implicit action observation, in addition to explicit motor phenomenal consciousness. On the other hand, their per-\nimagery (Dupont et al., 2024). formance did decline when the task required a high level\nOn the other hand, some evidence suggests that invol- of precision, which could mean that the easier levels of the\nuntary, unconscious imagery is possible in aphantasia. In task were completed by nonvisual compensatory strategies.\na case study conducted by Duan et al. (2024), an aphanta- While the existing evidence for the presence of involun-\nsic participant did not differ from controls on a differential tary imagery in aphantasia is mixed, Krempel and Monzel\nthreshold task involving involuntary imagery. Participants (2024) argue that involuntary imagery should not be consid-\nviewed pairs of visual gratings consecutively and had to ered a unified kind and may instead come in multiple forms.\njudge whether the second grating had rotated clockwise or From this perspective, involuntary imagery elicited while\ncounterclockwise to the first grating. Before presentation comprehending language (i.e., mental simulation) may be a\nof the first grating, a high- or low-pitch tone cued the ori- different kind relative to the involuntary imagery elicited in\nentation of the second grating. In the involuntary imagery the tasks outlined above.\ncondition, an association between the tones and the angle\nof the second grating had been learned implicitly. Interest-\nThe present study\ningly, the aphantasic also did not differ from controls when\nexplicitly asked to imagine the orientation of the second\ngrating when the interval between the instruction to imagine Our aim is to test the extent to which individuals with aphan-\nand presentation of the grating was very short (500 ms), tasia engage in mental simulation as part of language com-\nbut they performed worse than controls with a longer inter- prehension. We investigated the presence of mental simula-\nval (6,000 ms). Since it has been suggested that voluntary tion in aphantasia using an established property verification\nimagery can only affect perception with longer durations of task previously used to demonstrate mental simulation.\nimagery (Pearson et al., 2008), these results can be inter- Solomon and Barsalou (2004) conducted an experiment to\npreted as showing an impairment in voluntary but not invol- test the language and situated simulation (LASS) theory\nuntary imagery. (Barsalou et al., 2008). According to LASS, linguistic asso-\nNeuroimaging methods have also been used to reveal ciations between words are sufficient to perform shallow\nthe potential for involuntary imagery in aphantasia. Using semantic tasks, and are activated early in the time course\nfMRI and multi-voxel pattern analyses (MVPA), Cabbai of language processing (see also Connell, 2019; Louwerse,\net al. (2024) found that voluntary, conscious visual imagery 2011). In contrast, mental simulation is more useful during\nelicited via evocative sounds (e.g., the sound of a crowd deep semantic tasks, and is delayed relative to the influence\nof seagulls) could be decoded from representations in the of linguistic associations.\nprimary visual cortex (V1) for control participants, but not In Solomon and Barsalou’s (2004) property verifica-\nfor aphantasics. Interestingly, when aphantasics passively tion task, participants decided whether a presented prop-\nlistened to the same sounds, decoding accuracy in V1 was erty was a physical part of an object (e.g., is nose a part\ngreater than chance, even though participants did not report of face?). On false trials (when the property was not a\nany conscious imagery. Whilst it is unclear from this find- physical part), property-concept pairs were manipulated\ning if unconscious imagery in aphantasia could play a role to have either strong word association (associated con-\nin cognition, it at least highlights the potential role it has. dition e.g., apple–pear) or no word association (unas-\nAnother possibility is that aphantasics are capable of both sociated condition e.g., apple–cloud). False-trial word\nvoluntary and involuntary imagery, but have no conscious association was manipulated between participants. Prop-\naccess to it. Liu and Bartolomeo (2023) asked aphantasics, erty verification times to true trials were faster when the\n\nMemory & Cognition\nfalse trials were unassociated compared with when they Participants\nwere associated. This suggests that participants used a\nrapidly unfolding word association strategy to distinguish All participants were native speakers of Dutch. Aphantasic\nbetween associated true concept–property pairs and com- participants were recruited via advertisements on social\npletely unassociated word pairs. In contrast, when false media groups dedicated to aphantasia (e.g., on Facebook\ntrials were associated, word association was no longer and Reddit) and contact with researchers who were also\nhelpful and participants had to use mental simulation, a conducting research with aphantasic participants. Control\nslower process, to decide whether the two words formed participants were recruited on Prolific. Participants were\na concept–property pair. Perceptual and linguistic ratings paid 5 euros for their participation either via Prolific or\nof the concept–property pairs also predicted responses. as an online shopping voucher. Several participants were\nWhen false trials were associated, perceptual ratings removed from the dataset according to our preregistered\npredicted performance (response time and accuracy), but data exclusion criteria. The Vividness of Visual Imagery\nwhen false trials were unassociated, linguistic ratings did. Questionnaire (VVIQ; Marks, 1973) was used to deter-\nFollow-up work with fMRI found that visual association mine whether or not participants were aphantasic. Three\ncortex was activated when false trials were associated but aphantasic participants were removed for having a score\nnot when they were unassociated, further supporting the greater than 32, indicating intact visual imagery. Two\ninitial conclusion that mental simulation occurred (Kan control participants were removed for having a VVIQ\net al., 2003). Overall, their results suggest that the influ- score less than 32, indicating reduced vividness of visual\nences of linguistic association and mental simulation vary imagery. Five participants were removed from all analyses\ndepending on task context. for having an overall accuracy score of less than 80% cor-\nIn the present study, we used Solomon and Barsalou’s rect (three aphantasics and two controls). The final sample\n(2004) design to compare performance on the property consisted of 30 participants with aphantasia (M = 39.3\nage\nverification task between aphantasics and controls. If years, SD = 13.6) and 29 control participants (M = 36.3\nage\nmental simulation and mental imagery are related, and years, SD = 13.2). The two groups did not differ in age,\ntherefore aphantasics do not engage in mental simula- t(57) = 0.86, p = .4. Figure 1 displays the distribution of\ntion, we expect aphantasics to be slower than controls in mean VVIQ scores across aphantasics and controls.\nthe associated condition in which performing the task via\nlinguistic associations is unhelpful and mental simulation\nmust be used. Furthermore, we expect perceptual ratings Design\nto predict performance in the associated condition for the\ncontrols but not for the aphantasics. We do not expect the The study is a 2 × 2 between participants design with the\ngroups to differ in the unassociated condition in which factors group (aphantasic vs. control) and relatedness of\nthe task can be performed by linguistic association alone. the false trials (associated vs. unassociated).\nIf instead mental simulation and mental imagery are dis-\ntinct, then aphantasics and controls should not differ.\nBoth groups should have faster response times for true tri-\nals in the unassociated compared with the associated con-\ndition (because judgments via linguistic associations are\nfast). Furthermore, linguistic associations should predict\nperformance in the unassociated condition in both groups,\nand perceptual ratings should predict performance in the\nassociated condition in both groups.\nMethod\nThe study was ethically approved by the Ethics Assess-\nment Committee of the authors’ university and prereg-\nistered on the Open Science Framework: https://o sf.i o/\nFig. 1 Distribution of Vividness of Visual Imagery Questionnaire\n9ntdy\n(VVIQ; Marks, 1973) scores across final set of aphantasics and con-\ntrols. A score of less than 32 indicates aphantasia, as indicated by the\ndashed line\n\nMemory & Cognition\nStimuli the property. Participants were asked for each concept–prop-\nerty pair how many different sorts of objects have that prop-\nConcept–property pairs were selected based on Solomon erty (1 = 1 object, 2 = 2–3 objects, 3 = 4–10 objects, 4 =\nand Barsalou’s (2004) stimuli and translated to Dutch. Some 11–30 objects, 5 = 31–100 objects). As in the original study,\nitems needed to be changed because their Dutch translation this was used to control for the polysemy of the property\ndid not work or because they were outdated (e.g., a receiver words. For example, the property nose takes different forms\nfor a phone). There were 100 true pairs in which proper- for humans, animals, and planes. The reliability scores for\nties were physical parts (e.g., bull–horns). There were 100 each predictor were calculated using intraclass correlation\nfalse pairs in which the property was associated with the in R (R Core Team, 2020).\nconcept in one of three ways (associated condition): the-\nmatically related (e.g., banana–chimpanzee), related via Procedure\ntaxonomic category (e.g., donkey–mule), or taxonomically\nrelated parts (e.g., guitar–keyboard). There were 100 false The experiment was built with PsychoPy (Peirce et al., 2019)\npairs in which the property and the concept were unrelated and hosted online with Pavlovia (pavlovia.org). The experi-\n(unassociated condition). The unassociated pairs contained mental procedure followed that of Solomon and Barsalou\nthe same concepts and properties as the associated pairs but (2004). On each trial participants were shown the name of\nwere re-paired ensuring that the concept and property were a concept for 500 ms, followed by a 1,200 ms interstimu-\nunrelated. There were also 72 practice pairs, with an equal lus interval, and then the name of a property. The property\nnumber of true, false associated and false unassociated pairs. remained on the screen until participants responded. Verifi-\ncation times were measured starting at the onset of the pres-\nPredictors entation of the property name and ending at the response.\nParticipants were instructed to respond using the right arrow\nAll true pairs were rated by a separate set of participants on button for a “yes” if the property was a physical part of\nseven factors that were significant predictors of responses in the concept, or the left arrow for “no” if it was not. They\nSolomon and Barsalou (2004): L_conc_prop, P_area, P_left, were instructed to use their dominant hand to respond and\nP_initial, P_find, P_handle, and E_num_obj.1 The false pairs to answer as quickly as possible while keeping the number\nwere also rated on L_conc_prop. L_conc_prop is a linguistic of errors as low as possible. After each answer, participants\npredictor that indicates the associative strength between the received feedback on whether or not their answer was cor-\nconcept and property (ICC = .94). Participants were asked rect (“correct” or “incorrect” appeared on the screen). Par-\nto rate how quickly they thought of the property word when ticipants first received practice trials to become accustomed\nthey read the concept word on a scale of 1 (didn’t think of it to the procedure. They were told there were 16 practice\nat all) to 9 (very fast). The five factors starting with a P are items. Note that 32 additional practice items were presented\nperceptual predictors. For P_area (ICC = .93), participants at the beginning of the block of experimental trials. Partici-\nindicated the area of the property as a percentage of the pants were given the opportunity to take a short break every\nentire object (e.g., what percentage of a bull is the horns?, 31 trials. After the experiment, participants were directed\nscale: 0 –100%). For P_left (ICC = .66), participants were to a survey in Qualtrics (https://w ww.q ualtr ics.c om) that\nasked to image a box around the internal visual image of the included demographic questions and the VVIQ (Marks,\nconcept and indicate what percentage of the width of the box 1973). The VVIQ scores were used to check participants’\nis the distance from the left edge of the box to the property visual imagery abilities and distinguish between the aphanta-\nas a percentage of the entire concept length (scale: 0–100%). sics and controls. The aphantasics were also asked additional\nFor P_initial (ICC = .85), participants indicated whether or questions about their experience with aphantasia, following\nnot the property was in their initial visual image of the con- Zeman et al. (2020).\ncept (1 = yes, 0 = no). For P_find (ICC = .82), participants\nwere asked how easily they could find the property in the\nvisual image of the concept on a scale of 1 (very difficult) Results\nto 9 (very easy). For P_handle (ICC = .95), participants\nwere asked to imagine the concept and rate the likelihood Data and analysis scripts are available online (https://o sf.i o/\nof touching the property on a scale of 1 (not likely) to 9 (very j9znu/). Seventeen items were removed from analyses for\nlikely). The last factor, E_num_obj (ICC = .77), is an expec- having a mean accuracy of less than 70% (six true trials,\ntancy predictor of the amount of different objects that have 11 false associated). As preregistered, individual trials were\nremoved if they fell outside of two standard deviations of a\nparticipants’ mean response time for correct true responses\n1 See Appendix for original Dutch translations of rating scales. or correct false responses (6% of trials). In addition, response\n\nMemory & Cognition\nlatencies shorter than 300 ms or longer than 3,000 ms were both true and false trials suggest that the effect of relatedness\nremoved (a further 1%). does not differ between aphantasics and controls.\nThe data were analyzed using linear mixed effect models\nconducted in R (R Core Team, 2020) using the lme4 package Accuracy\n(Bates et al., 2015) with participants and items modelled as\nrandom intercepts. Separate models were conducted for true Models of accuracy did not converge with participants and\nand false trials, for response time and accuracy. We tested items modelled as random effects, nor with length and fre-\nthe effect of group (aphantasic vs. control), relatedness quency added as covariates, so we report analyses with only\n(associated vs. unassociated), and the interaction between participant level intercepts. For true trials there was no effect\ngroup and relatedness. Property word length and frequency of group, χ2(1) < 1, p = .889, R2 <.001, no effect of relat-\n(Zip frequency) were added to the models as control vari- edness, χ2(1) < 1, p = .592, R2 = .00, and no interaction,\nables. We compared models with and without the factors of χ2(1) < 1, p = .697, R2 ≤ .001. As shown in Fig. 3, overall\ninterest using likelihood ratio tests with chi-square. accuracy was very high in all conditions. For false trials\nthere was a significant effect of relatedness, χ2(1) = 14.80,\nResponse time p < .001, R2 = .005, with accuracy being higher in the unas-\nsociated (.98) than the associated condition (.94). There was\nFor response-time analyses we included only correct no effect of group, χ2(1) = 2.14, p = .4, R2 = .001, and no\nresponses. As predicted, there was a significant effect of interaction, χ2(1) < 1, p = .9, R2 < .001.\nrelatedness on response time to true trials, χ2(1) = 3.90, p\n= .048, R2 = .041, with response time faster in the unassoci- Linguistic and perceptual predictors\nated (819 ms) compared with the associated condition (956\nms, see Fig. 2). There was no difference between aphantasics To analyze the role of the linguistic and perceptual predic-\nand controls in response times for true trials, χ2(1) < 1, p tors in property verification judgments, we conducted lin-\n= .415, R2 = .005. Contrary to our prediction, there was no ear mixed effects models of true trials separately for each\ninteraction between group and relatedness, χ2(1) < 1, p = condition (aphantasic associated, aphantasic unassociated,\n.614, R2 = .001. control associated, control unassociated) with participants\nWe also found a significant effect of relatedness on and items as random intercepts, and property word length\nresponse time for false trials, χ2(1) = 6.67, p = .010, R2 and frequency (Zip frequency) as covariates. This was pos-\n= .056 (where the correct response was “no”), again with sible only for response time because the accuracy models did\nresponses faster in the unassociated (854 ms) compared with not converge. The unique contribution of perceptual predic-\nthe associated condition (1,054 ms; see Fig. 2). There was tors was tested by comparing a full model with all percep-\nno effect of group on response time to false trials, χ2(1) = tual predictors, the linguistic predictor, and the expectancy\n1.01, p = .315, R2 = .007, and no interaction between group predictor, with a model with only the linguistic predictor\nand relatedness, χ2(1) < 1, p = .414, R2 = .004. Results for and expectancy predictor. The unique contribution of the\nlinguistic predictor was tested by comparing a full model\nFig. 2 Response time (ms) for true and false trials for aphantasics and controls in the associated and unassociated conditions\n\nMemory & Cognition\nFig. 3 Accuracy (proportion correct) for true and false trials for aphantasics and controls in the associated and unassociated conditions\nof all perceptual predictors, the linguistic predictor, and the Table 1 Unique variance in response times explained by perceptual\nexpectancy predictor, with a model with only the perceptual and linguistic predictors using linear mixed-effects analyses (asterisks\npredictors and expectancy predictor. indicate significant variance explained)\nFor aphantasics, there was a significant effect of the per-\nAphantasics Controls\nceptual predictors over and above the linguistic and expec-\ntancy predictor in the associated condition, χ2(1) = 17.44, p Predictor Associated Unassociated Associated Unassociated\n< .001, R2 = .009, but not the unassociated condition, χ2(1) Perceptual .009* .008 .007* .002\n= 9.69, p = .085, R2 = .008, as in Solomon and Barsalou Linguistic .004* .013* .002 .004*\n(2004). There was an effect of the linguistic predictor over\nand above the perceptual and expectancy predictors for the\naphantasics in both the associated and unassociated condi- like the control participants. We also see that the aphantasic\ntion, associated condition: χ2(1) = 7.68, p = .006, R2 = .004, participants rely on linguistic associations in the associated\nunassociated condition: χ2(1) = 15.29, p < .001, R2 = .013. condition too, while this was not the case for the controls\nFor the control group, there was a significant effect of (although p = .052).\nthe perceptual predictors over and above the linguistic and Solomon and Barsalou (2004) analyzed their data using\nexpectancy predictor in the associated condition, χ2(1) = multiple regression by items. We therefore conducted the\n13.95, p = .016, R2 = .007, but not the unassociated condi- same analyses to compare R2 values with the original study,\ntion, χ2(1) = 7.27, p = .201, R2 = .002. There was an effect with property word length and frequency (Zip frequency) as\nof the linguistic predictor over and above the expectancy and control variables. The pattern of results is the same except\nperceptual predictors in the unassociated, χ2(1) = 11.32, p that with this analysis, the linguistic predictors explain\n< .001, R2 = .004, but not the associated condition, χ2(1) significant variance in all conditions (see Supplementary\n= 3.77, p = .052, R2 = .002. Results for the control group Analyses).\nare in line with the results of Solomon and Barsalou (2004). As exploratory analyses we examined the unique vari-\nTable 1 depicts the unique variance accounted for by the ance for each individual predictor by comparing full mod-\nperceptual and linguistic predictors in each condition. els including all predictors with models without the indi-\nThe analyses suggest that aphantasic individuals do use vidual predictor of interest. As shown in Table 2, the effect\nperceptual simulation in the associated condition, just like of the perceptual predictors is primarily driven by P_initial\ncontrols. Surprisingly, the variance explained by the per- (whether the property was in the initial visual image of the\nceptual predictors is larger for the aphantasics than con- concept) in all associated conditions, as well as the unassoci-\ntrols. The results also show that aphantasic participants use ated condition for the aphantasics. Interestingly, in the con-\nlinguistic associations in the unassociated condition, again trol unassociated condition, P_area (the area of the property\n\nMemory & Cognition\nTable 2 Unique variance of individual predictors in linear mixed-effects models of reaction time (asterisks indicate significant variance\nexplained)\nAphantasics Controls\nAssociated Unassociated Associated Unassociated\nPredictor β R2 β R2 β R2 β R2\nPerceptual\nP_handle .052 .002 .008 .000 .047 .002 −.014 .00\nP_left .022 .001 −.031 .001 −.015 .001 .006 .00\nP_initial −.092 .004* −.105 .006* −.067 .003* −.033 .00\nP_find −.019 .00 −.003 .000 .010 .00 −.030 .00\nP_area .052 .002 .013 .000 .036 .001 .051 .001*\nLinguistic\nL_conc_prop −.094 .004* −.173 .013* −.061 .002 −.101 .004*\nas a percentage of the whole concept) was also a significant mental simulation in the control group but not in the aphan-\npredictor, as well as the linguistic variable, L_conc_prop. tasic group.\nFor both groups then, even when linguistic association is We found that both aphantasics and controls were\nprimarily used to make property judgments, perceptual affected by the relatedness of the false trials. Responses\ninformation is to some extent still recruited. were faster when the false trials were unassociated com-\nWe also examined the unique variance for each predic- pared with associated, presumably because the influence\ntor using multiple regression by items, as in Solomon and of word association is more rapid than is the influence\nBarsalou (2004; see Supplementary Analyses). With this of mental simulation. Crucially, there was no difference\nanalysis the pattern of results differs from the linear mixed- between the two groups of participants. Although we\neffect models for the control participants in that P_area is expected aphantasics to be slower than control participants\nno longer a significant predictor in the unassociated condi- for associated trials in which word association did not reli-\ntion but only L_conc_prop (the linguistic variable) is, and ably cue a “yes” response, the results suggest that they\nP_initial is no longer a significant predictor in the associ- were not hindered by having to rely on mental simulation.\nated condition, but P_handle (the likelihood of touching Further evidence from our data supports the sugges-\nthe property) is. This contrast in results demonstrates the tion that aphantasic participants used mental simulation\nimportance of considering both participant and item vari- to complete the task. As in the original study (Solomon &\nance in the analysis. Barsalou, 2004), perceptual predictors predicted response\nOverall, while perceptual and linguistic predictors to times when the false trails were associated, and this was\nsome extent played a role in all conditions, perceptual pre- true for both groups of participants. This suggests that\ndictors explained more variance in the associated condi- aphantasics did engage in mental simulation when word\ntions and linguistic predictors explained more variance in association did not reliably cue the response. More broadly\nthe unassociated conditions, as in the original study. This this supports the suggestion that mental simulation is flex-\npattern held for both controls and aphantasics. ible and context-dependent, and may not be necessary in\nall language tasks (Ibañez et al., 2023; Lebois et al., 2015;\nvan Dam et al., 2012).\nGeneral discussion\nOur task was similar to that employed by Liu and Barto-\nlomeo (2023), where participants had to judge the similar-\nWe tested the extent to which mental simulation and volun- ity of pairs of objects (e.g., beaver, fox) on features such\ntary mental imagery are related by using an experimental as color and size. In contrast to our findings, however,\nparadigm known to demonstrate mental simulation (Solo- Liu and Bartolomeo found that aphantasics performed\nmon & Barsalou, 2004). We used this paradigm to com- the task more slowly than typical imagers. A crucial dif-\npare people with low vividness of visual imagery (people ference in their methodology was that participants were\nwith aphantasia) to control participants with intact visual explicitly asked to imagine the objects for two seconds\nimagery. If mental simulation and voluntary mental imagery each, whereas we did not instruct participants to imagine.\nare related strongly, one would expect to observe evidence of The focus on explicit imagery generation may have slowed\ndown information processing. This is in line with Cabbai\n\nMemory & Cognition\net al. (2024) who found that imagery could be decoded in previous conjectures (Muraki et al., 2023b). As Krempel\nV1 in aphantasics when passively listening to evocative and Monzel (2024) argue, however, the involuntary imagery\nsounds, but not when they were explicitly asked to gener- elicited during language comprehension may be only one\nate imagery of the sound content. form of involuntary imagery, so we cannot conclude whether\nAs expected, we found that the linguistic predictor (i.e., involuntary imagery in general is intact in aphantasia.\nthe associative strength between the concept and prop- It also remains unclear whether voluntary mental imagery\nerty) predicted response times in the unassociated condi- and mental simulation differ due to whether they are inten-\ntion in both groups. Interestingly, the linguistic predictor tional and voluntary, or whether they occur via conscious\nalso predicted response times in the associated condition or unconscious processes. Because aphantasics are known\nfor the aphantasic participants. While this finding was not to consciously experience mental imagery when they dream\nexpected, it might suggest that aphantasics rely more on (Zeman et al., 2020), which is thought to be involuntary, it\nlinguistic distributional information than do control partici- might be likely that the problem lies in the voluntary gen-\npants. This could result from a greater reliance on explicit eration of imagery (see Nanay, 2021, for a discussion of\nverbal information in everyday thought and memory, to voluntary vs. involuntary and conscious vs. unconscious\ncompensate for problems in explicit mental imagery. In line visual imagery). In line with the existence of mental simu-\nwith this idea, aphantasics have been shown to appreciate lation in individuals with aphantasia, Cabbai et al. (2024)\nthe language used by a writer in a short story, but appreci- found decodable sensory representations in V1 in a group\nate the descriptions of scenery in the short story to a much of aphantasics during spontaneous imagery (listening to\nlesser degree (Speed et al., 2024). An alternative explanation an evocative sound such as a cat meowing), even when the\nis that aphantasics used linguistic associations because their subjective experience of imagery was absent. Interestingly,\nmental simulation was weak. However, the size of the effect decoding in V1 was at chance during an explicit imagery\nof the perceptual predictors, which is larger than that of the task in aphantasics.\ncontrols, suggests this is not the case. An alternative explanation is that aphantasics were not\nOur results have important implications for theories of able to visually simulate the meaning of the words to per-\nembodied language comprehension because they suggest form the property verification judgement, but used another\nthat mental simulation can be performed independent of strategy. This would be in line with the suggestion that cog-\nstrategic or conscious imagery, as previously argued (e.g., nition is also supported by propositional representations,\nBarsalou, 1999). This is consistent with recent evidence not only sensory (Pearson & Kosslyn, 2015). This has been\nshowing that aphantasics are less likely to become absorbed suggested as an explanation for aphantasics’ performance on\nin a story world compared with controls with intact visual other tasks where an expected impairment was not observed\nimagery (Speed et al., 2024). Our results suggest that this (Scholz, 2024). For example, a single aphantasic participant\nkind of story absorption relies more on conscious voluntary did not perform more poorly than a group of controls on a\nimagery than unconscious involuntary simulation. In terms mental imagery task, and performed more poorly on a visual\nof understanding language at a somewhat basic or superficial working memory task only on very difficult trials (Jacobs\nlevel (as in the good enough theory of language comprehen- et al., 2018). Similarly, a group of aphantasics were not\nsion, cf. Ferreira et al., 2002) rather than immersed, enriched impaired in accuracy on a range of neuropsychological tasks\nstory experiences, aphantasics may be able to reactivate putatively associated with visual imagery (Pounder et al.,\nvisual information as part of word meaning. In fact, Barsa- 2022). Aphantasics have even been found to perform better\nlou (1999) already described how unconscious perceptual than controls on visual working memory (Keogh et al., 2021)\nprocessing (mental simulation) could underlie cognition and mental rotation tasks (Kay et al., 2024). Interestingly,\nwithout conscious awareness. He stated, “If human knowl- aphantasics reported more often using an analytic strategy\nedge is inherently perceptual, there is no a priori reason it (e.g., using logic and rules) to complete a mental rotation\nmust be represented consciously” (p.583). Since this is one task, instead of imagining visual rotation of the objects or\nof the first studies to find evidence for mental simulation in rotation of their own body (Kay et al., 2024). In our study\naphantasia, the results should be replicated with other men- it is possible that property verifications were accomplished\ntal simulation tasks. One possibility could be to test whether based on abstract information, rather than mental simulation.\nreading words or sentences could lead to visual priming For example, verbally generating parts might enable a par-\nin perceptual tasks such as those observed with binocular ticipant to correctly judge that “sleeve” is a physical part of\nrivalry (e.g., Keogh & Pearson, 2018). “blouse.” If this was the case, however, we would not expect\nOur results also have important implications for theo- perceptual ratings to predict performance. Alternatively, the\nries of aphantasia because they suggest that a specific form perceptual ratings may be correlated with another kind of\nof unconscious mental simulation in language processing linguistic information not measured by our word association\nis preserved in individuals with aphantasia, aligning with variable, although it is not clear what that would be. On the\n\nMemory & Cognition\nother hand, the time course of linguistic processing and men- during language comprehension. Visual imagery and mental\ntal simulation is purported to differ (Barsalou et al., 2008), simulation are separable cognitive processes.\nand would therefore lead to response time differences in the\nSupplementary Information The online version contains supplemen-\ntask, which was not observed here. Experimental paradigms\ntary material available at https://d oi.o rg/1 0.3 758/s 13421-0 25-0 1731-y.\nthat have been used to test the effect of language on visual\nprocessing, such as sentence–picture verification tasks (Con- Funding This research was supported by a Radboud-Western collabo-\nnell, 2007) or visual discrimination tasks (Meteyard et al., ration grant to L.S. and K.M.\n2007), may provide stronger evidence for mental simulation\nAvailable of data and materials Data, analysis scripts, and stimuli are\nin aphantasia.\navailable here: https://o sf.i o/j 9znu/\nAnother possibility is that visual simulation is impaired\nin aphantasia, but mental simulation in other modalities Code availability Not applicable\nis spared. When looking at the experimental items, only\nDeclarations\napproximately 60% of the true trials could be answered cor-\nrectly based on haptic simulation. For example, it is highly Conflicts of interest/Competing interests Not applicable.\nlikely that participants have no (or perhaps extremely little)\nhaptic experience with the parts of many of the (often wild) Ethics approval This study was approved by the Ethics Assessment\nCommittee of Radboud University. The procedures used in this study\nanimals that serve as stimuli in our study (e.g., cow–udder,\nadhere to the tenets of the Declaration of Helsinki.\npig–snout, shark–fin, zebra–hoof). Furthermore, this also\nis the case for a number of the nonliving object–part com- Consent to participate Informed consent was obtained from all indi-\nbinations that served as related trials (e.g., church–steeple, vidual participants included in the study.\nsailboat–mast). Therefore, we do not believe that haptic sim-\nConsent for publication Not applicable.\nulation was used as a compensatory strategy by aphantasics\nfor two reasons. If haptic simulation had been used by one\nOpen Access This article is licensed under a Creative Commons Attri-\ngroup and visual simulation by the other group, a response\nbution 4.0 International License, which permits use, sharing, adapta-\ntime difference would still be expected. It has been shown tion, distribution and reproduction in any medium or format, as long\nthat words’ visual associations typically facilitate word pro- as you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\ncessing, but haptic associations instead slow down word pro-\nwere made. The images or other third party material in this article are\ncessing (Speed & Brysbaert, 2022). In addition, only five\nincluded in the article’s Creative Commons licence, unless indicated\naphantasic participants reported impaired imagery in only otherwise in a credit line to the material. If material is not included in\nthe visual modality, whereas 13 reported impairments in all the article’s Creative Commons licence and your intended use is not\nmodalities,2 suggesting haptic simulation was unlikely. permitted by statutory regulation or exceeds the permitted use, you will\nneed to obtain permission directly from the copyright holder. To view a\nAnother potential limitation to our findings is that we\ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\ndo not have objective evidence that the aphantasic partici-\npants lack visual imagery. To determine whether participants\nhave aphantasia, we used the VVIQ (Marks, 1973). This References\nquestionnaire requires participants to make subjective judg-\nments on the vividness of their visual imagery when reading Albers, A. M., Kok, P., Toni, I., Dijkerman, H. C., & de Lange, F. P.\nshort scenarios. Although there do exist some limitations (2013). Shared representations for working memory and mental\nimagery in early visual cortex. Current Biology, 23(15), 1427–\nto using a subjective questionnaire, previous research sug-\n1431. https://d oi.o rg/1 0.1 016/j.c ub.2 013.0 5.0 65\ngests there is a strong relationship between VVIQ scores and\nAnderson, R. J., Dewhurst, S. A., & Dean, G. M. (2017). Direct and\nmore objective measures of aphantasia. Keogh and Pearson generative retrieval of autobiographical memories: The roles of\n(2024) found that 88% of participants with a VVIQ score visual imagery and executive processes. Consciousness and Cog-\nnition, 49, 163–171. https://d oi.o rg/1 0.1 016/j.c oncog.2 017.0 2.0 10\n<32 (the criterion we used here) showed no priming effect\nBarsalou, L. W. (1999). Perceptual symbol systems. Behavioral and\nin a binocular rivalry task. We are therefore confident that Brain Sciences, 22(04), 577–660.\nthe VVIQ is a good proxy for vividness of visual imagery. Barsalou, L. W. (2008). Grounded Cognition. Annual Review of Psy-\nIn conclusion, while people with aphantasia are impaired chology, 59(1), 617–645. https://d oi.o rg/1 0.1 146/a nnure v.p sych.\n59.1 03006.0 93639\nin conscious, voluntary imagery, our results suggest that they\nBarsalou, L. W., Santos, A., Simmons, W. K., & Wilson, C. D. (2008).\ncan engage in unconscious, involuntary mental simulation\nLanguage and simulation in conceptual processing. In M. de Vega,\nA. Glenberg, & A. Graesser (Eds.), Symbols, embodiment, and\nmeaning (pp. 245–283). Oxford Academic.\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2015). Fitting linear\nmixed-effects models using lme4. Journal of Statistical Software,\n2 Seven participants reported impaired imagery in one or more 67(1), 1–48. https://d oi.o rg/1 0.1 8637/j ss.v 067.i 01\nmodalities, and five were unsure.\n\nMemory & Cognition\nCabbai, G., Racey, C., Simner, J., Dance, C., Ward, J., & Forster, S. Jacobs, C., Schwarzkopf, D. S., & Silvanto, J. (2018). Visual working\n(2024). Sensory representations in primary visual cortex are not memory performance in aphantasia. Cortex, 105, 61–73.\nsufficient for subjective imagery. BioRxiv. https://d oi.o rg/1 0.1 101/ Kan, I. P., Barsalou, L. W., Olseth Solomon, K., Minor, J. K., &\n2024.0 1.1 0.5 74972 Thompson-Schill, S. L. (2003). Role of mental imagery in a\nCayol, Z., Rotival, C., Paulignan, Y., & Nazir, T. A. (2020). “Embod- property verification task: FMRI evidence for perceptual repre-\nied” language processing: Mental motor imagery aptitude predicts sentations of conceptual knowledge. Cognitive Neuropsychology,\nword-definition skill for high but not for low imageable words i",
  "char_count": 50000,
  "truncated": true,
  "structure": {
    "title": "Memory & Cognition",
    "authors": [
      "J. Speed",
      "Ken Mc",
      "E. Geraerds",
      "The Author"
    ],
    "abstract": "Intentional visual imagery is a component of numerous aspects of cognition. Related to visual imagery, mental simulation\nplays a role in language comprehension: modality-specific regions of the brain are activated as an implicit part of people\nunderstanding language. The degree of overlap between the processes underlying conscious, voluntary visual imagery versus\nless conscious, more automatic mental simulation is unclear. We investigated this issue by having aphantasics (people who\nare unable to experience conscious voluntary visual imagery) and control participants perform a property verification task\nin which they were asked whether a property is a physical part of an object (e.g., is mane a physical part of a lion?). We\nmanipulated the false trials so that the two words either were associated (semantically related) but did not form an object–\npart combination (monkey–banana), or were not associated (apple–cloud). Solomon and Barsalou (Memory & Cognition,\n32, 244–259, 2004) demonstrated that word association influenced responses when the words in the false trials were not\nassociated, whereas when they were associated, perceptual measures most strongly influenced the results, indicating mental\nsimulation. In the present study, control participants and aphantasics demonstrated similar evidence of the use of both mental\nsimulation and word association when verifying whether the words formed an object–part combination. These results suggest\nthat visual imagery and mental simulation are at least somewhat separable cognitive processes.\nKeywords Aphantasia · Mental simulation · Mental imagery · Embodiment\nHumans can voluntarily and purposefully create internal a separate, less conscious, more automatic process, known\nvisual images in their mind, known as visual imagery. Vis- as mental simulation, is used (Mak & Faber, 2024; Muraki\nual imagery is critically involved in many cognitive tasks. et al., 2023b).\nFor example, it has a role in working memory (Keogh & Evidence fr",
    "sections": [],
    "keywords": [],
    "references_found": true
  },
  "extraction_method": "pdfplumber"
}