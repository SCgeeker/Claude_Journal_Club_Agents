{
  "file_path": "D:\\core\\Research\\Program_verse\\+\\pdf\\Kang-2020.pdf",
  "file_name": "Kang-2020.pdf",
  "full_text": "Memory&Cognition(2020)48:390–399\nhttps://doi.org/10.3758/s13421-019-00977-7\nThe influence of state change on object representations\nin language comprehension\nXinKang1,2 &AnitaEerland3&GitteH.Joergensen4,5&RolfA.Zwaan6&GerryT.M.Altmann4,5\nPublishedonline:17October2019\n#ThePsychonomicSociety,Inc.2019\nAbstract\nTounderstandlanguagepeopleformmentalrepresentationsofdescribedsituations.Linguisticcuesareknowntoinfluencethese\nrepresentations.Inthepresentstudy,participantswereaskedtoverifywhethertheobjectpresentedinapicturewasmentionedinthe\nprecedingwords.Crucially,thepictureeithershowedanintactoriginalstateoramodifiedstateofanobject.Ourresultsshowedthat\ntheendstateofthetargetobjectinfluencedverificationresponses.Whennolinguisticcontextwasprovided,participantsresponded\nfaster to the original state of the object compared to the changed state (Experiment 1). However, when linguistic context was\nprovided,participantsrespondedfastertothemodifiedstatewhenitmatched,ratherthanmismatched,theexpectedoutcomeofthe\ndescribed event (Experiment 2 and Experiment 3). Interestingly, as for the original state, the match/mismatch effects were only\nrevealed after reading the past tense (Experiment 2) sentences but not the future-tense sentences (Experiment 3). Our findings\nhighlighttheneedtotakeaccountofthedynamicsofeventrepresentationinlanguagecomprehensionthatcapturestheinterplay\nbetweengeneralsemanticknowledgeaboutobjectsandtheepisodicknowledgeintroducedbythesententialcontext.\nKeywords Objectstate .Mentalrepresentation .Languagecomprehension .Tense .Pictureverification\nIntroduction\n2015;Morford&Goldin-Meadow,1997).Thisabilitytouse\ndisplaced reference may be unique to humans (Hockett,\nOne of the dominant features of human language communi- 1960; Liszkowski et al., 2009) and is linked to the social-\ncationistointentionallytalkaboutabsententitiesinthepast cognitive skills of humans and grammatical system of lan-\nand future that are not immediately spatially or temporally guages(Bergen&Chang,2005).Forexample,auxiliaryverbs\nnear the speaker and the listener (Cuccio & Carapezza, such as Bwill^ and Bwere^ in English are used to indicate\nwhether an event occurred before or after the moment of\nspeaking or events under discussion. Altmann and Kamide\n(2007)revealedthatvisualattentioncanbedirecteddifferent-\n* XinKang\nly to the visual scene depending on whether the sentences\nxin.kang@cuhk.edu.hk\nwere presented in past-tense or the future-tense conditions.\nAnitaEerland Participants launched more anticipatory eye movements to-\na.eerland@uu.nl wards a full glass of beer in the future tense (e.g., The man\nwill drink...) than in the past tense (e.g., The man drank...).\n1 LinguisticsandModernLanguages,TheChineseUniversityofHong\nBergen and Wheeler (2010) showed that when we process\nKong,HongKongSAR,China\nlanguagethatdescribesperceivablescenesorperformableac-\n2 BrainandMindInstitute,TheChineseUniversityofHongKong,\ntions,theactivationofperceptualandmotorsystemswasin-\nHongKongSAR,China\nfluenced bythe grammatical markers oftense.For example,\n3 DepartmentofLanguages,LiteratureandCommunication,Utrecht\nwhen hand motion was described in progressive sentences\nUniversity,Utrecht,TheNetherlands\n(e.g., John is closing the drawer), there was a facilitation\n4 DepartmentofPsychologicalSciences,UniversityofConnecticut,\neffectformanualactioninthesamedirectionofparticipants,\nStorrs,UnitedStates\nbut no such effect was found when the sentences were in\n5 InstitutefortheBrainandCognitiveSciences,Universityof\nperfecttense(e.g.,Johnhasclosedthedrawer).\nConnecticut,Storrs,UnitedStates\nThesefindingsareinlinewiththeoriesofmental/situation\n6 DepartmentofPsychology,Education,andChildSciences,Erasmus\nmodels(Johnson-Laird,1983;vanDijk&Kintsch,1983)and\nUniversityRotterdam,Rotterdam,TheNetherlands\n\nMemCogn(2020)48:390–399 391\nperceptual-symboltheoriesofcognition(Barsalou,1999)that representations so as to integrate the most recent information\nunderstandinglanguageinvolvestheconstructionofamental and deactivate irrelevant information. It is not always the case\nsituation as a Bsimulation^ of real-world experiences in the thatwehavetoencodeeventsinassociationwithotherobjects.\nspatiotemporalframework,thoughtowhatdegreeperceptual Linguisticinformation,suchasthetenseofsentences,canalsobe\nsystemsareinvolvedintheorganizationofobjectknowledge used as a cue for Btime shift^ (e.g., Altmann & Kamide,\nin the brain is still under debate (see Mahon & Caramazza, 2007; Ferretti, Kutas, & McRae, 2007; Madden & Zwaan,\n2011). According to these theories, concepts of objects are 2003). Besides, previous studies have not clarified whether the\nperceptual symbols that arise during perceptual and motor object-state has been tracked, maintained, and updated in the\nexperiences, which can later activate previous experiences eventmodels.Forexample,anobjectmaygothroughchanges\nand the relevant neural systems. For example, if we think duetoanexternalaction(e.g.,Thechefchoppedtheonion).An\naboutBeatinganapple,^wemayactivatetheneuralsystems onionwouldlookdifferentbeforeandafteritischopped.Inthis\nof vision, action, touch, taste, and smell that are engaged in case, the end state of the onion can be distinguished from its\nourpreviousexperiences.Thissimulation,ormentalmodels, initialstateandintermediatestatesfromthefeaturesoftheonion\nmayincludevisualinformationofaredandroundobject,and itself.Dowealsoencodetheconflictingstatesoftheonioninour\nsensorimotorinformationofeatingjuicyandcrunchypieces. eventmodels?\nUsingthepictureverificationparadigm,StanfieldandZwaan Sofar,thereislimitedempiricalevidenceoftheencodingof\n(2001)askedparticipantstoreadsentenceslikeBThecarpenter object state-change in language comprehension (but\npoundedthenailintothewall,^andtoverifywhetheranobject see Altmann, 2017; Hindy, Altmann, Kalenik, & Thompson-\ndisplayed on a picture (e.g., a nail) was mentioned in the sen- Schill, 2012; Solomon, Hindy, Altmann, & Thompson-Schill,\ntence.Critically,theobjectinthepictureeithermatchedormis- 2015). Hindy et al. (2012) revealed that reading sentences that\nmatchedtheimpliedorientation.Althoughtheobject’sorienta- describedachangeofstateprovidesachallengetoourcognitive\ntionwasirrelevanttothetask,participantsreactedfastertothe system;multiplerepresentationsoftheobjectindifferentstates\npicturedobject(e.g.,ahorizontallyorientednail)thatwascom- may be activated and we have to choose the situationally\npatiblewithitsimpliedorientationasdescribedinthesentence appropriateone.Solomonetal.(2015)furtherrevealedthatcom-\n(BThecarpenterhammeredthenailintothewall^)thanthein- petitionbetweenobjectstates(e.g.,anonioninitsoriginalstate\ncompatibleorientation(BThecarpenterhammeredthenailinto oritssubsequentchoppedstate)isonlyrevealedwhenthestates\nthefloor^).Suchmatch/mismatcheffectsbetweenlinguisticin- areassociatedwiththesameobject,butnotadifferentversionof\nformation and visual presentation were found when different thatobject(e.g.,oneonioninitsoriginalstate,andanotheronion\nproperties of objects were manipulated, including orientation inachoppedstate).Thus,itislikelythatwhenachangeofstate\n(Stanfield&Zwaan,2001;Wassenburg&Zwaan,2010),shape event occurs, the object is linked to multiple Bstates^ of itself\n(Huettig & Altmann, 2007; Yee, Huffstetler, & Thompson- acrosstime–beforeandafterthischange.Therefore,anobjectin\nSchill,2011;Zwaan,Stanfield,&Yaxley2002),motiondirection themodifiedstatehasitsownBhistory^thatincludesitsassoci-\n(Zwaan, Madden,Yaxley, &Aveyard, 2004), size (deKoning, ation with its prior original self and with changes to its states\nWassenburg, Bos, & van der Schoot, 2017), color (Connell, across time. Altmann and Ekves (2019) further proposed the\n2007; Hoeben-Mannaert, Dijkstra, & Zwaan, 2017; Huettig & Bevents as intersecting object histories^ (IOH) model that\nAltmann, 2011; Zwaan & Pecher, 2012), visibility (Yaxley & encodingevents(whetherwedirectlyexperiencethemorlearn\nZwaan,2007),distance(Winter&Bergen,2012),andnumerical about them through language) involves constructing dynamic\ncongruence(Patson,2016;Šetić&Domijan,2017). representationsofintersectingobjecthistories.Ifmentalsimula-\nHowever, in these studies event models are not established tionsofsituationsareanintegralpartofunderstandinglanguage,\naround the target objects alone but draw information from the can we expect match/mismatch effects after the object experi-\nsurrounding environment such as location (e.g., a nail into the encesachangeofstate?\nfloor/wall),otherobjects(e.g.,wine–wineglass),andtime(e.g., Inthepresentstudy,weaimedtoexplorewhetherobjectstate-\nanhourlatervs.amonthlater).Theoriesofeventmodelshave changeinfluencesthespeedofpictureverification.Weexpected\nrecognized that events can be encoded across multiple dimen- to find quicker response times when the object representation\nsions (Zwaan, Langston, & Graesser, 1995; Zwaan & matchedthepictureprobecomparedtowhenitmismatchedthe\nRadvansky, 1998; Zwaan, 2016), including location (e.g., probe.Experiment1wasintendedtoestablishbaselineresponses\nGlenberg, Meyer, & Lindem, 1987; Kukona, Altmann, & toprobepicturesthatshowedconflictingstatesoftargetobjects.\nKamide, 2014; Radvansky, 2005; Radvansky & Copeland, In Experiment 2, we manipulated object state-change by using\n2006; Radvansky & Copeland, 2010), time (Radvansky, twodifferentverbs–oneindicatingaminimal/nochangeandthe\nZwaan, Federico, & Franklin, 1998; Speer & Zacks, 2005; other a substantial change. An example is The woman chose/\nZwaan,1996),goals,andagents.Weconstruct,update,andre- dropped the ice cream. The task for participants was to verify\ntrievethesituationmodelsbasedonthesedimensions.Whena whether the probe picture that appeared afterwards was men-\nchange occurs in any dimension, we update our mental tioned in the sentence they just read. Our hypothesis was that\n\n392 MemCogn(2020)48:390–399\ndespitetheirrelevanceofobjectstatestotheverificationtask,the 32 high-frequency object names (e.g., ice cream, banana,\nobject states that are activated in language would influence the rope,candle)andpairedeachnamewithoneoftwopictures\nresponsestoprobepictures.Thus,wepredictedthatparticipants of the object – one showing the object in the original state\nwould react faster to a probe picture when it matched the de- (e.g.,anuprightice cream) and one showingthe objectina\nscribed state of the target object than when it mismatched the modifiedstate(e.g.,adroppedicecream).\nobjectstate.Experiment3furtherexploredwhetherthetenseof\nsentenceswouldfurthermediatetheactivationofobjectstatesin\nMethod\nlanguagecomprehensionwhenthesentenceswereinfuturetense.\nDatawerecollectedviaAmazon’sMechanicalTurk(MTurk,\nhttp://www.mturk.com) using the sentence-picture verification Participants We recruited 118 participants (54 female, mean\nparadigmfollowingZwaanandPecher(2012).Allthematerials age 36.19 years, range 19–64) through MTurk. All partici-\nand rawdata for our study can be found on the Open Science pants were residents of the USA and received US$1.50 for\nFramework (OSF) (https://osf.io/cvrm3/). The key independent their participation, which lasted approximately 15 min. One\nvariablewaswhetherthestateofthepicturewascompatibleor participant was excluded for reporting a non-English native\nincompatiblewiththeoriginalstateandmodifiedstateofobject language. With the exclusion of this participant our sample\ndescribedinthesentences.Oneachtrial,participantsreadaword included117nativeEnglishspeakers.\n(e.g.,icecream)orasentence(e.g.,Thewomandroppedtheice\ncream)andthenindicatedwhetherasubsequentpictureshowing Materials Each participant saw one of two lists that\nan ice cream was mentioned in the text. Visual probes were counterbalanced items and conditions of experimental trials.\ncommitted to a particular shape of the target object and thus CrucialtothegoalofExperiment1,theobjectname(e.g.,ice\nallowed us to assess the activation levels of different forms of cream)intheexperimentaltrialscouldbefollowedbyapic-\nthesameentity.Accuracyandreactiontimestotheprobepictures ture showing this object either in its original state (e.g., an\nwererecorded.Responsetimes(RTs)werecalculatedovercor- upright ice cream) or in its modified state (e.g., a dropped\nrecttrialsonlyandRTsthatwereshorterthan300msorlonger icecream)thatarecausedbyexternalforcesbutnotaninter-\nthan3,000mswereexcluded.Thelinearmixed-effectsmodels nalaction(e.g.,bloomingflowers)(seeWhite,1991, for the\n(LMMs) using the lme 4 package (Bates et al., 2015; Baayen, distinction between external/internal causal attribution).\nDavidson,&Bates,2008)ofR(RCoreTeam,2016)wereused Figure1illustratestwoexamplepairsofprobepictures.\nforstatisticalanalysis.Thelsmeanspackage(Lenth,2016)was We created four practice trials (including two Byes^ re-\nusedtoconductposthoccomparisonsforsignificantinteraction sponses and two Bno^ responses), 32 experimental trials re-\neffectswithTukeyadjustmentsofp-values.Table1summarizes quiringByes^responses(e.g.,theobject’snameBicecream^\nfixedeffectsofLMMsinallthreeexperiments. followedbyapictureofanicecream),and32fillersrequiring\nBno^ responses(e.g.,theobject’snameBbox^ followedbya\npictureofaball).Allpictureswerefromacommercialclipart\nExperiment 1 website and wereeditedtobestmatch the intended statesof\nthe object. The pictureswere resized toa maximum of3 in.\nheightand3in.width.\nWe conducted our first experiment using the word-picture\nverification paradigm to identify the baseline responses to-\nProcedureTheexperimentwaspresentedonlineintheQualtrics\nwardsourpicturestimuli.Thisallowedustodeterminewheth-\nsurvey research suite (http://www.qualtrics.com). Each trial\neronestatewouldberespondedtodifferentlyfromtheother\nstatewhenonlytheobject’snamewasmentioned.Weselected started with the presentation of a left justified and vertically\ncentered fixation cross on the computer screen for 1,000 ms,\nTable 1 Fixed effects estimated with linear mixed models in all immediately followed by an object name (e.g., ice cream),\nexperiments centered atthe same location asthe fixation cross. Participants\npressed the spacebar when they had read and understood the\nFixedeffects Coefficient SE t p\nobject name. After the keypress, the object name (e.g., ice\nExperiment1 Picturetype 117 18 6.53 <.001 cream) was replaced by a fixation-cross that appeared for 500\nExperiment2 Picturetype 153 18 8.58 <.001 ms,andthenimmediatelyfollowedbyapicture(e.g.,anupright\nEventtype 83 18 4.69 .615 ice cream). Participants were instructed to indicate as fast and\naccuratelyaspossiblewhethertheobjectdisplayedinthepicture\nInteraction 153 25 6.12 <.001\nmatched the object name they just read (yes/no) by pressing a\nExperiment3 Picturetype 175 49 5.18 <.001\nbuttononthekeyboard(m-key/c-key,respectively).Allexperi-\nEventtype 151 34 4.48 .001\nmental trials required a Byes^ response, whereas all filler trials\nInteraction 145 47 3.06 .002\nrequiredaBno^response.Thenexttrialstarted500msafterthe\n\nMemCogn(2020)48:390–399 393\nFig.1 TwoexamplepairsofprobepicturesusedinExperiments1–3.Theoriginalstatedepictsacanonicalorprototypicalformoftheobject,whilethe\nmodifiedstatewasusuallycausedbyanexternalaction(e.g.,drop)\nresponsewasgiven.Experimentalandfillertrialswerepresented MaterialsandprocedureWecreatedfourlistsofstimuli(two\ninrandomorder. types of events x two types of pictures) to counterbalance\nitems and conditions. The procedure of Experiment 2 was\nResultsanddiscussion\nidenticaltothatofExperiment1.Participantsread32exper-\nimentalsentencesthateitherdescribedasubstantialchangeof\nWe estimated the fixed effects of Picture type (Original vs. anobject’sstate(e.g.,BThewomandroppedtheicecream^)or\nModified) with subjects and items as random effects in the minimal/nochange(e.g.,BThewomanchosetheicecream^).\nfirstmodel. After reading the sentences, participants pressed the SPACE\nbarandapictureprobeappearedshowingeithertheoriginal\nmodel1< −lmer(RT~Picture+(1|Subject)+(1|Item))\nstateorthemodifiedstateofthatobject.Inadditiontothese32\nexperimental items that required Byes^ responses, 32 filler\nThesecondmodelisarandom-intercept-and-slopesmodel items that required Bno^ responses were added (e.g., BThe\nwithoutfixedeffects. mankickedtheball^;apictureofabox).Itemswerepresented\ninrandomorder.\nmodel2< −lmer(RT~1+(1|Subject)+(1|Item))\nResultsanddiscussion\nThe models were fit by restricted maximum likelihood\n(REML).Toassessthegoodnessoffit,wecomparedthemodels\nWe adopted the same statistical analysis procedure as\nusingtheχ2-distributedlikelihoodratioanditsassociatedp-val-\nExperiment 1. The fixed effects were Picture type (Original\nue. The model with a smaller Akaike Information Criterion\nvs.Modified)andEventtype(Substantialchangevs.Minimal\n(AIC)andtheBayesianInformationCriterion(BIC)wasconsid-\nchange). Random effects included subjects and items. The\neredasabetterfit.Theresultsshowedthatparticipantsresponded\ngoodnessoffitwasassessedbycomparingtheAICandBIC\nsignificantlyfastertotheoriginalstate,χ2(2)=41.177,p<.001,\nvaluesandχ2-distributedlikelihoodratioanditsassociatedp-\nsuggestingtheoriginalstate(LSMEANS:893±50ms)seemsto\nvalue.WefoundasignificantfixedeffectofPicturetype,χ2\nhaveanadvantageinresponsetimescomparedtothemodified\n(1)=35.85,p<.001withfasterreactiontimestotheoriginal\nstate(LSMEANS:1009±50ms)(seeFig.2)\nstate thantothe modifiedstate.Nofixed effectoftheEvent\ntypewasfound.Nonetheless,therewasasignificantinterac-\ntionbetweenPicturetypeandEventtype,χ2(1)=37.322,p<\nExperiment 2\n.001. Post hoc comparisons indicated that the original state\nwasverifiedfasterwhenthesentenceimpliedaneventinvolv-\nInExperiment2,weexaminedwhetherthelinguisticcontext\ning a minimal change of state (LSMEANS: 1,091 ± 33 ms)\nmaymodulatepictureverificationresponses.\nthanasubstantialchangeofstate(LSMEANS:1,161±34ms;\np < .001), while the modified state was verified faster when\nMethod thesentenceimpliedaneventinvolvingasubstantialchange\nofstate(LSMEANS:1,161±33ms)thanaminimalchangeof\nParticipantsWerecruited227participants(100female,mean state(LSMEANS:1,244±34ms,p<.001)(seeFig.3).\nage 35.07 years, range 18–65) through MTurk. All partici- Therefore,itseemsthatamatchadvantageoftheoriginal\npants were residents of the USA and received US$2.00 for stateandmodifiedstatewasfoundwhentheywerepresented\ntheirparticipation,whichlastedapproximately25min.Thirty- aftertheconditionthatindicatedthe appropriate endstateof\none participants indicated a language other than English as theobject.Insum,theresultsofExperiment2suggestthatthe\ntheirnativelanguage.Withtheexclusionoftheseparticipants, linguistic context has an impact on the activation of object-\noursampleincluded196nativeEnglishspeakers. state representations. The original state of an object was\n\n1400\n1200\n1000\nModified Original\nProbe pictures\nverifiedfasterwhenthesentencesdescribedaminimalchange the cues for such event sequences. Our findings show that\nofstate,butwhenasubstantialchangeofstatewasdescribed these explicit cues may not be necessary as the states of the\nthemodifiedstatewasverifiedfaster.Despitethefactthatthe objectcanbedescribedbyusingtheverbs(e.g.,drop),which\noriginal state was verified faster than the modified state in will also trigger the activation of the corresponding object\nExperiment 1, the modified state gained a match advantage statethatistheappropriateendstateoftheevent.\nwhenitwastheexpectedendstateoftheevent.\nOurfindingsareconsistentwithpreviousresearchshowing\nExperiment 3\nthatcontextuallyappropriateperceptualinformationaboutde-\nscribedobjectsisactivatedinlanguagecomprehension(e.g.,\nStanfield&Zwaan,2001;Zwaan,Stanfield,&Yaxley,2002; The first two experiments showed that (1) without any lin-\nseealsoHoeben-Mannaertetal.,2017),andtheevidenceon guistic context, people mentally represent the original state\nthe competition between multiple object states in language of an object, and (2) the modified state has a match advan-\ncomprehension (e.g., Hindy et al., 2012). Importantly, this tagewhenlinguisticcontext indicates a changecomparedto\nexperimentdemonstratesthattheinternalstructureofanarrat- no change. When we read the past tense version of a sen-\nedsequenceofeventscanbemappedwiththerepresentation tence (e.g., The woman dropped the ice cream), relative to\nofobjects.Previousstudieshaveoftenspecifiedthelocation the time of the hearer, the event has happened in the past,\n(e.g.,onthewall/floor)orthetime(e.g.,after1day/1year)as meaning that the ice cream is already in its dropped state.\n)sm(\nsemit\nesnopseR\n394 MemCogn(2020)48:390–399\nFig.2 Meanresponsetimesof\ntheprobepicturesafterreading\ntheobjectnameinExperiment1.\nDataareshownasLSmean±SE.\nThey-axisshowstheresponse\ntimestoprobepicturesinmilli-\nseconds(ms)\nPicture\nModified\nOriginal\n\n1500\n1400\n1300\n1200\n1100\n1000\nModified Original\nProbe pictures\nHowever,ifasentenceisinthefuturetense(e.g.,Thewom- InExperiment3,weaimedtoinvestigatewhetherthetenseof\nanwilldroptheicecream),relativetothetimeofthehearer, asentencemodulatestheactivationofthemostprominentstates\nthe ice cream is original, and although a change in state is of the object. Previous studies have shown that grammatical\ndescribed, if the hearer were to act on the ice cream, it tensemayplayaroleinconstructingmentalrepresentations.In\nwould be in the original state. Thus, theoretically we would Bergen and Wheeler (2010), participants read sentences that\ninhibit the activation of the changed state of the ice cream wereinthepresentprogressivetense(Experiment1:e.g.,Carol\nand keep the original state as being more accessible. When istakingoff/puttingonherglasses)orinthepresentperfecttense\nthe participant-centric current state of the world entails an (Experiment2:e.g.,Carolhastakenoff/putonherglasses)and\noriginalice-cream,but a future state of the world entailsthe decidedifthedescribedactionrequiredmovementofthehand\ndropped ice cream – will the representation associated with towardorawayfromthebody.Theyfoundanaction-sentence\nthe current state be the more accessible, or will the repre- congruencyeffectfortheprogressivesentencesinExperiment1\nsentationwiththeas-yetun-encounteredfuturestatebemore butnotthe perfect sentences in Experiment 2,arguingthat the\naccessible? actions in Experiment 2 were already completed and hence\n)sm(\nsemit\nesnopseR\nMemCogn(2020)48:390–399 395\nFig.3 Meanresponsetimesof\ntheprobepicturesafterreading\npast-tensesentencessuchasBThe\nwomandropped/chosetheice\ncream^inExperiment2.Dataare\nshownasLSmean±SE.They-\naxisshowstheresponsetimesto\nprobepicturesinmilliseconds\n(ms)\nEvent\nMinimal\nSubstantial\n\n1500\n1400\n1300\n1200\n1100\n1000\nModified Original\nProbe pictures\nrequirednosimulationoftheaction.Ifthisisthecase,consider nativelanguage.Withtheexclusionoftheseparticipants,our\nBThewomanwilldroptheicecream,^whichmightestablishtwo sampleincluded205nativeEnglishspeakers.\nconflictingstatesoftheobject(i.e.,thecurrentoriginalstateand\nthefuturemodifiedstate).Willtherebeamatchadvantageforthe Materials and procedure Experiment 3 was identical to\noriginalstategiventhatapossiblechangeofstatehasnothap- Experiment 2 with the exception that all single sentences in\npenedyet? thisexperimentusedfuturetenseratherthanpasttense.\nMethod Resultsanddiscussion\nParticipantsWerecruited211participants(104female,mean WefollowedthesamestatisticalprocedureasinExperiment2.\nage 33.87 years, range 18–69) through MTurk. All partici- TheresultssuggestedthattherewasafixedeffectofPicturetype,\npants were residents of the USA and received US$2.00 for χ2(1)=18.18,p<.001thattheoriginalpictureswereresponded\ntheir participation, which lasted approximately 25 min. Six tofasterthanthemodifiedpictures.Therewasafixedeffectof\nparticipants indicated a language other than English as their Eventtype,χ2(1)=10.65,p=.001thatthepicturefollowinga\n)sm(\nsemit\nesnopseR\n396 MemCogn(2020)48:390–399\nFig.4 Meanresponsetimesof\ntheprobepicturesafterreading\nthefuture-tensesentencessuchas\nBThewomanwilldrop/choosethe\nicecream^inExperiment3.Data\nareshownasLSmean±SE.The\ny-axisshowstheresponsetimes\ntoprobepicturesinmilliseconds\n(ms)\nEvent\nMinimal\nSubstantial\n\nMemCogn(2020)48:390–399 397\nsubstantial change was verified faster than a minimal change. closelinkbetweentheconsequencesoftheactionandthegram-\nImportantly,therewasasignificantinteractionbetweenPicture maticaltensesofsentences.Thistightcouplingbetweenaction\ntypeandEventtype,χ2(1)=9.36,p=.002.Posthoccompari- andknowledgeofobjectssupportstheIOHmodel(Altmann&\nsonsshowedthattherewasnosignificantdifferenceinverifica- Ekves, 2019) that language comprehension involves activating\ntion time between a minimal change (LSMEANS: 1,175 ± 49 situatedobjectstatesbeforeandafterobjectstate-change.\nms)andasubstantialchange(LSMEANS:1,169±49ms,p= Onelimitationofthisstudyisthatwemeasuredtheactiva-\n.998) when the probe picture indicated an original state of the tion of object representation at the end of sentence reading,\nobject. However, the modified state was verified significantly whichmayonlybeabletocapturepartoftheactivationpro-\nfaster,whenthesentenceindicatedasubstantialchangeofstate cessing. Another potential confound was that the degree of\nevent (LSMEANS: 1,199 ± 49 ms) than a minimal change of changewasmanipulatedbyusingtwodifferentverbs.Thus,\nstateevent(LSMEANS:1,349±49ms,p<.001)(seeFig.4). theeffectsthatweobservedmightbedrivenbythesemantic\nThese results are partly consistent with the findings of associationsbetweentheactionsandtheperceptualproperties\nExperiment2inthattherewasamatchadvantageforthemod- ofthe objects (e.g.,Bach,Nicholson,& Hudson, 2014).For\nified state in the change situation compared to the no-change example,thedroppedicecreamcouldbeassociatedwiththe\nsituation. That is, when a picture of a Bdropped^ ice cream is Bdrop^actionbutnottheBchoose^action.Withoutanysim-\npresented to participants, they might associate the picture with ulationofthemotororperceptualpropertiesofthesituation,\ntheBdrop^action,butnotnecessarilywiththeBchoose^action. one may even establish the link between the object and the\nHowever,asopposedtoExperiment2,theoriginalstatedidnot consequencesoftheaction.\nshow any match advantage in the minimal change condition In conclusion, our experiments demonstrate that perceptual\ncomparedwiththesubstantialchangecondition.Previousempir- propertiesofobjectscanbeactivatedinlanguagecomprehension\nical studies have shown facilitatory effects between action and andmodulatedbythecontentofthelinguisticinput.Theinter-\naffordances of objects (e.g., Symes et al., 2007). Our findings playbetweengeneralsemanticknowledgeaboutobjectsandthe\nmaybeaccountedbytheequalaffordanceoftheoriginalstatefor episodicknowledgeintroducedbythesententialcontextiscap-\naminimalchangeandasubstantialchangeinthefuturetense.By tured by dynamics of event representation in language\ncomparison,inthepasttense,theoriginalstatematchedtheend comprehension.\nstateoftheminimalchange,butitdidnotaffordfurthersubstan-\ntialchangesanddidnotmatchtheconsequences,leadingtothe Dataaccessibilitystatement Thematerialsanddataforalltheexperiments\ncanbefoundontheOpenScienceFramework(https://osf.io/cvrm3/).\nmatch/mismatcheffect.\nAuthor contributions Contributed to conceptionand design: XK, AE,\nGHJ,RAZ,GTMA\nGeneral discussion\nContributedtoacquisitionofdata:XK,GHJ,GTMA\nContributed to analysis and interpretation of data: XK, AE, GHJ,\nRAZ,GTMA\nIn this study, we reported findings of three experiments that\nDraftedand/orrevisedthearticle:XK,AE,GHJ,RAZ,GTMA\nexploredtheactivationofobjects’mentalrepresentationsinlan-\nApprovedthesubmittedversionforpublication:XK,AE,GHJ,RAZ,\nguage comprehension. More specifically, we investigated the GTMA\ninfluenceofobject-state(originalvs.modified)thatwasmanip-\nulatedbydegreeofchangeoftheevent(aminimalchangevs.a Funding information This research was supported by an Overseas\nsubstantialchange)andgrammaticaltense(pasttensevs.future ResearchScholarshipfromtheUniversityofYorkawardedtoXinKang.\ntense)onpictureverificationresponses.Ourstudyshowedthat\nCompliancewithethicalstandards\ntheoriginalstatewasrespondedtofasterthanthemodifiedstate\nwhen only object name was presented (Experiment 1).\nCompeting interests The authors declare that they do not have any\nNonetheless,whencontextualinformationwasprovided,thede-\ncompetinginterests.\nscribedsituationinlanguagemodulatedtheresponses.Objectsin\nthe modified state were verified more quickly when they was\ndescribed to experience a substantial change than a minimal\nchange sentences in both past tense (Experiment 2) and future References\ntense (Experiment 3). However, objects in their original state\nwere only verified more quickly when they were described to Altmann,G.T.M.(2017).Abstractionandgeneralizationinstatistical\nexperienceaminimalchangethanasubstantialchangecondition learning:implicationsfortherelationshipbetweensemantictypes\nin past tense sentences (Experiment 2) but not in future-tense and episodic tokens. Philosophical Transactions of the Royal\nSocietyofLondon.SeriesB,BiologicalSciences,372(1711).\nsentences. Our results suggested that the activation of the con-\nAltmann, G.T. M., & Ekves, Z.(2019). Events asintersectingobject\ntextuallyappropriateobjectrepresentationwasmodulatedbythe\nhistories: A new theory of event representation. Psychological\ndegree of change. Our findings also indicated that there was a Review.\n\n398 MemCogn(2020)48:390–399\nAltmann, G.T. M., & Kamide,Y. (2007). The real-time mediation of Morford, J. P., & Goldin-Meadow, S.(1997).FromHere and Nowto\nvisualattentionbylanguageandworldknowledge:Linkingantici- There and Then: The Development of Displaced Reference in\npatory(andother)eyemovementstolinguisticprocessing.Journal HomesignandEnglish.ChildDevelopment,68(3),420.\nofMemoryandLanguage,57,502–518. Mahon,B.Z.,&Caramazza,A.(2011).Whatdrivestheorganizationof\nBach,P.,Nicholson,T.,&Hudson,M.(2014).Theaffordance-matching objectknowledgeinthebrain?TrendsinCognitiveSciences,15(3),\nhypothesis:howobjectsguideactionunderstandingandprediction. 97–103.\nFrontiersinHumanNeuroscience,8,254. Nikole D. Patson, (2016) Evidence in support of a scalar implicature\nBarsalou,L.W.(1999).Perceptualsymbolsystems.TheBehavioraland account of plurality.. Journal of Experimental Psychology:\nBrainSciences,22(4),577–609;discussion610–660. Learning,Memory,andCognition42(7):1140-1153\nBates,D.,Mächler,M.,Bolker,B.,&Walker,S.(2015).FittingLinear Bach, P., Nicholson, T., Hudson, M. (2014) Theaffordance-matching\nMixed-EffectsModelsUsinglme4.JournalofStatisticalSoftware, hypothesis:howobjectsguideactionunderstandingandprediction.\nArticles,67(1),1–48. FrontiersinHumanNeuroscience8\nBaayen,R.H.,Davidson,D.J.,&Bates,D.M.(2008).Mixed-effects Radvansky, G. A. (2005). Situation models, propositions, and the fan\nmodeling with crossed random effects for subjects and items. effect.PsychonomicBulletin&Review,12(3):478-483.\nJournalofMemoryandLanguage,59(4),390–412. Radvansky,G.A.,&Copeland,D.E.(2006).Walkingthroughdoorways\nBergen, B., & Chang, N. (2005). Embodied construction grammar in causesforgetting:Situationmodelsandexperiencedspace.Memory\nsimulation-based language understanding. In J.-O. Ostman & M. &Cognition,34(5),1150-1156.\nFried (Eds.), Construction Grammars: Cognitive Grounding and Radvansky, G. A. & Copeland, D. E. (2010). Reading times and the\nTheoreticalExtensions(147–190).Amsterdam:Benjamins detection of event shift processing. Journal of Experimental\nBergen,B.,&Wheeler,K.(2010).Grammaticalaspectandmentalsim- Psychology,Learning,Memory,andCognition,36,210-216.\nulation.BrainandLanguage,112(3),150–158. R Core Team (2016) R: A Language and Environment for Statistical\nComputing. R Foundation for Statistical Computing, Vienna,\nConnell,L.(2007).Representingobjectcolourinlanguagecomprehen-\nAustria.https://www.R-project.org/.\nsion.Cognition,102(3),476-485.\nRadvansky, G. A., Zwaan, R. A., Federico, T., & Franklin, N. (1998).\nCuccio,V.,&Carapezza,M.(2015).Isdisplacementpossiblewithout\nRetrieval from temporally organized situation models. Journal of\nlanguage? Evidence from preverbal infants and chimpanzees.\nPhilosophicalPsychology,28(3),369–386. Experimental Psychology: Learning, Memory, and Cognition, 24,\n1224-1237.\ndeKoning,B.B.,Wassenburg,S.I.,Bos,L.T.&vanderSchoot,M.\nŠetić, M., & Domijan,D.(2017). Numerical congruency effect inthe\n(2017.Mentalsimulationoffourvisualobjectproperties:similari-\nsentence-pictureverificationtask.ExperimentalPsychology,64(3),\ntiesanddifferencesasassessedbythesentence-pictureverification\n159-169.\ntask.JournalofCognitivePsychology.29,420-432.\nSolomon,S.H.,Hindy,N.C.,Altmann,G.T.M.,&Thompson-Schill,S.\nFerretti, T. R., Kutas, M., & McRae, K. (2007). Verb aspect and the\nL.(2015).CompetitionbetweenMutuallyExclusiveObjectStates\nactivation of event knowledge. Journal of Experimental\nPsychology.Learning,Memory,andCognition,33(1),182–196. in Event Comprehension. Journal of Cognitive Neuroscience,\n27(12),2324–2338.\nGlenberg,A.M.,Meyer,M.,&Lindem,K.(1987).Mentalmodelscon-\nSpeer,N.K.,Zacks,J.M.(2005).Temporalchangesaseventboundaries:\ntribute to foregrounding during text comprehension. Journal of\nProcessing and memory consequences of narrative time shifts.\nMemoryandLanguage,26,69–83.\nJournalofMemoryandLanguage,53,125-140.\nHindy,N.C.,Altmann,G.T.M.,Kalenik,E.,&Thompson-Schill,S.L.\nStanfield,R.A.,&Zwaan,R.A.(2001).Theeffectofimpliedorientation\n(2012).Theeffectofobjectstate-changesoneventprocessing:doob-\nderivedfromverbalcontextonpicturerecognition.Psychological\njects compete with themselves? The Journal of Neuroscience: The\nScience,12,153-156.\nOfficialJournaloftheSocietyforNeuroscience,32(17),5795–5803.\nSymes, E., Ellis, R.,& Tucker, M. (2007). Visual object affordances:\nHockett, Charles F. (1960). The origin ofspeech, Scientific American, objectorientation.ActaPsychologica,124(2),238–255.\n203,88-111.\nVan Dijk, T.A., & Kintsch, W. (1983). Strategies of discourse\nHoeben-Mannaert,L.,Dijkstra,K.,&Zwaan,R.A.(2017).Iscoloran\ncomprehension.NewYork:AcademicPress.\nintegralpartofarichmentalsimulation?Memory&Cognition,45,\nWassenburg,S.I.,&Zwaan,R.A.(2010).Readersroutinelyrepresent\n974-982.\nimplied object rotation: the role of visual experience. Quarterly\nHuettig,F.,&Altmann,G.T.M.(2007).Visual-shapecompetitionduring JournalofExperimentalPsychology,63(9),1665–1670.\nlanguage-mediatedattentionisbasedonlexicalinputandnotmodulated\nWhite, P. A. (1991). Ambiguity in the internal/external distinction in\nbycontextualappropriateness.VisualCognition,15(8),985–1018.\ncausal attribution. Journal of Experimental Social Psychology,\nHuettig,F.,&Altmann,G.T.M.(2011).Lookingatanythingthatisgreen 27(3),259–270.\nwhenhearingBfrog^:Howobjectsurfacecolourandstoredobject\nWinter, B., & Bergen, B. (2012). Language comprehenders represent\ncolourknowledgeinfluencelanguage-mediatedovertattention.The object distance both visually and auditorily. Language and\nQuarterlyJournalofExperimentalPsychology,64(1),122–145. Cognition,4(1),1–16.\nJohnson-Laird,P.N.(1983).Mentalmodels.Cambridge,MA:Harvard Yaxley,R.H.,&Zwaan,R.A.(2007).Simulatingvisibilityduringlan-\nUniversityPress. guagecomprehension.Cognition,105(1),229–236.\nKukona,A.,Altmann,G.T.M.,&Kamide,Y.(2014).Knowingwhat, Yee,E.,Huffstetler,S.,&Thompson-Schill,S.L.(2011).Functionfol-\nwhere, and when: event comprehension in language processing. lowsform:Activationofshapeandfunctionfeaturesduringobject\nCognition,133(1),25–31.\nidentification. Journal of Experimental Psychology: General,\nLenth,R.(2016).Least-SquaresMeans:TheRPackagelsmeans.Journal 140(3),348.\nofStatisticalSoftware,Articles,69(1),1–33.\nZwaan, R. A., Langston, M. C., & Graesser, A. C. (1995). The\nLiszkowski, U., Schäfer, M., Carpenter, M., & Tomasello, M.(2009). ConstructionofSituationModelsinNarrativeComprehension:An\nPrelinguisticinfants,butnotchimpanzees,communicateaboutab- Event-IndexingModel.PsychologicalScience,6(5),292–297.\nsententities.PsychologicalScience,20(5),654–660. Zwaan, R. A. (1996). Processing narrative time shifts. Journal of\nMadden,C.J.&Zwaan,R.A.(2003).Howdoesverbaspectconstrain Experimental Psychology: Learning, Memory, and Cognition. 22\neventrepresentations?Memory&Cognition,31,663-672. (5):1196-1207.\n\nMemCogn(2020)48:390–399 399\nZwaan,R.A.(2016).Situationmodels,mentalsimulations,andabstract Zwaan,R.A.,&Radvansky,G.A.(1998).Situationmodelsinlanguage\nconcepts in discourse comprehension. Psychonomic Bulletin & andmemory.PsychologicalBulletin,123,162-185.\nReview,23(4),1028–1034. Zwaan, R. A., Stanfield, R. A., & Yaxley, R. H. (2002). Language\nZwaan,R.A.,Madden,C.J.,Yaxley,R.H.,&Aveyard,M.E.(2004). comprehenders mentally represent the shapes of objects.\nMovingwords: dynamic representations in language comprehen- PsychologicalScience,13(2),168–171.\nsion.CognitiveScience,28(4),611–619.\nZwaan, R.A., & Pecher, D. (2012). Revisiting Mental Simulation in Publisher’s note Springer Nature remains neutral with regard to\nLanguageComprehension:SixReplicationAttempts.PLoSONE,7,\njurisdictionalclaimsinpublishedmapsandinstitutionalaffiliations.\ne51382.",
  "char_count": 36791,
  "truncated": false,
  "structure": {
    "title": "Memory&Cognition(2020)48:390–399",
    "authors": [
      "M.Altmann",
      "Keywords Objectstate",
      "H.Joergensen",
      "A.Zwaan"
    ],
    "abstract": "Tounderstandlanguagepeopleformmentalrepresentationsofdescribedsituations.Linguisticcuesareknowntoinfluencethese\nrepresentations.Inthepresentstudy,participantswereaskedtoverifywhethertheobjectpresentedinapicturewasmentionedinthe\nprecedingwords.Crucially,thepictureeithershowedanintactoriginalstateoramodifiedstateofanobject.Ourresultsshowedthat\ntheendstateofthetargetobjectinfluencedverificationresponses.Whennolinguisticcontextwasprovided,participantsresponded\nfaster to the original state of the object compared to the changed state (Experiment 1). However, when linguistic context was\nprovided,participantsrespondedfastertothemodifiedstatewhenitmatched,ratherthanmismatched,theexpectedoutcomeofthe\ndescribed event (Experiment 2 and Experiment 3). Interestingly, as for the original state, the match/mismatch effects were only\nrevealed after reading the past tense (Experiment 2) sentences but not the future-tense sentences (Experiment 3). Our findings\nhighlighttheneedtotakeaccountofthedynamicsofeventrepresentationinlanguagecomprehensionthatcapturestheinterplay\nbetweengeneralsemanticknowledgeaboutobjectsandtheepisodicknowledgeintroducedbythesententialcontext.\nKeywords Objectstate .Mentalrepresentation .Languagecomprehension .Tense .Pictureverification",
    "sections": [
      {
        "title": "Introduction",
        "position": 1568
      },
      {
        "title": "1 LinguisticsandModernLanguages,TheChineseUniversityofHong",
        "position": 2672
      },
      {
        "title": "2 BrainandMindInstitute,TheChineseUniversityofHongKong,",
        "position": 2863
      },
      {
        "title": "3 DepartmentofLanguages,LiteratureandCommunication,Utrecht",
        "position": 3046
      },
      {
        "title": "4 DepartmentofPsychologicalSciences,UniversityofConnecticut,",
        "position": 3256
      },
      {
        "title": "5 InstitutefortheBrainandCognitiveSciences,Universityof",
        "position": 3448
      },
      {
        "title": "6 DepartmentofPsychology,Education,andChildSciences,Erasmus",
        "position": 3632
      }
    ],
    "keywords": [],
    "references_found": true
  },
  "extraction_method": "pdfplumber"
}