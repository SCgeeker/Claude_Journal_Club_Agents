{
  "file_path": "D:\\core\\Research\\Program_verse\\+\\pdf\\Zwaan-2002.pdf",
  "file_name": "Zwaan-2002.pdf",
  "full_text": "Psychological Science\nhttp://pss.sagepub.com/\nLanguage Comprehenders Mentally Represent the Shapes of Objects\nRolf A. Zwaan, Robert A. Stanfield and Richard H. Yaxley\nPsychological Science 2002 13: 168\nDOI: 10.1111/1467-9280.00430\nThe online version of this article can be found at:\nhttp://pss.sagepub.com/content/13/2/168\nPublished by:\nhttp://www.sagepublications.com\nOn behalf of:\nAssociation for Psychological Science\nAdditional services and information for Psychological Science can be found at:\nEmail Alerts: http://pss.sagepub.com/cgi/alerts\nSubscriptions: http://pss.sagepub.com/subscriptions\nReprints: http://www.sagepub.com/journalsReprints.nav\nPermissions: http://www.sagepub.com/journalsPermissions.nav\n>> Version of Record - Mar 1, 2002\nWhat is This?\nDownloaded from pss.sagepub.com at TZU CHI UNIV LIB on January 14, 2013\n\nPSYCHOLOGICAL SCIENCE\nResearch Report\nLANGUAGE COMPREHENDERS MENTALLY REPRESENT THE\nSHAPES OF OBJECTS\nRolf A. Zwaan, Robert A. Stanfield, and Richard H. Yaxley\nFlorida State University\nAbstract—We examined the prediction that people activate perceptual was being manipulated in the sentence. The object in the drawing was\nsymbols during language comprehension. Subjects read sentences de- presented either in a horizontal or in a vertical orientation, thus creat-\nscribing an animal or object in a certain location. The shape of the ob- ing a match or a mismatch with the orientation implied by the sen-\nject or animal changed as a function of its location (e.g., eagle in the tence. The subjects made speeded recognition responses as to whether\nsky, eagle in a nest). However, this change was only implied by the sen- the object in the picture was mentioned in the sentence.\ntences. After reading a sentence, subjects were presented with a line We tested two competing predictions. Perceptual symbol theories\ndrawing of the object in question. They judged whether the object had assume that people activate and manipulate perceptual symbols during\nbeen mentioned in the sentence (Experiment 1) or simply named the language comprehension, such that an object’s implied orientation in a\nobject (Experiment 2). In both cases, responses were faster when the sentence would be part of the mental representation of that sentence.\npictured object’s shape matched the shape implied by the sentence than Thus, according to such theories, responses would be faster when the\nwhen there was a mismatch. These results support the hypothesis that object’s implied orientation in the sentence matched the object’s ori-\nperceptual symbols are routinely activated in language comprehension. entation in the picture compared with when there was a mismatch be-\ntween the implied and pictured orientations. In contrast, in an amodal\npropositional representation the object’s orientation would not be rep-\nConsider the sentences The ranger saw the eagle in the sky and The\nresented. Thus, according to amodal symbol theories, the match-mis-\nranger saw the eagle in its nest. According to most theories of lan-\nmatch manipulation would not affect response latencies to the picture.\nguage comprehension, the linguistic input would be converted to a\nOur findings supported the perceptual symbol hypothesis. Responses\npropositional representation (e.g., Kintsch, 1998; Kintsch & van Dijk,\nwere significantly faster when there was a match between implied ori-\n1978) such as [[SAW[RANGER,EAGLE]], [IN[EAGLE,SKY]]] and\nentation and pictured orientation than when there was a mismatch.\n[[SAW[RANGER,EAGLE]], [IN[EAGLE,NEST]]]. Thus, the propo-\nThe purpose of the present study was to extend these findings in\nsitional representations for the two sentences would be largely identi-\ntwo ways. First, if language comprehenders represent the implied ori-\ncal, with the exception of the noun specifying the location. However,\nentation of objects, they should also represent their implied shape.\nintuition suggests that this cannot be the whole story. After all, when a\nThus, there should be a mismatch effect when subjects are presented\nbird is in the air, it usually has its wings outstretched, and when it is in\nwithThe ranger saw the eagle in the sky followed by a picture of an\nits nest, it usually has its wings folded. These differences are not cap-\neagle with folded wings and also when subjects are presented with\ntured in an amodal propositional structure like the one just given, al-\nThe ranger saw the eagle in its nest followed by a picture of an eagle\nthough such a structure is routinely assumed by language comprehension\nwith outstretched wings. We tested this hypothesis in two experiments.\nresearchers. Figure 1 illustrates a similar example. The shape of an\nIn Experiment 1, we used the same recognition paradigm as in our\negg is different when it is in the refrigerator than when it is in a skillet.\nprevious study (Stanfield & Zwaan, 2001). However, in a second ex-\nInspired by a philosophical tradition that has thus far remained out-\ntension of our earlier work, we used a naming task in Experiment 2.\nside the mainstream of cognitive science, Barsalou (1999) recently ar-\nThe naming task arguably provides a stronger test of the perceptual\ngued that perceptual representations rather than amodal propositions\nhypothesis in that unlike a recognition task it does not require an ex-\nare the building blocks of cognition. Perceptual symbols are the resi-\nplicit comparison between the sentence and the picture.\ndues of a perceptual experience, stored as patterns of activation in the\nbrain. Because attention is limited, perceptual symbols are typically\nschematic, rather than being akin to high-resolution video clips or EXPERIMENT 1\nhigh-fidelity sound clips. However, unlike amodal propositions, per-\nceptual symbols bear an analog relationship with their referents. Subjects\nBarsalou hypothesized that perceptual symbols are used in perceptual\nFifty-one undergraduate students enrolled in introductory psychol-\nsimulations that make up human cognitive processes.\nogy courses at The Florida State University participated for course\nIn a recent study (Stanfield & Zwaan, 2001), we found support for\ncredit. The data of 7 subjects were discarded because of computer\nthis idea in the domain of language comprehension. We presented sub-\nproblems (not all the data for a given subject were recorded or the data\njects with sentences such as He hammered the nail into the wall orHe\nfile was corrupted). The data of 2 additional subjects were discarded\nhammered the nail into the floor. In the first sentence, the nail’s orien-\nbecause of extremely long median response latencies ((cid:1)1,300 ms).\ntation is horizontal, whereas in the second sentence it is vertical. Each\nsentence was followed by a line drawing of an object. For the experi-\nmental items, this was always the object whose implied orientation Materials\nSeventy-two black-and-white drawings obtained from Snodgrass\nand Vanderwart (1980) and from a popular clip-art package were used.\nAddress correspondence to Rolf A. Zwaan, Department of Psychology, Flor- Of these pictures, 24 were used to construct filler items. The remain-\nida State University, Tallahassee, FL 32306-1270; e-mail: zwaan@psy.fsu.edu. ing 48 experimental pictures formed pairs, with the two members of a\n168 Copyright © 2002 American Psychological Society VOL. 13, NO. 2, MARCH 2002\nDownloaded from pss.sagepub.com at TZU CHI UNIV LIB on January 14, 2013\n\nPSYCHOLOGICAL SCIENCE\nRolf A. Zwaan, Robert A. Stanfield, and Richard H. Yaxley\nTable 1. Object recognition latencies and accuracy in\nExperiment 1 and picture naming times in Experiment 2\nCondition\nMeasure Match Mismatch Neutral\nExperiment 1\nReaction time 697 (202) 761 (210) —\nPercentage correct 97 (6) 93 (7) —\nFig. 1. Different shapes of an egg: in a refrigerator versus in a skillet.\nExperiment 2\nReaction time 605 (115) 638 (128) 617 (125)\npair showing different shapes of the same object. For example, one\nmember of the pair might be a picture of an eagle with wings out- Note. Standard deviations are given in parentheses.\nstretched as if in flight and the other member a picture of an eagle with\nwings drawn in, as if perched. Other animals and objects used in-\ncluded an egg (in a carton vs. in a pan), an onion (in a basket vs. in\nwere used rather than means because of the within-subjects variability.\nbatter), a frog (sitting vs. leaping), a book (on a table vs. on a photo-\nHowever, analyses done on the averages yielded the same statistical\ncopier), and bread (a loaf vs. a slice). Each picture was scaled to oc-\npattern as the analyses with the medians.) We conducted a 2 (condi-\ncupy a square of about 3 in.\ntion: match vs. mismatch) (cid:2) 2 (picture version) (cid:2) 2 (list) analysis of\nSeventy-two sentences were created to accompany the pictures: 24\nvariance (ANOVA), with list as the only between-subjects variable, on\nfiller sentences and 48 experimental sentences. The experimental sen-\nthe recognition response latencies and accuracy.\ntences were organized in pairs, with the two members of each pair im-\nThere was a significant mismatch effect on response latency: Re-\nplying different shapes of the same object. The filler sentences all\nsponses were faster when sentence and picture matched than when\nmentioned an object (by way of a concrete noun) other than the one\nthey mismatched, F(1, 38) (cid:3) 13.14, p(cid:4) .001; F(1, 44) (cid:3) 14.54, p(cid:4)\nthat was presented in the picture, and thus required a “no” response on 1 2\n.0001. The two-way interaction between condition and list was not\nthe recognition task. The experiment was run on a PowerMac 7200/\nsignificant,F(1, 38) (cid:3) 3.55, p(cid:4) .07; F (cid:4) 1. The interaction between\n120 with an Apple Multiple Scan 15 Display using the Psyscope soft- 1 2\ncondition and picture version was significant in the analysis by items\nware program (Cohen, MacWhinney, Flatt, & Provost, 1993). Re-\nonly, F (cid:4) 1; F(1, 46) (cid:3) 7.04, p(cid:4) .015. The three-way interaction in-\nsponses were recorded via the keyboard, using the “x” for “no” 1 2\nvolving all three factors was not significant, F (cid:4) 1; F(1, 44) (cid:3) 2.10,\nresponses and the period key for “yes” responses. 1 2\np(cid:1) .15.\nAnalyses of response accuracy showed that responses were more\nDesign and Procedure accurate when there was a match than when there was a mismatch, but\nWe created four lists that counterbalanced items and conditions. Each this effect was significant in the analysis by subjects only, F 1 (1, 38) (cid:3)\nlist included a different one of the four possible versions (2 sentences (cid:2) 12.69,p(cid:4) .001; F 2 (1, 44) (cid:3) 1.26, p(cid:1) .25. The Condition (cid:2) List in-\n2 pictures) for each object. Each subject saw one of these lists. This pro- teraction was significant in the analysis by items only, F 1 (1, 38) (cid:3)\nduced a 2 (condition: match vs. mismatch) (cid:2) 2 (picture version) (cid:2) 2 1.20, p (cid:1) .25; F 2 (1, 44) (cid:3) 9.05, p (cid:4) .005. The interaction between\n(list) design, with condition and shape (picture version) within-subjects condition and picture version was not significant, F 1 (1, 38) (cid:3) 1.47,\nvariables and list a between-subjects variable. Thus, each subject saw 24 p (cid:1) .2; F 2 (1, 44) (cid:3) 1.75, p (cid:1) .15. The three-way interaction was\nexperimental sentence-picture pairs (12 match and 12 mismatch), requir- not significant by subjects, but was significant by items, F 1 (cid:4) 1;\ning “yes” responses and 24 filler pairs, requiring “no” responses. F 2 (1, 44) (cid:3) 13.04, p(cid:4) .001.\nSubjects were instructed to read each sentence, and then to decide These results support the prediction derived from perceptual sym-\nif the pictured object that followed had been mentioned in the preced- bol theory. Apparently, subjects represented the implied shape of the\ning sentence. Subjects were further told that reaction times were being object when comprehending the sentence, so that responses to the pic-\nmeasured and that it was important for them to make the decisions ture were slower when the picture mismatched the implied shape than\nabout the pictures as quickly as possible. During each trial, subjects when there was a match between the pictured and implied shapes. The\nfirst saw a sentence, left-justified on the screen, that either mentioned goal of Experiment 2 was to examine whether the same effect could be\nor did not mention the object they would later see. They pressed the obtained with a task that does not call for a comparison between the\nspace bar when they had understood the sentence, and then a fixation picture and the sentence. In this experiment, the subjects merely\npoint appeared in the center of the screen for 250 ms, followed by a named the picture after having read the sentence.\npicture. Subjects then determined if the pictured item had been men- We also included a neutral condition in Experiment 2. The sen-\ntioned in the previous sentence. The experiment took approximately tences in this condition did not imply anything about the shape of the\n30 min to complete. object (e.g., The ranger heard the eagle in the forest). We included this\ncondition to explore whether the mismatch effect observed in Experi-\nment 1—and our previous study (Stanfield & Zwaan, 2001)—was due\nResults and Discussion\nto a response facilitation in the match condition or a response inhibi-\nTable 1 displays the mean of the median response latencies as well tion in the mismatch condition. If the results were due to facilitation,\nas response accuracy for each condition. (Median response latencies response times in the neutral and mismatch conditions would be equal;\nVOL. 13, NO. 2, MARCH 2002 169\nDownloaded from pss.sagepub.com at TZU CHI UNIV LIB on January 14, 2013\n\nPSYCHOLOGICAL SCIENCE\nPerceptual Symbols in Language Comprehension\nif the results were due to inhibition, response times in the neutral con- F(2, 40) (cid:3) 4.64, p(cid:4) .025. The neutral condition was marginally sig-\n2\ndition and match condition would be equal. nificantly faster than the mismatch condition in the analysis by sub-\njects only, F(1, 45) (cid:3) 4.01, p(cid:3) .05; F (cid:4) 1.\n1 2\nEXPERIMENT 2\nDiscussion\nSubjects\nThese results extend those of Experiment 1 in that they show a\nmismatch effect even when the task, naming, does not call for a com-\nFifty-seven undergraduate students enrolled in introductory psy-\nparison between the sentence and the picture. It is interesting to note\nchology courses at The Florida State University participated for\nthat the size of this effect was comparable across the two experiments:\ncourse credit. The data of 6 of those subjects were discarded because\nd(cid:3) .32 in Experiment 1 and d(cid:3) .27 in Experiment 2.\nof the same computer problems as in Experiment 1.\nThe results do not support either of the predictions pertaining to\nthe neutral condition. It does not appear that the mismatch effect is\nMaterials\ndue to a facilitation of responses in the match condition relative to the\nThe same line drawings and sentences as in Experiment 1 were mismatch and neutral conditions, given that naming was not signifi-\nused. An additional 24 neutral sentences that did not suggest a particu- cantly slower in the neutral condition than in the match condition.\nlar shape for the relevant object were created for the neutral condition. Similarly, it does not appear that the mismatch effect is due to an in-\nThe experiment was run on a PowerMac 7200/120 with an Apple Mul- hibitory effect in the mismatch condition because naming was not sig-\ntiple Scan 15 Display using Psyscope (Cohen et al., 1993). Responses nificantly faster in the neutral condition than in the mismatch\nwere recorded using a Koss SB-30 headset-microphone attached to a condition. However, the fact that the mean naming time in the neutral\nCarnegie Mellon University button box. condition fell in between the naming times for the match and mis-\nmatch conditions is consistent with a scenario that can be derived from\nperceptual symbol theory. According to this scenario, comprehenders\nDesign and Procedure\nroutinely activate perceptual symbols that include the shape of objects,\nWe created six lists that counterbalanced items and conditions. even when the shape is not implied or articulated by the linguistic in-\nEach list included a different one of the six possible versions (3 sen- put. If this is the case, then given the counterbalancing scheme, a\ntences(cid:2) 2 pictures) for each object. Each subject saw one list. Thus, match between the sentence and the picture would be expected in half\neach subject saw 24 filler items, 8 match items, 8 mismatch items, and the observations and a mismatch would be expected in the other half.\n8 neutral items. This design produced a 3 (condition: match vs. mis- As a consequence, the average naming latencies in the neutral condi-\nmatch vs. neutral) (cid:2) 2 (picture version) (cid:2) 3 (list) design, with list as tion would fall between those of the match and mismatch conditions.\nthe only between-subjects variable. The procedure was nearly identi- This speculative scenario provides a post hoc explanation for the ob-\ncal to that of Experiment 1. The only difference was that, instead of served pattern of results. More extensive research is needed before\ndeciding whether the pictured object had been mentioned by the pre- firmer conclusions can be reached regarding the default representation\nceding sentence, subjects named the object. of object shapes.\nResults\nCONCLUSION\nTable 1 shows the average naming time for each of the three condi-\nOur results, along with those of our previous study (Stanfield &\ntions.1 A 3 (condition: match vs. mismatch vs. neutral) (cid:2) 2 (picture\nZwaan, 2001) and those of other recent studies (Fincher-Kiefer, in\nversion) (cid:2) 3 (list) ANOVA with list as the only between-subjects fac-\npress; Kaschak & Glenberg, 2000; Kellenbach, Wijers, & Mulder,\ntor yielded a significant overall effect of condition by subjects, F(2,\n1 2000), support the idea that people activate perceptual symbols of ref-\n90)(cid:3) 3.71, p(cid:4) .04; F(2, 80) (cid:3) 2.21, p(cid:4) .12. Picture version did not\n2 erents during language comprehension (Barsalou, 1999), even when\nsignificantly interact with condition, F(2, 90) (cid:3) 1.78; F(2, 80) (cid:3)\n1 2 the perceptual characteristics are merely implied rather than explicitly\n2.07,p(cid:1) .13, and neither did list, F(4, 90) (cid:3) 2.20; F (cid:4) 1. The three-\n1 2 stated. Moreover, our results show that the sentential context has a\nway interaction among condition, picture version, and list was signifi-\nstrong and rather immediate impact on the nature of the mental repre-\ncant in the analysis by items only, F (cid:4) 1; F(4, 80) (cid:3) 3.05, p(cid:4) .025.\n1 2 sentation (see also Hess, Foss, & Carroll, 1995; van Berkum, Hagoort,\nFollow-up analyses comparing pairs of conditions showed that the\n& Brown, 1999). These findings are consistent with the idea (e.g.,\nmismatch condition yielded significantly slower responses than the\nLangacker, 1987) that the representation of meaning from linguistic\nmatch condition, F(1, 45) (cid:3) 6.90, p(cid:4) .015; F(1, 40) (cid:3) 3.87, p(cid:4)\n1 2 input is a dynamic process involving malleable perceptual representa-\n.06. No interactions were significant. The neutral condition was not\ntions rather than the mechanical combination of discrete components\nsignificantly different from the match condition, F (cid:4) 1; F(1, 40) (cid:3)\n1 2 of meaning (see also Barsalou, 1999; Glenberg, 1997; MacWhinney,\n2.86,p(cid:3) .10. No two-way interactions were significant (all Fs(cid:4) 1).\n1999). The challenge for future research is to examine in more detail\nHowever, there was a significant three-way interaction involving con-\nthe theoretical and empirical ramifications of such a perceptual view\ndition, picture version, and list in the analysis by items only, F (cid:4) 1;\n1 of language comprehension.\nAcknowledgments—We thank Kelly Danzeisen and Amanda Hall for\n1. One item turned out to be problematic (an undeployed parachute, which\ntheir assistance with data collection and Barbara Kaup and Carol Madden\ncould be mistaken for a backpack) and yielded unusually long naming times. It\nfor helpful feedback on a previous version of this article.\nwas omitted from the analyses.\n170 VOL. 13, NO. 2, MARCH 2002\nDownloaded from pss.sagepub.com at TZU CHI UNIV LIB on January 14, 2013\n\nPSYCHOLOGICAL SCIENCE\nRolf A. Zwaan, Robert A. Stanfield, and Richard H. Yaxley\nREFERENCES Kintsch, W. (1998). Comprehension: A paradigm for cognition. Cambridge, MA: Cam-\nbridge University Press.\nBarsalou, L.W. (1999). Perceptual symbol systems. Behavioral and Brain Sciences,22, Kintsch, W., & van Dijk, T.A. (1978). Toward a model of text comprehension and produc-\n577–660. tion.Psychological Review,85, 363–394.\nCohen, J.D., MacWhinney, B., Flatt, M., & Provost, J. (1993). Psyscope: An interactive Langacker, R.W. (1987). Foundations of cognitive grammar (Vol. 1). Stanford, CA: Stan-\ngraphic system for designing and controlling experiments in the psychology labora- ford University Press.\ntory using Macintosh computers. Behavior Research Methods, Instruments, & Com- MacWhinney, B. (1999). The emergence of language from embodiment. In B.\nputers,25, 257–271. MacWhinney (Ed.), The emergence of language (pp. 213–256). Mahwah, NJ:\nFincher-Kiefer, R. (in press). Perceptual components of situation models. Memory & Cog- Erlbaum.\nnition. Snodgrass, J.G., & Vanderwart, M. (1980). A standardized set of 260 pictures: Norms for\nGlenberg, A.M. (1997). What memory is for. Behavioral and Brain Sciences,20, 1–55. name agreement, image agreement, familiarity, and visual complexity. Journal of\nHess, D.J., Foss, D.J., & Carroll, P. (1995). Effects of global and local context on lexical Experimental Psychology: Human Learning and Memory,6, 174–215.\nprocessing during language comprehension. Journal of Experimental Psychology: Stanfield, R.A., & Zwaan, R.A. (2001). The effect of implied orientation derived from ver-\nGeneral,124, 62–82. bal context on picture recognition. Psychological Science,12, 153–156.\nKaschak, M.P., & Glenberg, A.M. (2000). Constructing meaning: The role of affordances van Berkum, J.J.A., Hagoort, P.M., & Brown, C.M. (1999). Semantic integration in sen-\nand grammatical constructions in sentence comprehension. Journal of Memory and tences and discourse: Evidence from the N400. Journal of Cognitive Neuroscience,\nLanguage,43, 508–529. 11, 657–671.\nKellenbach, M.L., Wijers, A.A., & Mulder, G. (2000). Visual semantic features are acti-\nvated during the processing of concrete words: Event-related potential evidence for\nperceptual semantic priming. Cognitive Brain Research,10, 67–75. (RECEIVED 1/24/01; REVISIONACCEPTED 5/4/01)\nVOL. 13, NO. 2, MARCH 2002 171\nDownloaded from pss.sagepub.com at TZU CHI UNIV LIB on January 14, 2013",
  "char_count": 22897,
  "truncated": false,
  "structure": {
    "title": "Psychological Science",
    "authors": [
      "Mentally Represent",
      "Email Alerts",
      "Language Comprehenders",
      "H. Yaxley",
      "A. Zwaan",
      "Psychological Science",
      "A. Stanfield"
    ],
    "abstract": null,
    "sections": [
      {
        "title": "Discussion",
        "position": 14171
      },
      {
        "title": "Results",
        "position": 17490
      },
      {
        "title": "2 erents during language comprehension (Barsalou, 1999), even when",
        "position": 18160
      },
      {
        "title": "1 of language comprehension.",
        "position": 19928
      },
      {
        "title": "1. One item turned out to be problematic (an undeployed parachute, which",
        "position": 20018
      }
    ],
    "keywords": [],
    "references_found": true
  },
  "extraction_method": "pdfplumber"
}