{
  "file_path": "D:\\core\\Research\\Program_verse\\+\\pdf\\vanZuijlen-2024.pdf",
  "file_name": "vanZuijlen-2024.pdf",
  "full_text": "Memory & Cognition\nhttps://doi.org/10.3758/s13421-024-01533-8\nAutomatic mental simulation in native and non‑native speakers\nSamuel J. A. van Zuijlen1 · Sharon Singh1 · Kevin Gunawan1 · Diane Pecher1 · René Zeelenberg1\nAccepted: 24 June 2023\n© The Author(s) 2024\nAbstract\nPictures of objects are verified faster when they match the implied orientation, shape, and color in a sentence-picture\nverification task, suggesting that people mentally simulate these features during language comprehension. Previous studies\nhad an unintended correlation between match status and the required response, which may have influenced participants’\nresponses by eliciting strategic use of this correlation. We removed this correlation by including color-matching filler\ntrials and investigated if the color-match effect was still obtained. In both a native sample (Experiment 1) and a non-native\nsample (Experiment 2), we found strong evidence for a color-match advantage on median reaction time and error rates. Our\nresults are consistent with the view that color is automatically simulated during language comprehension as predicted by\nthe grounded cognition framework.\nKeywords Mental simulation · Color match · Perceptual symbols system · Sentence-picture verification task · Language\ncomprehension · Non-native speaker · Bilingualism\nIntroduction\nprocesses that they would also have used if they were\nimmersed in the real-world equivalent of what is described\nIf we write our friend about the new car we bought, how does by the language. In the present study we investigated whether\nour friend know exactly what we mean when we say “car”? such mental simulations also underlie understanding of non-\nHow is this meaning of a car represented in her mind when native languages.\nshe comprehends language relating to an object? The world Several studies testing native speakers have obtained\ncomprises many objects, and when we read or talk about evidence for visual mental simulations during language\nthem, we almost instantly understand what is meant and comprehension. When participants are given a verbal\nwhat the most salient features of the object are (given that property verification task (e.g., “Is a banana yellow?”),\nwe have experienced the object before). Because language their responses are influenced by visual characteristics of the\ncomprehension plays such a big part in how humans come properties (Borghi, 2004; Borghi, et al., 2004; Morey et al.,\nto understand and interact with other people, it is important 2021; Solomon & Barsalou, 2004; Spivey & Geng, 2001;\nto understand its mechanisms. A question that has interested Taylor & Zwaan, 2008; Zwaan & Taylor, 2006) and trial-to-\ncognitive scientists is whether perceptual features of objects trial switches in perceptual modality (Ambrosi et al., 2011;\nare represented by readers when they comprehend language. Connell & Lynott, 2011; Marques, 2006, Pecher et al., 2003,\nAccording to grounded cognition theories, the features that 2004; Van Dantzig et al., 2008; Vermeulen et al., 2007).\nare activated during language comprehension are based One of the earliest studies on mental simulations during\non earlier perceptual-motor experiences with the objects language comprehension found that participants were faster\ndescribed in the sentences (Barsalou, 1999; Barsalou et al., and more accurate in verifying that a pictured object (e.g.,\n2003). On this account, people represent the meaning of an upright nail) was mentioned after reading a sentence\nlanguage by mentally simulating the perceptual and motor implying the depicted orientation (e.g., “He hammered the\nnail into the floor”) than after reading a sentence implying\na different orientation (e.g., “He hammered the nail into the\n*\nRené Zeelenberg wall”) (Stanfield & Zwaan, 2001). In this so-called sentence-\nzeelenberg@essb.eur.nl\npicture verification task, participants decide whether\n1 Erasmus University, Woudestein T13-31, PO Box 1738, the object presented immediately after the sentence was\n3000, DR, Rotterdam, the Netherlands\nVol.:(0123456789)\n\nMemory & Cognition\nmentioned in the preceding sentence or not. It seems that However, their study used different sentences in the match\nparticipants mentally simulate the content of the sentence, and mismatch conditions, which introduced a confound\nand that subsequent verification of the depicted object is between condition and stimulus materials, raising questions\nfaster and more accurate when the visual feature implied about the validity of the results.\nby the sentence matches that of the picture even though In the present study we investigated the mental simulation\nthat feature was not explicitly mentioned. Match effects of color using the sentence-picture verification task in native\nhave now been obtained for various sensory features such and non-native speakers of English. Objects (e.g., a leaf) can\nas shape, distance, or size (De Koning et al., 2017; Pecher, take different colors (green, brown), which can be implied\nvan Dantzig, Zwaan, et al., 2009; Sato et al., 2013; Winter by a sentence (“The leaf was on the tree” vs. “The leaf was\n& Bergen, 2012; Zwaan et al., 2004; Zwaan & Pecher, on the ground”). Although initially a mismatch advantage\n2012; Zwaan et al., 2002; Zwaan et al., 2018). Note that was obtained (Connell, 2005; 2007), later studies, using\nthe simulation account of the match effect differs from larger samples, did not report this color-mismatch advan-\nmental imagery, which is largely conscious and concerns tage (Hoeben-Mannaert et al., 2017; Zwaan & Pecher, 2012).\nitself with imagination. Mental simulation is assumed to be Rather, both studies reported a positive match effect of color\nunconscious, and is the underlying process of conceptual (i.e., a match advantage), where images that matched the\nprocessing (Pecher, van Dantzig, & Schifferstein, 2009a, preceding sentence on the object and color produced faster\n2009b; Solomon & Barsalou, 2004; Vermeulen et al., 2008; responses than images that mismatched the color (also see\nZwaan & Pecher, 2012). De Koning et al., 2017). Together, the results across different\nRelatively little attention has been devoted to the role studies suggest that people represent color during language\nof mental simulations in language comprehension of non- comprehension.\nnative speakers. Some researchers have argued that mental Before testing whether match effects can be found for\nsimulations may be less vivid when people read a non-native non-native speakers, we wanted to improve the paradigm\nlanguage. Especially for a second language that is learned by eliminating the potential for strategic responding.\nlater in life, in a formal setting such as school, people may If sensory simulation is an integral part of language\nhave weaker links between language and sensory experiences comprehension, simulations should be automatic\n(Foroni, 2015; Kogan et al., 2020; Norman & Peleg, 2022). whenever language comprehenders process the meaning\nThe strength of mental simulations may depend on profi- of a sentence. A noticeable feature of the sentence-picture\nciency in the second language (e.g., Dijkstra & van Heuven, verification task is that there is a correlation between the\n2002; Monaco et al., 2019; van Heuven & Dijkstra, 2010; match status (match vs. mismatch) and the required (i.e.,\nZhao et al., 2019; but see Bergen et al., 2010). Empirical correct) response (‘’yes’’ vs. ‘’no’’). Consider, to make\nevidence for mental simulation in non-native speakers is this more concrete, studies that have investigated the\nrelatively sparse and seems to come mainly from paradigms color-match effect. Participants in these experiments read\nthat aim to assess involvement of the motor system. There a sentence that is followed by an object picture and decide\nis some evidence that non-native speakers perform mental whether the object is mentioned in the preceding sentence.\nsimulations (Dudschig et al., 2014; Wheeler & Stojanovic, On critical trials (i.e., where the depicted object was\n2006), although this may depend on the extent to which a mentioned in the preceding sentence), typically half consist\nperson’s native language can be mapped onto the meanings of of a color-match trial and half consist of a color mismatch\ntheir non-native language (Ahlberg et al., 2018). In sentence- trial. On filler trials (i.e., where the depicted object was not\npicture verification tasks the evidence for mental simulations mentioned in the preceding sentence, thus requiring a “no”\nin non-native speakers is weak at best. Chen et al. (2020) response), color match is not controlled or manipulated.\npresented items that matched or mismatched in implied shape Because objects can have many different colors this\nin a delayed recognition task (modelled after a study with results in few, if any, filler trials on which the object color\nnative speakers by Pecher, van Dantzig, Zwaan, et al., 2009) matches the color implied by the sentence. Consequently,\nto participants who were native speakers of Cantonese and the color match/mismatch status is correlated with the\nnon-native speakers of English and Mandarin. They found a required response. If the color of the object in the picture\nmatch effect in reaction times only when sentences had been matches that of the implied color in the sentence, there\nread in the participants’ native language and not in either is a high probability that the object was mentioned in the\nof the two non-native languages. Norman and Peleg (2022) sentence.1 On the other hand, if the color of the object\nfound a shape-match effect for native Hebrew speakers when in the picture does not match the implied color in the\nsentences were in Hebrew but not when sentences were in\ntheir non-native language English. Ahn and Jiang (2018),\non the other hand, did obtain similar shape and orientation 1 This probability is 100% if none of the filler trials are color-match\nmatch effects for native and non-native speakers of Korean. trials.\n\nMemory & Cognition\nsentence, the probability that the object was mentioned in designed experiments that aim to eliminate the contribution\nthe sentence is well below 50%.2 If participants pick-up on of strategic processes. Consistent with an automatic\nthis correlation they may use it to aid their responses in the activation view, semantic priming effects are also obtained\nsentence-picture verification task. when the contribution of strategic processes is prevented\nAmple research, using a variety of tasks, stimuli, (e.g., Balota & Lorch, 1986; de Groot, 1983; Pecher et al.,\nand procedures, has shown that people are sensitive to 2002). Thus, to investigate automatic conceptual processes,\ncorrelations between stimuli as well as correlations between it is important to use procedures that eliminate more\nstimuli and responses (e.g., Garcia et al., 1955; Parise et al., strategic contributions to an effect.\n2012; Reber, 1967; Zeelenberg et al., 2004), even without In the present study, we investigated if a color-match\nexplicit instructions to detect, learn, or use such correlations effect in the sentence-picture verification task is also\nto facilitate responding. As an example, consider a well- found when the correlation between the presence of a\nknown study by Neely et al. (1989), who investigated color match and the required response is eliminated. Thus,\nsemantic priming effects in a lexical decision task. In a in contrast to previous studies on the match effect, the\nlexical decision task, participants make binary decisions presence of a match was not predictive of the required\nabout the lexical status (word vs. nonword) of the target response. Crucially, we added color-match filler (i.e.,\nstimulus. A characteristic of the primed lexical decision “no”) trials to the stimuli presented in the experiment.\ntask is that there is a correlation between the relatedness That is, even on trials where the object was not mentioned\nof the prime and the target and the required response. If the in the preceding sentence, the object color could still\nprime and target are semantically related (e.g., cat – dog), match the implied color of the object mentioned in the\nthe target is a word, because nonwords are not semantically sentence (e.g., the sentence implies pink paint and a\nrelated to words. Neely et al. assumed that participants use picture of a pink marshmallow is shown). In doing so,\nthis correlation in the decision process. Participants will be we removed the correlation between color match and\nbiased to give a “word” response if they detect a relation the required response. A match effect in the absence of\nbetween prime and target and they will be biased to give a this correlation provides stronger evidence that match\n“nonword” response if they do not detect a relation between effects are not dependent on mental simulations that are\nprime and target. By manipulating the nonword ratio, Neely strategically employed in the sentence-picture verification\net al. showed that participants are sensitive to the correlation task. In our study, the presence of a color match does\nbetween relatedness of the prime and target and the lexical not inform participants about the required response. If\nstatus of the target. The nonword ratio is the probability language comprehenders, given that they process the\nthat the target is a nonword given that it is unrelated to the sentence at a semantic level, automatically simulate\nprime. If the nonword ratio is high, the absence of a relation properties such as the color of an object mentioned in a\nbetween prime and target is highly predictive for the fact that sentence, we should still obtain a color-match advantage.\nthe target is a nonword. If the nonword ratio is low, however, If, on the other hand, the color-match advantage depends\nthe absence of a relation between prime and target is less on strategically employed mental simulations to aid\ninformative. Neely et al. found larger priming effects with responding in the sentence-picture verification task, no\nhigh nonword ratios, indicating that participants are indeed such advantage would be present because there is no\nsensitive to the correlation between the relatedness of the correlation between color match and the required response.\nprime and target and the lexical status of the target stimulus. If under these circumstances we still find a match effect\nIn addition to these more strategic decisional processes that for native speakers in Experiment 1, we will then proceed\nare biased by this correlation and contribute to the semantic to test a sample of non-native speakers in Experiment 2\npriming effect, researchers have argued that semantic using the same stimulus materials.\npriming is also due to automatic activation processes (e.g.,\nden Heyer et al., 1983; McNamara, 1992; Neely, 1977; Neely\nExperiment 1\net al., 1989). Because strategic processes may have the same\neffects on performance measures as automatic processes,\nMethod\nit is difficult to conclude that the observed priming effects\nare due to automatic processes. Therefore, researchers have\nPreregistration\nPredictions, method (including exclusion criteria), and\n2 This probability is 33% in the following typical case. Half of the\nplanned data analyses of Experiment 1 were preregistered\ntrials consist of ‘’yes’’ trials and half consist of ‘’no’’ trials; half of\non the Open Science Framework (OSF) in advance of data\nthe ‘’yes’’ trials are match trials and half are mismatch trials; for\n‘’no’’ trials, none of the trials are match trials. collection (https://o sf.i o/r 6b7j/).\n\nMemory & Cognition\nParticipants pictures (i.e., eight color-match trials and eight non-match\ntrials) and 16 sentence-picture pairs (also eight color-match\nA total of 371 native speakers of English were recruited trials and eight non-match trials) that were used as fillers.\nfor the study. The data of 300 participants were included As shown in Table 1, on filler trials the object color matched\nin the final analysis (detailed information about participant or mismatched the implied color of the sentence, but the\nexclusion is provided later). The mean reported age was 31.0 depicted object was not mentioned in the preceding sentence.\n(range 18–73) years, 165 participants reported being female. Half of the filler trials were followed by a comprehension\nThey reported their country of birth/country of residence as question with an equal number of ”yes” and ”no” responses\nthe UK (51.4%/57.8%), South Africa (17.3%/18.1%), USA (see Table 1), to ensure that participants did not merely skim\n(6.8%/8.4%), Australia (3.0%/3.5%), Ireland (3.0%/3.0%), the sentences. An additional set of eight sentence-picture\nCanada (2.4%/3.0%), Germany (1.1%/0%), and 26 other pairs and eight comprehension questions was used for\ncountries or did not provide this information (14.3%/6.2%). practice. We used the same practice pairs for all participants.\nParticipants were recruited on Prolific and received £1.25 The experiment was programmed in Inquisit (https://\nfor their participation. Completing the experiment took www.m illis econd.c om/), a software application developed\napproximately 8 min. The posting on Prolific was offered for online psychological testing. All pictures were royalty-\nonly to native speakers of English. Based on the effect free images obtained through the Google images search\nsize reported by Hoeben-Mannaert et al. (2017) for their engine. All images were of an object in one dominant color\nExperiment 1 (d = 0.26), we computed the required against a neutral background. We only selected images of\nsample size to obtain a statistical power of .95 with a two- objects that have limited color variations (e.g., a ripe vs. an\ntailed paired-sample t-test (α = .05) using G*power (Faul unripe tomato). Image height was 50% of the screen. See\net al., 2009). The required sample size amounted to 195 Online Supplementary Materials (OSM) for examples of\nparticipants. To be on the safe side, we decided to test pictures. All text was presented in the letter font Verdana\n300 participants. We included only participants who met (letter height 3% of the screen) against a white background.\nall the following criteria: (1) participants completed the\nexperiment, (2) participants indicated that they were native\nspeakers of English, (3) participants responded correctly Procedure\non at least 80% of the sentence-picture verification trials,\nand (4) participants responded correctly to at least 50% Participants selected the study on Prolific and started the\nof the sentence comprehension questions. The data from experiment from their personal computer or laptop. Upon\nparticipants who failed to meet one or more of these criteria opening the experiment, participants gave informed consent\nwere excluded from the analyses. Removed participants and read a welcome text and instructions. Participants\nwere replaced by new ones who were tested with the same were instructed to respond as quickly and as accurately as\ncounterbalancing version. possible. They responded “yes” (by pressing the M key on\nthe keyboard) when the depicted object was mentioned in\nStimulus materials and software application the preceding sentence. They responded “no” (by pressing\nthe Z key on the keyboard) when the depicted object was not\nThe present experiment used the same critical stimuli as mentioned in the sentence. Each trial started with a fixation\nHoeben-Mannaert et al. (2017). These consisted of 16 cross (+) presented for 1,000 ms vertically in the middle of\nsentence pairs and 16 picture pairs. The two versions of a the screen and horizontally aligned to the left, where the\nsentence pair, each one implying a different color, could be first character of the sentence would appear (see Fig. 1). The\ncoupled with the two versions of a picture pair, each one in fixation cross was followed by a sentence. After the sentence\na different color, to form matching or mismatching trials. was read and understood, the participant pressed the spacebar\nAcross four list versions, for each of the 16 critical objects, to proceed. Another fixation cross (+) was presented centrally\none of the sentences in a pair was coupled with one of the for 500 ms. Following this fixation cross, an object picture\npictures in a pair, resulting in four different combinations was presented centrally to which participants responded\nof sentence-picture pairs (see Table 1 for examples). Thus, “yes” or “no” using the M or Z key, respectively. On half of\neach participant saw only one sentence and one picture of an the filler trials the response to the picture was followed by a\nobject. In this manner, four counterbalanced versions were comprehension question. Comprehensions questions required\ncreated so that, across participants, each sentence and each a “yes” (M key) or “no” (Z key) response. If participants\npicture were presented equally often in the color-match and made an error on picture trials or comprehension questions,\ncolor-mismatch condition. The same set of 16 filler items was the feedback message “Incorrect” was presented for 500 ms.\npresented to all participants. Each counterbalanced version A 1,000-ms intertrial interval followed the response of the\nthus included 16 critical sentences paired with 16 critical participant (or feedback in case of an incorrect response).\n\nMemory & Cognition\nTable 1 Example of experimental and filler stimuli\nS(cid:30)mulustype Sentence Picture Comprehension\nQues(cid:30)on\nExperimental trial color The driving instructor told Bob to None\nmatch list version 1 stop at the traffic light\nExperimental trial color The driving instructor told Bob to None\nmismatch list version 2 stop at the traffic light\nExperimental trial color The driving instructor told Bob to None\nmatch list version 3 go at the traffic light\nExperimental trial color The driving instructor told Bob to None\nmismatch list version 4 go at the traffic light\nFiller color mismatch Lloyd swam in a calm and clear Was Lloyd in the\nocean water?\nFiller color match Julia picked out a paint for her None\nnewly born daughter's room\nTrials were presented in a random order. Different random et al., 2002) and our preregistered analysis plan, statistical\norders were generated for each participant. analyses were based on the median reaction times. For\nParticipants first completed eight practice trials followed each participant and condition the median reaction time\nby 32 experimental trials (16 of which required a “yes” for correct responses was determined and entered in the\nresponse and 16 of which required a “no” response) pre- analyses. We conducted a paired-samples t-test to compare\nsented in random order. The trial procedure was the same the median reaction times in the color match and color\nfor practice and experimental trials. For both practice trials mismatch conditions (using α = .05). A comparable\nand experimental trials, half consisted of color-match trials analysis was performed on the mean error rates.\nand half consisted of color-mismatch trials.\nThe experiment ended with a closing questionnaire that\nResults and discussion\nasked participants for their native language, gender, and age,\nfollowed by a final thank you message.\nBased on our preregistered criteria, the data from 71 partici-\nData analysis pants were excluded. Thirty-three participants indicated that\ntheir native language was one other than English. Twelve\nFollowing previous studies (Hoeben-Mannaert et al., 2017; participants did not finish the experiment. Moreover, we\nStanfield & Zwaan, 2001; Zwaan & Pecher, 2012; Zwaan\n\nMemory & Cognition\nFig. 1 Example color-match filler trial and comprehension question. If the participants understood the sentence, they pressed the spacebar to\ncontinue. Only panels 1–5 were shown on experimental trials, and on filler trials without comprehension question\n1100\n1050\n1000\n950\n900\n850\n800\n750\n700\nna(cid:29)ve speakers (Exp 1) nonna(cid:29)ve speakers (Exp2 )\nremoved the data from one participant due to a low compre- participants to ensure an equal number of participants in\nhension score (below 50%),3 and we removed the data from each counterbalancing version.4 We analyzed and report the\nten participants due to a low overall accuracy on the critical data of the remaining 300 participants (56% female, mean\ntrials (below 80%). Finally, we removed the data from 15 age = 30.8 years, SD = 11.7). The data of all experiments\nreported in this article are available at https://o sf.i o/r 6b7j/.\n)sm(semiTnoitcaeR\nmatch\nmismatch\nFig. 2 Mean median reaction times for match and mismatch conditions in Experiments 1 and 2. In both experiments sentences were presented in\nEnglish. Error bars represent standard error of the mean difference between the match and mismatch conditions (Loftus & Masson, 1994)\n3 Note that the comprehension questions were merely added to\nstimulate processing the meaning of the sentence and not to select 4 In accordance with our preregistration, we retained the first 75\nparticipants. Of the remaining participants, 95% made two or participants with valid data for each counterbalancing version and\nfewer errors. The overall accuracy for these participants on the included these in the data analyses. The data of the remaining (later\ncomprehension questions was 89%. tested) participants were not included in the analyses.\n\nMemory & Cognition\nThe analyses were based on only the critical trials. Figure 2 the Netherlands. They received course credits for their\nshows the mean median reaction times (RTs) for the match and participation. We tested students at our own university\nmismatch condition (only trials with a correct response were because we know they are highly proficient non-native\nincluded in the analyses). Participants responded faster on match speakers of English. Erasmus University offers a Dutch\ntrials than on mismatch trials. The 106-ms color-match advantage language track and an international (English language)\n(871 ms vs. 976 ms) was significant, t(299) = 6.23, p < .001, track for the 3-year Psychology bachelor program. The\nd = 0.36. Moreover, participants made fewer errors on color- main difference between these tracks is in the small group\nmatch trials than on color-mismatch trials (4.3% vs. 13.1%), meetings that students typically attend two or three times a\nt(299) = 10.55, p < .001, d = 0.61. Thus, we found a color-match week to discuss the literature and work on exercises. Small\nadvantage on RTs and error rates even when the color match group meetings are either in Dutch or English, depending\nstatus was uncorrelated to the required response. These results are on the language track. For both tracks, plenary lectures are\nconsistent with the view that native speakers of English mentally given in English and the literature consists of texts written\nsimulated color during language comprehension. in English (mainly textbooks and journal articles).\nOur results are in line with previous studies reporting Before enrolling at the university, most Dutch students\na color-match advantage (De Koning et al., 2017; Hoeben- have had 6 years of secondary education throughout which\nMannaert et al., 2017; Zwaan & Pecher, 2012). Our evidence they have taken English classes. These students are fre-\nin favor of a match advantage, however, stands in contrast with quently exposed to English outside of formal educational\nstudies reporting a mismatch advantage (Connell, 2005; 2007). settings as most movies and television programs in the\nWe are not aware of a good explanation for this discrepancy Netherlands are shown in their original format (with Dutch\nin results. However, several researchers have now obtained a subtitles for broadcasts in a language other than Dutch).\ncolor-match advantage in preregistered experiments (Hoeben- Many Dutch people frequently travel to other countries\nMannaert et al., 2017; the current Experiment 1). Moreover, where they often speak English. In addition, English lan-\nthe positive color-match effect aligns with similar findings guage songs are very popular in the Netherlands. The\nfor shape (e.g., Zwaan et al., 2002, 2018; Zwaan & Pecher, educational and cultural background of our international\n2012) and orientation (e.g., Stanfield & Zwaan, 2001; Zwaan students is more diverse. However, all international stu-\n& Pecher, 2012). We are not aware of anyone reporting a nega- dents self-selected to take part in the English language pro-\ntive match effect for implied shape and orientation. Thus, it gram at Erasmus University and provided proof of English\nseems that native speakers mentally simulate the color of an proficiency prior to admission – for example, by having\nobject when comprehending language. obtained a secondary education diploma of which English\nExperiment 1 provided additional evidence for the idea was part of the final exam, by having attended secondary\nthat simulations are an automatic consequence of sentence school in an English-speaking country (e.g., UK), or having\nprocessing. In Experiment 2 we asked whether evidence obtained a TOEFL (Test of English as a Foreign Language)\nfor mental simulations is also found when language com- score ≥ 6.5 or IELTS (International English Language\nprehenders read sentences in their non-native language. Testing System) score ≥ 90.\nGiven the mixed results for non-native speakers in previ- The sample included a wide variety in native languages;\nous studies using sentence-picture verification tasks (Ahn together the 200 participants listed 24 different native\n& Jiang, 2018; Chen et al., 2020; Norman & Peleg, 2022), languages. Most prevalent were native speakers of Dutch\nwe investigated if the color-match effect that we observed (125 participants). Other languages that were listed as a\nin Experiment 1 with native speakers would be found in a native language by four or more participants were Ger-\ngroup of non-native participants. If non-native speakers of man (15 participants), Russian (six participants), Arabic\nEnglish, like native speakers, use a similar visual simulation (five participants), Turkish (five participants), Italian (five\nprocess during language comprehension, we should find a participants), Polish (four participants), Romanian (four\ncolor-match effect as we did in Experiment 1. participants), Spanish (four participants), and Vietnamese\n(four participants).\nAlthough we initially planned to analyze data of\nExperiment 2\n300 participants, we eventually decided to include 200\nparticipants in the analyses because the recruitment of\nMethod\nparticipants proceeded slower than we had hoped. Although\nwe anticipated that the effect size in Experiment 2 might be\nParticipants somewhat smaller than the one we obtained in Experiment\n1 (d = 0.36), because we tested non-native speakers, we\nParticipants were non-native speakers of English who expected that 200 participants would be sufficient to ensure\nstudied Psychology at Erasmus University Rotterdam in a high statistical power (as indicated by the initial power\n\nMemory & Cognition\nanalysis for Experiment 1). We collected data from 17 May non-native than for native speakers, F(1,498) = 7.62, p <\n2021 until 19 March 2022. .01, partial η2 = .02. The interaction for error rates should\nbe interpreted with caution because it was accompanied by a\nProcedure nonsignificant trend in the opposite direction for RTs. Thus,\nour results provide no evidence that the match effect was\nThe procedure was identical to that of Experiment 1. smaller for non-native than native speakers.\nData analysis\nGeneral discussion\nThe data analysis was the same as that of Experiment 1.\nPrevious studies reported findings consistent with the idea\nResults and discussion\nthat people mentally simulate features such as shape, ori-\nentation, and color during native language comprehension\nThe data of 56 participants were excluded based on our cri- (e.g., De Koning et al., 2017; Hoeben-Mannaert et al., 2017;\nteria and we analyzed data of 200 participants (80% female, Stanfield & Zwaan, 2001; Zwaan et al., 2002; Zwaan et al.,\nmean age = 21.3 years, SD = 3.8). Eleven participants indi- 2018; Zwaan & Pecher, 2012). Crucially, on critical trials\ncated English as their native language and their data were the depicted object could match or mismatch the object in\nconsequently removed. Five participants did not finish the the sentence on a feature such as shape, orientation, or color\nexperiment. We removed the data of three participants due to that was implied by the sentence but not explicitly men-\na low comprehension score (below 50%),5 and we removed tioned. Studies using the sentence-picture verification task\nthe data of ten participants due to a low overall accuracy on have shown that participants respond faster on match trials\nthe critical trials (below 80%). Finally, we removed the data than mismatch trials, bolstering the view that people perform\nof 27 participants to ensure an equal number of participants mental simulations during language comprehension. How-\n(i.e., 50) in each counterbalancing version. ever, a common property of these studies was that they did\nThe analyses were based on only the critical trials. Fig- not control the match status for filler trials. Consequently, in\nure 2 shows the mean median RT for correct responses in the the typical sentence-picture verification experiment there is\nmatch and mismatch condition. Participants responded faster a correlation between the match status and required response.\non match trials than on mismatch trials. The 76-ms match Participants may strategically use such correlations to aid\nadvantage (897 ms vs. 973 ms) was significant, t(199) = task performance (cf. Neely et al., 1989). By including\n3.81, p < .001, d = 0.27. Participants also made fewer errors color-match filler trials in our study, we removed the cor-\non match trials than on mismatch trials (5.2% vs. 17.9%), relation between color match and the required response. In\nt(199) = 10.33, p < .001, d = 0.73. Thus, we obtained a Experiment 1, we observed that even though color match\ncolor-match advantage on median RT and mean error rates was uncorrelated to the required response, participants still\neven when the correct response was uncorrelated to the verified color-match trials faster and with greater accuracy\ncolor match. The results indicate that non-native speakers of than color-mismatch trials. This is consistent with the idea\nEnglish (at least from the population we sampled) mentally that, in this task, color simulations are automatic and not\nsimulated color during language comprehension. dependent on strategies elicited by task demands. These\nresults strengthen the claim that participants mentally simu-\nExploratory analyses lated an object’s color while processing the meaning of a\nsentence in their native language, regardless of the specific\nTo investigate if the size of the match effect was different for task demands. This finding aligns with previous research\nnative and non-native speakers, we performed an additional that suggested that mental simulations are automatic and\nANOVA on the combined data from Experiments 1 and outside of awareness (Barsalou, 1999; Pecher et al., 2009a,\n2. For RTs we found no interaction between experiment 2009b; Zwaan & Pecher, 2022), at least when sentences are\nand match effect, F(1,498) = 1.25, p = .264, partial η2 = processed at a semantic level. Language comprehenders use\n.00, indicating no difference in the size of the match effect previous perceptual-motor experiences to construct simula-\nbetween the native and non-native speakers. For error rates tions of objects during language comprehension as proposed\nwe, somewhat surprisingly, found a larger match effect for by Barsalou’s (1999) perceptual symbols system theory.\nIn Experiment 2 we extended the match advantage to\nnon-native speakers. Previous studies investigating mental\nsimulations in non-native speakers have found inconsistent\n5 Of the remaining participants, 88% made two or fewer errors on the\nresults. Whereas some studies found evidence for mental\ncomprehension questions. The overall accuracy for these participants\non the comprehension questions was 83%. simulations in non-native speakers (Dudschig et al., 2014;\n\nMemory & Cognition\nWheeler & Stojanovic, 2006), other studies, in particular verification task for native speakers, they did not find a\nthose using the sentence-picture verifications task, did not match effect for non-native speakers. Possibly, the power\nfind such evidence (Chen et al., 2020; Norman & Peleg, to find a potentially smaller effect for non-natives was low.\n2022). In contrast, we obtained a clear match effect, which A second factor may be language proficiency. We did not\nindicates that the non-native speakers from our pool adopt a specifically measure language proficiency, but all participants\nnative-like comprehension style. were university students in a program that requires partici-\nOur results suggest that, at least for the proficient non- pants to be proficient in English as the lectures and the course\nnative speakers that we tested, language comprehension literature are in English. Students can enroll only if they can\nprocesses in the native and non-native language are very demonstrate proficiency in English. Moreover, proficiency\nsimilar. It seems that non-native speakers mentally simulate in English is not only a requirement to enter the bachelor\nthe content of sentences during language comprehension. program at our university, participating in the program also\nThus, even though the non-native language is acquired at means that students are frequently exposed to English (and\na later age than the native language, comprehension in the are very likely to have been recently exposed to English\nnon-native language seems to rely on sensorimotor informa- prior to participating in Experiment 2). Although language\ntion just like comprehension in the native language. On the proficiency, frequency, and recency of language use are all\none hand one might argue that this is perhaps not surprising correlated to each other, they are not the same. For exam-\ngiven that the lexical representations of the native and non- ple, a Dutch person who resides in the Netherlands may be\nnative language are connected to a shared conceptual system proficient in French but not be exposed much to French dur-\n(Kroll & Stewart, 1994; Potter et al., 1984; Zeelenberg & ing day-to-day life. Such a person may have learned French\nPecher, 2003). The lexical representations of the native and during secondary education and maintain relatively high\nnon-native language are often assumed to activate the same French-language proficiency during one or two trips a year\nor at least very similar conceptual information. On the other to France. The extent to which such a person would show evi-\nhand, it has been argued that because the non-native lan- dence of mental simulation when reading French sentences\nguage is learned in a different way than the native language, may depend on the recency with which the person has used\nsensorimotor information might not play a role during non- French. Participants in our study process English language\nnative language comprehension (Foroni, 2015; Kogan et al., on an almost daily basis and this may have contributed to\n2020). The reasoning is that because the non-native language our finding of a match effect in non-native speakers of Eng-\nis learned in a formal setting in which new words are not lish. The participants tested by Chen et al. (2020) and Nor-\nlearned through bodily experiences and direct interaction man and Peleg (2022) resided in their home country at the\nwith the physical world, the connections between the lexi- time of participating in their studies and, consequently, may\ncal representations and sensorimotor information are much have used their non-native language less frequently than the\nweaker than for the native language. The present results participants in our sample. This difference may explain why\nseem to be at odds with this view; the mental simulation we obtained evidence for visual simulations in non-native\nof visual characteristics seem to be a part of the language speakers and they did not. It would be interesting for future\ncomprehension processes in the native and non-native lan- studies to investigate which language characteristics of non-\nguage. Of course, this issue merits further investigation to native speakers, such as immersion (day-to-day exposure to\nsee whether this holds for visual characteristics other than and use of non-native language), initial age of learning the\ncolor and whether this also holds for non-native speakers non-native language and manner of language acquisition, are\nwho are less proficient or do not use their non-native lan- related to the match effect.\nguage as frequently as our participants. Apart from statistical reasons and individual differences\nWe can only speculate as to why some studies have related to language proficiency and language use, results may\nfailed to find evidence for mental simulations in non-native also depend on specific tasks and procedures used to study\nspeakers. One factor may be related to statistical power of mental simulations in non-native speakers. Chen et al. (2020)\nsome published studies. Recent studies that investigated used a delayed version of the sentence-picture verification\nthe color-match effect in native speakers had sample sizes task in which all sentences were presented in a first phase\nof around 200 (Hoeben-Mannaert et al., 2017; Zwaan & and participants responded to pictures only after all sen-\nPecher, 2012), which is an adequate size according to our tences had been read. Although Pecher, van Dantzig, Zwaan,\npower analysis. In Experiment 2, we therefore tested 200 et al. (2009) found evidence for mental simulations in such\nparticipants, which is much larger than samples used in a delayed task with native speakers, it is possible that the\nprevious studies with non-native speakers. For example, effects are short-lived for non-native speakers. Future stud-\nChen et al. (2020) had a sample size of 36 participants and ies could systematically investigate factors such as language\nNorman and Peleg (2022) had a sample size of 80. While proficiency and delay of testing to determine if and how these\nthey did find a shape-match effect in the sentence-picture factors contribute to match effects in non-native speakers.\n\nMemory & Cognition\nWe used two online experiments. Although online testing Ambrosi, S., Kalénine, S., Blaye, A., & Bonthoux, F. (2011).\nmay introduce more variability because participants use dif- Modality switching cost during property verification by 7 years\nof age. International Journal of Behavioral Development, 35(1),\nferent devices and may be in a noisy environment, it lessens\n78–83. https://d oi.o rg/1 0.1 177/0 16502 54103 71603\nthe influence researchers can wield over participants in terms Balota, D. A., & Lorch, R. F. (1986). Depth of automatic spreading\nof expectancies or unconscious experimenter effects. Moreo- activation: Mediated priming effects in pronunciation but\nver, it allowed us to recruit a more diverse sample of Eng- not in lexical decision. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 12(3), 336–345. https://d oi.\nlish-speaking adults in Experiment 1. Because participation\norg/1 0.1 037/0 278-7 393.1 2.3.3 36\nwas not limited to university students, the sample included a Barsalou, L. W. (1999). Perceptual symbol systems. Behavioral and\nlarge variation in terms of age and educational background, Brain Sciences, 22(4), 577–660.\na larger proportion of male participants than our sample of Barsalou, L. W., Simmons, W. K., Barbey, A. K., & Wilson, C. D.\n(2003). Grounding conceptual knowledge in modality-specific\nuniversity students in Experiment 2, and participants that\nsystems. Trends in Cognitive Sciences, 7(2), 84–91. https://d oi.\nresided in different countries (primarily Australia, Canada, org/1 0.1 016/S 1364-6 613(02)0 0029-3\nIreland, South Africa, the UK, and the USA). The sample in Bergen, B., Lau, T., Narayan, S., Stojanovic, D., & Wheeler, K.\nExperiment 2 consisted of university students, and included (2010). Body part representations in verbal semantics. Memory &\nCognition, 38(7), 969–981. https://d oi.o rg/1 0.3 758/M C.3 8.7.9 69\nparticipants who were native speakers of a large variety of\nBorghi, A. M. (2004). Object concepts and action: Extracting\ndifferent languages (e.g., Dutch, German, Russian, Arabic, affordances from objects parts. Acta Psychologica, 115(1), 69–96.\nTurkish, Italian, Polish, Romanian, Spanish, and Vietnam- https://d oi.o rg/1 0.1 016/j.a ctpsy.2 003.1 1.0 04\nese). Together, these findings suggest that our effects are Borghi, A. M., Glenberg, A. M., & Kaschak, M. P. (2004). Putting\nwords in perspective. Memory & cognition, 32(6), 863–873.\nnot limited to people from a relatively limited population\nhttps://d oi.o rg/1 0.3 758/B F0319 6865\nwith specific characteristics. Rather, our findings are consist- Chen, D., Wang, R., Zhang, J., & Liu, C. (2020). Perceptual\nent with the idea that mental simulations are automatically representations in L1, L2 and L3 comprehension: Delayed\nrecruited and an integral part of the language comprehension sentence–picture verification. Journal of Psycholinguistic\nResearch, 49(1), 41–57. https:// doi. org/ 10. 1007/\nprocess, even for non-native speakers.\ns10936- 019- 09670-x\nConnell, L. (2005). Colour and stability in embodied representations.\nOpen Practices Statement The data are available via the Open Science In B., Bara, L., Barsalou,, & M. Bucciarelli, (Eds.), Proceedings\nFramework at https://o sf.i o/r 6b7j/. of the Twenty-Seventh Annual Conference of the Cognitive Science\nExperiment 1 is preregistered on the Open Science Framework at Society (pp. 482-487), Lawrence Erlbaum.\nhttps://o sf.i o/r 6b7j/.\nConnell, L. (2007). Representing object colour in language\ncomprehension. Cognition, 102(3), 476–485. https://d oi.o rg/1 0.\nDeclarations\n1016/j.c ognit ion.2 006.0 2.0 09\nConnell, L., & Lynott, D. (2011). Modality switching costs emerge in\nConflict of interest The authors have no known conflicts of interest to concept creation as well as retrieval. Cognitive Science, 35(4),\ndisclose. 763–778. https://d oi.o rg/1 0.1 111/j.1 551-6 709.2 010.0 1168.x\nde Koning, B., Wassenburg, S. I., Bos, L. T., & van der Schoot, M.\nOpen Access This article is licensed under a Creative Commons Attri- (2017). Mental simulation of four visual object properties:\nbution 4.0 International License, which permits use, sharing, adapta- Similarities and differences as assessed by the sentence-picture\ntion, distribution and reproduction in any medium or format, as long verification task. Journal of Cognitive Psychology, 29(4), 420–\nas you give appropriate credit to the original author(s) and the source, 432. https://d oi.o rg/1 0.1 080/2 04459 11.2 017.1 28128 3\nprovide a link to the Creative Commons licence, and indicate if changes den Heyer, K., Briand, K., & Dannenbring, G. L. (1983). Strategic\nwere made. The images or other third party material in this article are factors in a lexical-decision task: Evidence for automatic and\nincluded in the article’s Creative Commons licence, unless indicated attention-driven processes. Memory & Cognition, 11(4), 374–81.\notherwise in a credit line to the material. If material is not included in https://d oi.o rg/1 0.3 758/b f0320 2452\nthe article’s Creative Commons licence and your intended use is not Dijkstra, T., & van Heuven, W. J. B. (2002). The architecture of\npermitted by statutory regulation or exceeds the permitted use, you will the bilingual word recognition system: From identification to\nneed to obtain permission directly from the copyright holder. To view a decision. Bilingualism: Language and Cognition, 5(3), 175–197.\ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/. https://d oi.o rg/1 0.1 017/S 13667 28902 00301 2\nDudschig, C., De La Vela, I., & Kaup, B. (2014). Embodiment and\nsecond-language: Automatic activation of motor responses during\nprocessing spatially associated L2 words and emotion L2 words\nin a vertical Stroop paradigm. Brain & Language, 132, 14–21.\nReferences\nhttps://d oi.o rg/1 0.1 016/j.b andl.2 014.0 2.0 02\nFaul, F., Erdfelder, E., Buchner, A., & Lang, A.-G. (2009). Statistical\nAhlberg, D. K., Bischoff, H., Kaup, B., Bryant, D., & Strozyk, power analyses using G*Power 3.1: Tests for correlation and\nJ. V. (2018). Grounded cognition: Comparing language x regression analyses. Behavior Research Methods, 41, 1149–1160.\nspace interactions in first and second language. Applied https://d oi.o rg/1 0.3 758/B RM.4 1.4.1 149\nPsycholinguistics, 39(2), 437–459. https://d oi.o rg/1 0.1 017/S 0142 Foroni, F. (2015). Do we embody second language? Evidence for\n716417 00042 X ‘partial’ simulation during processing of a second language.\nAhn, S., & Jiang, N. (2018). Automatic semantic integration during L2 Brain and Cognition, 99, 8–16. https://d oi.o rg/1 0.1 016/j.b andc.\nsentential reading. Bilingualism: Language and Cognition, 21(2), 2015.0 6.0 06\n375–383. https://d oi.o rg/1 0.1 017/S 13667 28917 00025 6\n\nMemory & Cognition\nGarcia, J., Kimeldorf, D. J., & Koelling, R. A. (1955). Conditioned Pecher, D., Zeelenberg, R., & Barsalou, L. W. (2004). Sensorimotor\naversion to saccharin resulting from exposure to gamma radiation. simulations underlie conceptual representations: Modality-specific\nScience, 122, 157–158. https://d oi.o rg/1 0.1 126/s cienc e.1 22.3 179. effects of prior activation. Psychonomic Bulletin & Review, 11(1),\n1089 164–167. https://d oi.o rg/1 0.3 758/B F0320 6477\nHoeben-Mannaert, L. N., Dijkstra, K., & Zwaan, R. A. (2017). Is color Pecher, D., Zeelenberg, R., & Raaijmakers, J. G. W. (2002).\nan integral part of a rich mental simulation? Memory & Cognition, Associative priming in a masked perceptual identification\n45(6), 974–982.",
  "char_count": 50000,
  "truncated": true,
  "structure": {
    "title": "Memory & Cognition",
    "authors": [
      "Sharon Singh",
      "Keywords Mental",
      "Kevin Gunawan",
      "Diane Pecher",
      "The Author"
    ],
    "abstract": "Pictures of objects are verified faster when they match the implied orientation, shape, and color in a sentence-picture\nverification task, suggesting that people mentally simulate these features during language comprehension. Previous studies\nhad an unintended correlation between match status and the required response, which may have influenced participants’\nresponses by eliciting strategic use of this correlation. We removed this correlation by including color-matching filler\ntrials and investigated if the color-match effect was still obtained. In both a native sample (Experiment 1) and a non-native\nsample (Experiment 2), we found strong evidence for a color-match advantage on median reaction time and error rates. Our\nresults are consistent with the view that color is automatically simulated during language comprehension as predicted by\nthe grounded cognition framework.\nKeywords Mental simulation · Color match · Perceptual symbols system · Sentence-picture verification task · Language\ncomprehension · Non-native speaker · Bilingualism",
    "sections": [
      {
        "title": "Introduction",
        "position": 1321
      },
      {
        "title": "2 This probability is 33% in the following typical case. Half of the",
        "position": 15173
      },
      {
        "title": "3 Note that the comprehension questions were merely added to",
        "position": 24814
      },
      {
        "title": "5 Of the remaining participants, 88% made two or fewer errors on the",
        "position": 35946
      },
      {
        "title": "References",
        "position": 48284
      }
    ],
    "keywords": [],
    "references_found": true
  },
  "extraction_method": "pdfplumber"
}