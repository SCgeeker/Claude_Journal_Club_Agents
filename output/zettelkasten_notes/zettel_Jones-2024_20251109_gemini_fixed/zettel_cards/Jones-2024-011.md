---
title: "Counterfactual Reasoning"
summary: |-
  "The MLLM could reason about what would have happened if an agent had taken a different action, indicating an understanding of cause and effect."
---

## èªªæ˜
The MLLM was able to perform counterfactual reasoning, which suggests that it had developed a causal model of the world and could simulate alternative scenarios.

## é€£çµç¶²çµ¡


**åŸºæ–¼** â†’ [[Jones-2024-006]]





## ä¾†æºè„ˆçµ¡
- ğŸ“„ **æ–‡ç»**: 



## å€‹äººç­†è¨˜


ğŸ¤– **AI**: Does counterfactual reasoning truly require embodied simulation? Or can it be achieved through purely symbolic or logical reasoning processes as is a frequent claim against generative models highlighted in [[Jones-2024-006]]?

âœï¸ **Human**:



## å¾…è§£å•é¡Œ
How can we design experiments to specifically test the role of embodied simulation in counterfactual reasoning?
