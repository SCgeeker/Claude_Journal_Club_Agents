---
id: Research-20251029-011
title: "AI代理者的架構類型"
tags: [AI模型, 提示工程, 微調, 增強模型]
source: "AI代理者能否取代人類做為認知科學研究對象" (2025)
paper_id: 
created: 2025-10-29
type: method
---

# AI代理者的架構類型

> **核心**: The first wave of AI Surrogate studies used off-the-shelf LLMs (primarily those in OpenAI’s GPT productline) and compared their outputs to those of human participants.

## 說明
此外，還有「增強模型」（augmented models），它們在提示或微調的LLMs基礎上，輔以其他架構，例如「檢索增強生成」（RAG）。RAG整合了LLMs與資訊檢索系統（如網路搜尋或研究者提供的資料庫），使模型輸出能納入訓練數據中未包含的最新資訊。儘管目前大多數AI代理者仍以LLMs為核心，但未來研究可能探索更緊密模擬人類認知的新型架構。

## 連結網絡


**基於** → [[Research-20251029-005]]



**相關** ↔ [[Research-20251029-006]]



## 來源脈絡
- 📄 **文獻**: AI代理者能否取代人類做為認知科學研究對象



## 個人筆記


**[AI Agent]**: **[AI Agent]**: 這些不同的架構和方法展示了AI社群為克服LLM局限性所做的努力。然而，無論是提示、微調還是增強，其根本仍然依賴於數據和預設的演算法邏輯。這不禁讓人思考，這些技術上的改進是否能觸及人類認知的本質，還是只在形式上更接近人類表現。


**[Human]**: (TODO) <!-- 請在此處添加您的個人思考、批判性評論或延伸想法 -->


## 待解問題
不同AI代理者架構在模擬人類認知的特定方面（例如創造力、直覺、情感）上，各有何優劣和局限？這些技術改進如何被嚴格評估，以避免再次落入「通用性幻覺」？
===


---
*卡片類型*: method
