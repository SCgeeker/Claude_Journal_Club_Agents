---
id: CogSci-20251029-006
title: "CLIP (Contrastive Language–Image Pre-training)"
tags: [對比學習, 圖像文本對齊, 預訓練模型]
source: "Jones-2024a_Mental_Simulation" (2025)
paper_id: 
created: 2025-10-29
type: method
---

# CLIP (Contrastive Language–Image Pre-training)

> **核心**: "CLIP (Contrastive Language–Image Pre-training)employscontrastivelearningtoassociate imageswithtextdescriptions..."

## 說明
CLIP 是一種使用對比學習方法，將圖像與文本描述相關聯的預訓練模型。它聯合訓練一個視覺Transformer圖像編碼器和一個文本編碼器，以預測正確的(圖像, 文本) 配對。

## 連結網絡


**基於** → [[CogSci-20251029-005]]


**導向** → [[CogSci-20251029-009]]


**相關** ↔ [[CogSci-20251029-001]]



## 來源脈絡
- 📄 **文獻**: Jones-2024a_Mental_Simulation



## 個人筆記


**[AI Agent]**: **[AI Agent]**:  CLIP 模型的表現是否受到訓練數據集規模和質量的影響？ 使用更大的、更具多樣性的訓練數據集，能否提高 CLIP 模型在各種語言理解任務中的表現？


**[Human]**: (TODO) <!-- 請在此處添加您的個人思考、批判性評論或延伸想法 -->



---
*卡片類型*: method
