---
id: CogSci-20251031-009
title: "統計學種族歧視的歷史背景"
tags: [歷史背景, 種族歧視, 心理測量學, 統計學批判]
source: "Critical AI Literacy for Psychologists" (2025)
paper_id: 
created: 2025-10-31
type: finding
---

# 統計學種族歧視的歷史背景

> **核心**: "Most serious are the eugenics roots of modern statistics and psychometrics, which gave rise to pseudoscientific theories like physiognomy and phrenology, which in turn provided scientific cover for racism, sexism, classism, ableism, and ultimately genocide"

## 說明
這是論文引用的一個重要歷史事實，揭示了現代統計學和心理測量學與優生學、種族歧視的黑暗歷史聯繫。作者指出，最嚴重的是現代統計學和心理測量學的優生學根源，它們產生了偽科學理論如面相學和顱相學，這些理論為種族主義、性別歧視、階級歧視、殘障歧視以及最終的種族滅絕提供了科學偽裝。這個歷史背景被用作現代AI技術批判的深層框架，暗示當前的數據驅動技術可能重複歷史上的科學濫用。

## 連結網絡



**導向** → [[CogSci-20251031-001]]


**相關** ↔ [[CogSci-20251031-008]]



## 來源脈絡
- 📄 **文獻**: Critical AI Literacy for Psychologists



## 個人筆記


**[AI Agent]**: [AI Agent]: 這個歷史背景很有說服力，但需要注意避免「滑坡謬誤」。雖然歷史上確實有統計學被用於歧視和壓迫的例子，但不能因此斷定所有現代統計方法和AI技術都必然重複這些錯誤。現代科學社群對倫理問題的認識和監管機制遠超過去。關鍵可能在於建立適當的倫理框架和監管機制，而非完全抵制數據驅動技術。


**[Human]**: (TODO) <!-- 請在此處添加您的個人思考、批判性評論或延伸想法 -->


## 待解問題
[待解問題: 如何確保現代AI技術的發展不會重複歷史上統計學被濫用的錯誤？需要建立什麼樣的倫理框架和監管機制來防止技術濫用？]
===


---
*卡片類型*: finding
