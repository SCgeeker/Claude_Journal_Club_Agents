---
id: CogSci-20251028-004
title: "LLM 的局限性"
tags: [LLM, 偏見, 可解釋性, 穩定性]
source: "AI Surrogates" (2025)
paper_id: 
created: 2025-10-28
type: concept
---

# LLM 的局限性

> **核心**: 基於 LLM 的 AI 代理可能存在過度代表主流觀點、缺乏反應多樣性以及難以解釋和不穩定的問題。

## 說明
基於大型語言模型 (LLM) 的 AI 代理存在一些局限性，包括：
*   過度代表訓練數據中的主流觀點，可能導致偏見。
*   缺乏人類反應的多樣性。
*   難以解釋其內部運作機制。
*   可能因為不明原因產生不穩定的結果。

## 連結網絡


**基於** → [[CogSci-20251028-001]]


**導向** → [[CogSci-20251028-010]]




## 來源脈絡
- 📄 **文獻**: AI Surrogates




## 個人筆記
這些局限性提醒我們，在使用基於 LLM 的 AI 代理時，需要特別注意其潛在的偏見和不穩定性。



## 待解問題
如何克服基於 LLM 的 AI 代理的局限性？
===


---
*卡片類型*: concept
