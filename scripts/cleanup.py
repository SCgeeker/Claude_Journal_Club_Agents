#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ˆæ¡ˆæ¸…ç†è…³æœ¬
æ¸…ç†è‡¨æ™‚æ–‡ä»¶ã€å¿«å–å’ŒèˆŠè¼¸å‡º
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
import shutil

# è¨­ç½®UTF-8ç·¨ç¢¼ï¼ˆWindowsç›¸å®¹æ€§ï¼‰
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# å°ˆæ¡ˆæ ¹ç›®éŒ„
ROOT = Path(__file__).parent.parent


def clean_cache():
    """æ¸…ç†å¿«å–ç›®éŒ„"""
    cache_dir = ROOT / ".cache"
    if cache_dir.exists():
        file_count = len(list(cache_dir.glob("*")))
        if file_count > 0:
            for item in cache_dir.iterdir():
                if item.is_file():
                    item.unlink()
                elif item.is_dir():
                    shutil.rmtree(item)
            print(f"âœ… æ¸…ç†å¿«å–: åˆªé™¤ {file_count} å€‹æ–‡ä»¶")
        else:
            print("âœ… å¿«å–ç›®éŒ„å·²ç¶“æ˜¯ç©ºçš„")
    else:
        print("âš ï¸  å¿«å–ç›®éŒ„ä¸å­˜åœ¨")


def clean_old_outputs(days=30):
    """æ¸…ç†èˆŠçš„è¼¸å‡ºæ–‡ä»¶"""
    output_dir = ROOT / "output"
    if not output_dir.exists():
        print("âš ï¸  è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨")
        return

    cutoff_date = datetime.now() - timedelta(days=days)
    deleted = 0

    for file in output_dir.glob("*.json"):
        if datetime.fromtimestamp(file.stat().st_mtime) < cutoff_date:
            file.unlink()
            deleted += 1

    if deleted > 0:
        print(f"âœ… æ¸…ç†è¼¸å‡º: åˆªé™¤ {deleted} å€‹è¶…é {days} å¤©çš„æ–‡ä»¶")
    else:
        print(f"âœ… æ²’æœ‰è¶…é {days} å¤©çš„è¼¸å‡ºæ–‡ä»¶")


def clean_logs(days=7):
    """æ¸…ç†èˆŠæ—¥èªŒ"""
    logs_dir = ROOT / "logs"
    if not logs_dir.exists():
        print("âš ï¸  æ—¥èªŒç›®éŒ„ä¸å­˜åœ¨")
        return

    cutoff_date = datetime.now() - timedelta(days=days)
    deleted = 0

    for file in logs_dir.glob("*.log"):
        if datetime.fromtimestamp(file.stat().st_mtime) < cutoff_date:
            file.unlink()
            deleted += 1

    if deleted > 0:
        print(f"âœ… æ¸…ç†æ—¥èªŒ: åˆªé™¤ {deleted} å€‹è¶…é {days} å¤©çš„æ—¥èªŒ")
    else:
        print(f"âœ… æ²’æœ‰è¶…é {days} å¤©çš„æ—¥èªŒæ–‡ä»¶")


def clean_pycache():
    """æ¸…ç†Pythonå¿«å–"""
    deleted = 0
    for pycache in ROOT.rglob("__pycache__"):
        shutil.rmtree(pycache)
        deleted += 1

    for pyc in ROOT.rglob("*.pyc"):
        pyc.unlink()
        deleted += 1

    if deleted > 0:
        print(f"âœ… æ¸…ç†Pythonå¿«å–: åˆªé™¤ {deleted} å€‹é …ç›®")
    else:
        print("âœ… æ²’æœ‰Pythonå¿«å–éœ€è¦æ¸…ç†")


def show_disk_usage():
    """é¡¯ç¤ºç£ç¢Ÿä½¿ç”¨æƒ…æ³"""
    print("\nğŸ“Š ç£ç¢Ÿä½¿ç”¨æƒ…æ³:")

    dirs_to_check = [
        ("çŸ¥è­˜åº«", ROOT / "knowledge_base"),
        ("è¼¸å‡º", ROOT / "output"),
        ("å¿«å–", ROOT / ".cache"),
        ("æ—¥èªŒ", ROOT / "logs"),
    ]

    for name, dir_path in dirs_to_check:
        if dir_path.exists():
            total_size = sum(f.stat().st_size for f in dir_path.rglob("*") if f.is_file())
            size_mb = total_size / (1024 * 1024)
            file_count = len(list(dir_path.rglob("*")))
            print(f"   {name}: {size_mb:.2f} MB ({file_count} å€‹æ–‡ä»¶)")
        else:
            print(f"   {name}: ä¸å­˜åœ¨")


def main():
    print("=" * 60)
    print("ğŸ§¹ å°ˆæ¡ˆæ¸…ç†å·¥å…·")
    print("=" * 60)

    print("\né–‹å§‹æ¸…ç†...\n")

    clean_cache()
    clean_old_outputs(days=30)
    clean_logs(days=7)
    clean_pycache()

    show_disk_usage()

    print("\n" + "=" * 60)
    print("âœ… æ¸…ç†å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
